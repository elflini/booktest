<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Key Statistical Concepts | Statistics for Health Data Science</title>
  <meta name="description" content="Lecture notes for Statistics for Health Data Science" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Key Statistical Concepts | Statistics for Health Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes for Statistics for Health Data Science" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Key Statistical Concepts | Statistics for Health Data Science" />
  
  <meta name="twitter:description" content="Lecture notes for Statistics for Health Data Science" />
  

<meta name="author" content="Jin Hyun Nam" />


<meta name="date" content="2021-11-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter1.html"/>
<link rel="next" href="chapter3.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics for Health Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Statistics and Health Data</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#statistics-and-organic-statistics"><i class="fa fa-check"></i><b>1.2</b> Statistics and Organic Statistics</a></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#statistical-methods-and-models"><i class="fa fa-check"></i><b>1.3</b> Statistical Methods and Models</a></li>
<li class="chapter" data-level="1.4" data-path="chapter1.html"><a href="chapter1.html#health-care-data"><i class="fa fa-check"></i><b>1.4</b> Health Care Data</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="chapter1.html"><a href="chapter1.html#medical-claims"><i class="fa fa-check"></i><b>1.4.1</b> Medical Claims</a></li>
<li class="chapter" data-level="1.4.2" data-path="chapter1.html"><a href="chapter1.html#medical-records"><i class="fa fa-check"></i><b>1.4.2</b> Medical Records</a></li>
<li class="chapter" data-level="1.4.3" data-path="chapter1.html"><a href="chapter1.html#health-surveys"><i class="fa fa-check"></i><b>1.4.3</b> Health Surveys</a></li>
<li class="chapter" data-level="1.4.4" data-path="chapter1.html"><a href="chapter1.html#disease-registries"><i class="fa fa-check"></i><b>1.4.4</b> Disease Registries</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="chapter1.html"><a href="chapter1.html#outline-of-the-text"><i class="fa fa-check"></i><b>1.5</b> Outline of the Text</a></li>
<li class="chapter" data-level="1.6" data-path="chapter1.html"><a href="chapter1.html#software-and-data"><i class="fa fa-check"></i><b>1.6</b> Software and Data</a></li>
<li class="chapter" data-level="1.7" data-path="chapter1.html"><a href="chapter1.html#loading-meps-data"><i class="fa fa-check"></i><b>1.7</b> Loading MEPS data</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="chapter1.html"><a href="chapter1.html#data-loading"><i class="fa fa-check"></i><b>1.7.1</b> Data Loading</a></li>
<li class="chapter" data-level="1.7.2" data-path="chapter1.html"><a href="chapter1.html#visualize-histogram-of-total-expenditures"><i class="fa fa-check"></i><b>1.7.2</b> Visualize histogram of total expenditures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> Key Statistical Concepts</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#samples-and-populations"><i class="fa fa-check"></i><b>2.1</b> Samples and Populations</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#statistics-basics"><i class="fa fa-check"></i><b>2.2</b> Statistics Basics</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="chapter2.html"><a href="chapter2.html#random-variables"><i class="fa fa-check"></i><b>2.2.1</b> Random Variables</a></li>
<li class="chapter" data-level="2.2.2" data-path="chapter2.html"><a href="chapter2.html#dependent-and-independent-variables"><i class="fa fa-check"></i><b>2.2.2</b> Dependent and Independent Variables</a></li>
<li class="chapter" data-level="2.2.3" data-path="chapter2.html"><a href="chapter2.html#statistical-distributions-and-their-summaries"><i class="fa fa-check"></i><b>2.2.3</b> Statistical Distributions and Their Summaries</a></li>
<li class="chapter" data-level="2.2.4" data-path="chapter2.html"><a href="chapter2.html#parameters-and-models"><i class="fa fa-check"></i><b>2.2.4</b> Parameters and Models</a></li>
<li class="chapter" data-level="2.2.5" data-path="chapter2.html"><a href="chapter2.html#estimation-and-inference"><i class="fa fa-check"></i><b>2.2.5</b> Estimation and Inference</a></li>
<li class="chapter" data-level="2.2.6" data-path="chapter2.html"><a href="chapter2.html#variation-and-standard-error"><i class="fa fa-check"></i><b>2.2.6</b> Variation and Standard Error</a></li>
<li class="chapter" data-level="2.2.7" data-path="chapter2.html"><a href="chapter2.html#conditional-and-marginal-means"><i class="fa fa-check"></i><b>2.2.7</b> Conditional and Marginal Means</a></li>
<li class="chapter" data-level="2.2.8" data-path="chapter2.html"><a href="chapter2.html#joint-and-mixture-distributions"><i class="fa fa-check"></i><b>2.2.8</b> Joint and Mixture Distributions</a></li>
<li class="chapter" data-level="2.2.9" data-path="chapter2.html"><a href="chapter2.html#variable-transformations"><i class="fa fa-check"></i><b>2.2.9</b> Variable Transformations</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#common-statistical-distributions-and-concepts"><i class="fa fa-check"></i><b>2.3</b> Common Statistical Distributions and Concepts</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="chapter2.html"><a href="chapter2.html#the-bernoulli-and-binomial-distributions-for-binary-outcomes"><i class="fa fa-check"></i><b>2.3.1</b> The Bernoulli and Binomial Distributions for Binary Outcomes</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapter2.html"><a href="chapter2.html#pmf-plot"><i class="fa fa-check"></i><b>2.3.2</b> pmf plot</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapter2.html"><a href="chapter2.html#comparison-with-simulated-value"><i class="fa fa-check"></i><b>2.3.3</b> comparison with simulated value</a></li>
<li class="chapter" data-level="2.3.4" data-path="chapter2.html"><a href="chapter2.html#the-multinomial-distribution-for-categorical-outcomes"><i class="fa fa-check"></i><b>2.3.4</b> The Multinomial Distribution for Categorical Outcomes</a></li>
<li class="chapter" data-level="2.3.5" data-path="chapter2.html"><a href="chapter2.html#the-poisson-and-negative-binomial-distributions-for-counts"><i class="fa fa-check"></i><b>2.3.5</b> The Poisson and Negative Binomial Distributions for Counts</a></li>
<li class="chapter" data-level="2.3.6" data-path="chapter2.html"><a href="chapter2.html#pmf-plot-1"><i class="fa fa-check"></i><b>2.3.6</b> pmf plot</a></li>
<li class="chapter" data-level="2.3.7" data-path="chapter2.html"><a href="chapter2.html#comparison-with-simulated-value-1"><i class="fa fa-check"></i><b>2.3.7</b> comparison with simulated value</a></li>
<li class="chapter" data-level="2.3.8" data-path="chapter2.html"><a href="chapter2.html#the-normal-distribution-for-continuous-outcomes"><i class="fa fa-check"></i><b>2.3.8</b> The Normal Distribution for Continuous Outcomes</a></li>
<li class="chapter" data-level="2.3.9" data-path="chapter2.html"><a href="chapter2.html#the-gamma-and-lognormal-distributions-for-right-skewed-outcomes"><i class="fa fa-check"></i><b>2.3.9</b> The Gamma and Lognormal Distributions for Right-Skewed Outcomes</a></li>
<li class="chapter" data-level="2.3.10" data-path="chapter2.html"><a href="chapter2.html#pdf-plot"><i class="fa fa-check"></i><b>2.3.10</b> pdf plot</a></li>
<li class="chapter" data-level="2.3.11" data-path="chapter2.html"><a href="chapter2.html#comparison-with-simulated-value-2"><i class="fa fa-check"></i><b>2.3.11</b> comparison with simulated value</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#hypothesis-testing-and-statistical-inference"><i class="fa fa-check"></i><b>2.4</b> Hypothesis Testing and Statistical Inference</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> Regression Analysis</a>
<ul>
<li class="chapter" data-level="3.0.1" data-path="chapter3.html"><a href="chapter3.html#regression-to-estimate-the-effect-of-an-intervention"><i class="fa fa-check"></i><b>3.0.1</b> Regression to Estimate the Effect of an Intervention</a></li>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#linear-regression-estimation-and-interpretation"><i class="fa fa-check"></i><b>3.1</b> Linear Regression Estimation and Interpretation</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#model-selection-and-hypothesis-testing"><i class="fa fa-check"></i><b>3.2</b> Model Selection and Hypothesis Testing</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#checking-assumptions-about-the-random-part"><i class="fa fa-check"></i><b>3.3</b> Checking Assumptions About the Random Part</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="chapter3.html"><a href="chapter3.html#추가자료_quantile-regression"><i class="fa fa-check"></i><b>3.3.1</b> 추가자료_Quantile regression</a></li>
<li class="chapter" data-level="3.3.2" data-path="chapter3.html"><a href="chapter3.html#추가자료_loess-lowess"><i class="fa fa-check"></i><b>3.3.2</b> 추가자료_Loess Lowess</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics for Health Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter2" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Key Statistical Concepts</h1>
<!-- --------- Chapter 2 Key Statistical Concepts ------------------>
<div id="samples-and-populations" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Samples and Populations</h2>
<ul>
<li><p><strong>Statistics</strong>: Inferences from a sample about a defined population.</p></li>
<li><p><strong>Population</strong>: The main goal of health research is to learn about health outcomes and their drivers in the population.</p></li>
<li><p>This is the aim of clinical trials and most observational health care studies.</p></li>
<li><p>The population can be well defined at the outset</p>
<p><code>-</code> All people who were in the city of Hiroshima at the time of the atomic bombings and survived the first year</p></li>
<li><p>Or can be hypothetical</p>
<p><code>-</code> All breast cancer patients who have undergone or will undergo radical mastectomy.</p></li>
<li><p>A sub-population is a population in and of itself that satisfies well-defined properties.</p>
<p><code>-</code> Men under the age of 20 years</p>
<p><code>-</code> Patients with hormone-receptor-positive breast cancer who have undergone radical mastectomy.</p></li>
<li><p>Many scientific questions relate to differences between sub-populations</p>
<p><code>-</code> Comparing treated and untreated concern sub-populations as they estimate the mean outcome for different groups (sub-populations) defined by the covariates.</p></li>
<li><p><strong>Sample</strong>: A sample is a subset of the population that is used to learn about that population.</p>
<p><code>-</code> Sub-population: fixed criteria</p>
<p><code>-</code> Sample: random mechanism</p>
<p><code>-</code> Survey samples are examples of random samples, but many observational studies are not randomly sampled.</p></li>
<li><p>Regardless of how samples are obtained, their use to learn about a target population means that issues of representativeness are inevitable and deserve to be addressed.</p></li>
</ul>
</div>
<div id="statistics-basics" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Statistics Basics</h2>
<div id="random-variables" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Random Variables</h3>
<ul>
<li><p>The study of health care outcomes is the study of the random variables that measure these outcomes.</p></li>
<li><p>A random variable captures a specific characteristic of individuals in the population, and its values typically vary across individuals.</p></li>
<li><p>Each random variable can take on a range of values in theory although, in practice, we observe a specific value for each individual.</p></li>
<li><p>Examples of random variables that are health outcomes:</p>
<p><code>-</code> Whether a patient is hospitalized or re-admitted after surgery</p>
<p><code>-</code> Whether a breast cancer patient receives a mastectomy or a lumpectomy</p>
<p><code>-</code> Types of prescription medications filled for a specific condition</p>
<p><code>-</code> Days hospitalized after a specific type of surgery</p>
<p><code>-</code> Inpatient, outpatient, or prescription medication expenditures within a year</p>
<p><code>-</code> Number and types of advanced imaging tests after primary cancer treatment</p>
<p><code>-</code> Number of outpatient visits over a defined time interval</p>
<p><code>-</code> Total annual expenditures among patients within a specific health category.</p></li>
<li><p>Random variable: Generically or theoretically, capital letters like <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Specific values: small letters like <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p></li>
<li><p>Thus, for example, we might talk about an unspecified patient age <span class="math inline">\(X\)</span> with a range from 20 to 85 years, but for a given patient, we might observe a specific age <span class="math inline">\(x\)</span> equal to 62 years.</p></li>
</ul>
</div>
<div id="dependent-and-independent-variables" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Dependent and Independent Variables</h3>
<ul>
<li><p>A key first task in any analysis is to identify the dependent (<span class="math inline">\(Y\)</span>) and independent (<span class="math inline">\(X\)</span>) variables.</p></li>
<li><p>Dependent variable</p>
<p><code>-</code> Response variable</p>
<p><code>-</code> Outcome</p></li>
<li><p>Independent variable</p>
<p><code>-</code> Explanatory variable</p>
<p><code>-</code> Predictor</p>
<p><code>-</code> Covariate</p></li>
<li><p>In regression analyses, the central question concerns how Y changes as X varies. More precisely, if the value of the independent variable <span class="math inline">\(X\)</span> changes, then what is the consequence for the dependent variable <span class="math inline">\(Y\)</span>?</p></li>
<li><p>Loosely speaking, the independent and dependent variables are analogous to “cause” and “effect,” where the quotation marks here emphasize that this is just an analogy, and that cause must be rigorously determined using an appropriate study design and analysis.</p></li>
<li><p>Whether a variable is an independent or a dependent variable depends on the research question.</p></li>
<li><p>Sometimes be quite challenging to decide which variable is dependent and which is independent, particularly when there are feedback loops going in both directions between the variables.</p></li>
<li><p>Example: Association between elective vigorous exercise and insomnia</p>
<p><code>-</code> Exercise (done at the right time of the day) may reduce insomnia.</p>
<p><code>-</code> But insomnia may also reduce a person’s ability to exercise.</p></li>
<li><p>Sometimes, outcomes other than the one specified may masquerade as potential independent variables.</p></li>
<li><p>Example: How medical expenditures in a given year depend on smoking history.</p>
<p><code>-</code> Independent variable: smoking history</p>
<p><code>-</code> Dependent variable: medical expenditures</p>
<p><code>-</code> How about number of hospitalizations?</p>
<p><code>-</code> Number of hospitalizations will be strongly correlated with medical expenditures, but for this question both hospitalizations and medical expenditures are best considered as dependent variables that coevolve.</p></li>
</ul>
</div>
<div id="statistical-distributions-and-their-summaries" class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Statistical Distributions and Their Summaries</h3>
<ul>
<li><p>Each random variable has a distribution that describes the probability that the variable takes any value or interval in its range.</p></li>
<li><p>A categorical variable can take any of a finite number of discrete values, and the distribution is given by a finite set of probabilities corresponding to these possible values, with the probabilities summing to 1.</p></li>
<li><p>A continuous variable has many (effectively an infinite number of) possible values. Consequently, the probability of each value is very small.</p></li>
<li><p>In principle, we can imagine the distribution of a continuous variable as an extremely detailed histogram in which the widths of the intervals become very small.</p></li>
<li><p>The histogram becomes a curve called the probability density function (PDF) of the random variable, and the area under the PDF over any interval represents the probability that the random variable will have a value within that interval.</p></li>
<li><p>The cumulative distribution function (CDF) at a specified value gives the probability that the random variable takes on a value smaller than or equal to that value and is mathematically equal to the integral of the PDF up to that value. Words used to describe the shape of a distribution include symmetric, skewed, heavy-tailed or kurtotic (referring to a high frequency of extreme values), and uni- or multimodal (referring to the number of peaks of the most likely values).</p></li>
<li><p>Quantitative summaries of distributions often focus on identifying the most typical, or representative, value of a random variable.</p></li>
<li><p>The mean</p>
<p><code>-</code> Mean of a random variable <span class="math inline">\(Y\)</span> is denoted by <span class="math inline">\(E(Y)\)</span>.</p></li>
<li><p>Other common summaries: percentiles or quantiles</p>
<p><code>-</code> Median is the 50th percentile and represents the center of the distribution in the sense that 50% of the observations are below it and 50% are above it.</p></li>
<li><p>The median and the mean coincide if the distribution is symmetric and differ otherwise; the mean is influenced by extreme (large and small) observations, while the median is not.</p></li>
<li><p>Health care outcomes are often right-skewed because of the presence of a few heavy users whose health is extremely poor relative to the rest of the population.</p>
<p><code>-</code> Mean is larger than the median, and therefore the median may be a better summary of a typical value of the population.</p></li>
</ul>
<p><img src="fig/fig2.1.png" /></p>
<ul>
<li><p>Figure 2.1 is a histogram of total costs among persons with any reported inpatient costs based on data from the Medical Expenditure Panel Survey (MEPS) in 2017.</p></li>
<li><p>The MEPS collects information on socio-demographics, health behavior, health insurance, health care utilization, and expenditures for a population-representative sample of households in the United States.</p></li>
<li><p>The figure shows an extreme right-skewed distribution with a mean of 18,145 and a much lower median of 9664.</p></li>
</ul>
</div>
<div id="parameters-and-models" class="section level3" number="2.2.4">
<h3><span class="header-section-number">2.2.4</span> Parameters and Models</h3>
<ul>
<li><p>Parameters, typically denoted by Greek letters like <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\alpha\)</span>, allow us to specify which member of the family.</p></li>
<li><p>Thus, we can talk about a random variable having a normal distribution, but by specifying the mean <span class="math inline">\(\mu=9.8\)</span> and the variance <span class="math inline">\(\sigma^2=2.4\)</span>, we narrow focus to a specific normal distribution.</p></li>
<li><p>Parametric statistical methods specify the family of distributions and then use the data to learn about its specific member by estimating the parameters.</p></li>
<li><p>If <span class="math inline">\(f\)</span> is the PDF of an outcome variable <span class="math inline">\(Y\)</span>, interest may focus on its mean and variance.</p></li>
<li><p>In regression analysis, we try to explain how the parameters of <span class="math inline">\(f\)</span> depend on covariates <span class="math inline">\(X\)</span>.</p></li>
<li><p>In classical linear regression, we assume that <span class="math inline">\(Y\)</span> has a normal distribution with mean <span class="math inline">\(\mu=E(Y)\)</span>, and we estimate how <span class="math inline">\(E(Y)\)</span> depends on <span class="math inline">\(X\)</span>.</p></li>
<li><p>The term model is ubiquitous in statistics.</p></li>
<li><p>The model comprises the assumptions and mathematical specifications for the analysis.</p></li>
<li><p>The model depends on the data and the research question, but it is rarely unique; in most cases, there is more than one model that might reasonably address the same question given the data.</p></li>
<li><p>In predicting annual medical expenditures based on the MEPS, for example, the model specification includes the set of candidate covariates, the mathematical expression linking the predictor variables with the expenditure outcome, and any assumptions about the distribution of the outcome.</p></li>
</ul>
</div>
<div id="estimation-and-inference" class="section level3" number="2.2.5">
<h3><span class="header-section-number">2.2.5</span> Estimation and Inference</h3>
<ul>
<li><p>Estimation is the process by which the sample is used to learn about the population.</p></li>
<li><p>The sample mean is a natural estimate of the population mean, and the sample median is a natural estimate of the population median.</p></li>
<li><p>When we talk about estimating a population summary measure (sometimes referred to as a population parameter) or estimating the distribution of a random variable, we are talking about using the data to learn about these features in the population.</p></li>
<li><p>Statistical inference is the process by which sample estimates are used to answer research questions and address specified hypotheses about the population.</p></li>
<li><p>Thus, for example, the sample mean is an estimate, the sample standard error is an estimate, and a hypothesis test is a procedure by which these estimates are combined to make inferences.</p></li>
</ul>
</div>
<div id="variation-and-standard-error" class="section level3" number="2.2.6">
<h3><span class="header-section-number">2.2.6</span> Variation and Standard Error</h3>
<ul>
<li><p>Estimates are functions of the sampled data.</p></li>
<li><p>Although we always observe only a single sample, we must take into consideration the fact that it was randomly drawn among many potential samples.</p></li>
<li><p>Thus, we can think about an estimate as having a distribution that reflects its variation over repeated samples.</p></li>
<li><p>The standard error of an estimate quantifies the variation that we would expect if we could repeat the sampling and modeling that generated the estimate many times.</p></li>
<li><p>Technically, the standard error is measured by the standard deviation of the estimate.</p></li>
<li><p>The standard deviation (<span class="math inline">\(SD(Y)\)</span>) of a variable <span class="math inline">\(Y\)</span> is the square root of the variance, which measures the average (squared) distance between the values of <span class="math inline">\(Y\)</span> and its mean.</p></li>
<li><p>While the SD is used as the natural measure of variability, having the same physical units as <span class="math inline">\(Y\)</span>, the variance is more convenient for mathematical calculations.</p></li>
<li><p>The standard error of an estimate is a function of the sample data, the formulation of the estimate, and the variability of the observations.</p>
<p><code>-</code> A higher standard error implies that we would expect greater variation if we could repeat the sampling and estimation many times.</p>
<p><code>-</code> A sample of 10 randomly selected <span class="math inline">\(Y\)</span> values from a population will produce a higher standard error around an estimate than a sample of <span class="math inline">\(100\)</span> randomly selected <span class="math inline">\(Y\)</span> values.</p></li>
<li><p>The standard error of an estimate is also a function of the model used.</p>
<p><code>-</code> Different models may yield similar estimates but produce different standard errors.</p></li>
<li><p>Confidence intervals place estimates in the context of their standard errors; they are sometimes referred to as interval estimates.</p></li>
<li><p>Like standard errors, confidence intervals are interpreted in terms of what we would expect if we could repeat the sampling and estimation many times.</p></li>
<li><p>In the case of a 95% confidence interval for the mean, the appropriate interpretation is: if the sampling and estimation could be repeated many times, an interval so constructed would include the true mean 95% of the time.</p></li>
<li><p>Interpretation of confidence intervals can be challenging because a specific interval is estimated but it is interpreted in terms of the underlying sampling and estimation process.</p></li>
</ul>
</div>
<div id="conditional-and-marginal-means" class="section level3" number="2.2.7">
<h3><span class="header-section-number">2.2.7</span> Conditional and Marginal Means</h3>
<ul>
<li><p>In health care studies, we are frequently interested in comparisons of outcomes (<span class="math inline">\(Y\)</span>) in sub-populations defined by values of random variables (<span class="math inline">\(X\)</span>).</p></li>
<li><p>The conditional mean of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span></p>
<p><code>-</code> <span class="math inline">\(E(Y|X=x)\)</span>,</p>
<p><code>-</code> The mean for the sub-population with the specific value (<span class="math inline">\(x\)</span>) of the predictor variable (<span class="math inline">\(X\)</span>).</p></li>
</ul>
<p><img src="fig/table2.1.png" /></p>
<ul>
<li><p>Table 2.1 shows estimated total medical expenditures per person (<span class="math inline">\(Y\)</span>) for MEPS 2017 participants according to perceived health status at the start of the year (<span class="math inline">\(X\)</span>), ranging from “Excellent” to “Poor.”</p></li>
<li><p>The table also provides the percentage of respondents falling into each health category corresponding to the size of each sub-population.</p></li>
<li><p>The conditional mean expenditures given “Excellent” health</p>
<p><code>-</code> <span class="math inline">\(E(Y|X=“Excellent”)=1,957\)</span></p></li>
<li><p>The conditional mean expenditures given “Poor” health</p>
<p><code>-</code> <span class="math inline">\(E(Y|X=“Poor”)=22,619\)</span></p></li>
<li><p>Medical expenditures are strongly dependent on perceived health status</p>
<p><code>-</code> Worse health -&gt; higher expenditures.</p>
<p><code>-</code> If a person had “Excellent” health, one would predict very different annual expenditures than if that person had “Poor” health.</p></li>
<li><p>What if we wanted to predict a person’s total medical expenditures without knowing his or her perceived health status?</p>
<p><code>-</code> Reasonable guess: weighted average of the conditional means, with weights given by those percentages</p></li>
<li><p>This average of the conditional means</p>
<p><code>-</code> Called the marginal mean <span class="math inline">\(E(Y)\)</span> because it no longer conditions on <span class="math inline">\(X\)</span>; rather, it averages over the distribution of <span class="math inline">\(X\)</span>.</p>
<p><code>-</code> <span class="math inline">\(E(E(Y|X))=E(Y)\)</span></p></li>
<li><p>In Table 2.1, the marginal mean, calculated by the weighted average, is:
<span class="math display">\[
E(Y) = 1957 \times 0.34 + 3729 \times 0.29 + 6183 \times 0.25 + 11387 \times 0.10 + 22619 \times 0.03 = 5110
\]</span></p></li>
<li><p>This might seem low when compared with the highest expenditures in the table, but this is because persons with better health, who have correspondingly lower expenditures, were more frequent in the sample than persons in poorer health.</p>
<p><code>-</code> This concept of a marginal mean extends also to other statistics, such as the variance, and even to distributions.</p></li>
<li><p>Thus, we may talk about the conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span> if we want to study the sub-population defined by <span class="math inline">\(X=x\)</span>, and, by extension, the marginal distribution of <span class="math inline">\(Y\)</span> if we are interested in the whole population.</p></li>
</ul>
</div>
<div id="joint-and-mixture-distributions" class="section level3" number="2.2.8">
<h3><span class="header-section-number">2.2.8</span> Joint and Mixture Distributions</h3>
<ul>
<li><p>Joint distributions: two or more random variables vary together, e.g., when two outcome variables coevolve in a dependent fashion.</p></li>
<li><p>An example of this phenomenon might be total medical care costs and hospitalizations over a specified interval.</p></li>
<li><p>In cases where we have multiple coevolving outcomes, we do not generally try to estimate the conditional mean of one outcome given another.</p></li>
<li><p>Rather, we model them together as a multivariate outcome.</p></li>
<li><p>Mixture distributions: when one part of the data follows one distribution and the other part follows another distribution.</p>
<p><code>-</code> Two-part models can be used to study a type of mixture distribution for medical expenditures where one part of the sample (a fraction <span class="math inline">\(p\)</span>) has no medical expenditures because they have not accessed the health care system and the other part of the sample (a fraction <span class="math inline">\(1-p\)</span>) has expenditures that follow a specified distribution.</p>
<p><code>-</code> Figure 2.1 shows an extremely right-skewed distribution that also has a high frequency of low values;</p>
<p><code>-</code> This distribution can be modeled as a two-part mixture distribution with a spike at zero reflecting the fraction of the sample incurring zero health care expenditures for the year (see Chap. 6).</p></li>
</ul>
</div>
<div id="variable-transformations" class="section level3" number="2.2.9">
<h3><span class="header-section-number">2.2.9</span> Variable Transformations</h3>
<ul>
<li><p>Transformation of a random variable can play a useful role in a statistical analysis.</p></li>
<li><p>Consider a random variable <span class="math inline">\(Y\)</span> with pdf <span class="math inline">\(f\)</span>, and suppose we have a general function of <span class="math inline">\(Y\)</span>, <span class="math inline">\(G(Y)\)</span>.</p>
<p><code>-</code> Some functions that will be of interest, particularly in studying health care expenditures, include the logarithmic transformation (<span class="math inline">\(G(Y)=log(Y)\)</span>) and the exponential transformation (<span class="math inline">\(G(Y)=exp(Y)\)</span>).</p>
<p><code>-</code> How does applying <span class="math inline">\(G\)</span> change the distribution of <span class="math inline">\(Y\)</span> and its summaries such as the mean, variance, and percentiles?</p>
<p><code>-</code> If <span class="math inline">\(G\)</span> is a linear function, i.e., <span class="math inline">\(G(Y)=aY+b\)</span>, then there are known formulas for the mean and variance of <span class="math inline">\(G(Y)\)</span>; namely, <span class="math inline">\(E[G(Y)]=aE(Y)+b\)</span> and <span class="math inline">\(Var[G(Y)]=a^2Var(Y)\)</span>.</p>
<p><code>-</code> If <span class="math inline">\(G\)</span> is a non-linear function, then it can completely change the distribution of <span class="math inline">\(Y\)</span> and alter its mean and variance in ways that require customized study.</p></li>
<li><p>When <span class="math inline">\(G\)</span> is one of logarithmic or exponential transformations, the following are true:</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>If <span class="math inline">\(M\)</span> is the median of <span class="math inline">\(Y\)</span>, then <span class="math inline">\(G(M)\)</span> is the median of <span class="math inline">\(G(Y)\)</span>, and similarly for other percentiles.</p></li>
<li><p>If <span class="math inline">\(p\)</span> is the probability that <span class="math inline">\(Y\)</span> falls in an interval <span class="math inline">\((a, b)\)</span>, then <span class="math inline">\(p\)</span> is also the probability that <span class="math inline">\(G(Y)\)</span> falls in the interval <span class="math inline">\((G(a), G(b))\)</span>.</p></li>
</ol>
<ul>
<li><p>Thus both percentiles and probability are translated by these transformations.</p>
<p><code>-</code> In fact, (1) and (2) are true for any increasing transformation.</p></li>
</ul>
</div>
</div>
<div id="common-statistical-distributions-and-concepts" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Common Statistical Distributions and Concepts</h2>
<div id="the-bernoulli-and-binomial-distributions-for-binary-outcomes" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> The Bernoulli and Binomial Distributions for Binary Outcomes</h3>
<ul>
<li><p>Binary health care outcomes: whether a patient is re-admitted after surgery.</p></li>
<li><p>The Bernoulli distribution is the family of distributions for a binary outcome <span class="math inline">\(Y\)</span> that can take on values 0 and 1.</p>
<p><code>-</code> Refer to these as negative and positive outcomes, respectively, reflecting non-occurrence or occurrence of an event of interest.</p></li>
<li><p>Bernoulli Probability mass function (pmf)</p></li>
</ul>
<p><span class="math display">\[P(x) = p^x(1-p)^{1-x},\quad x = 0,1 \]</span></p>
<p><span class="math inline">\(p\)</span> : sucess probability, i.e. <span class="math inline">\(P(X=1) = p\)</span>, <span class="math inline">\(E(X) = p\)</span>, <span class="math inline">\(Var(X) = p(1-p)\)</span>.</p>
<ul>
<li><p>Binary regression analysis focuses on <span class="math inline">\(P(Y=1)\)</span>, the probability that <span class="math inline">\(Y\)</span> will take the value 1, and attempts to identify factors <span class="math inline">\(X\)</span> that are associated with that probability.</p>
<p><code>-</code> Example: studying the factors that are associated with higher versus lower risks of re-admission.</p>
<p><code>-</code> When the Bernoulli distribution is used, it turns out that <span class="math inline">\(P(Y=1)\)</span> is in fact the mean of <span class="math inline">\(Y\)</span> ; thus, the problem of learning about the correlates <span class="math inline">\(X\)</span> of <span class="math inline">\(P(Y=1)\)</span> is essentially the same as the problem of modeling the conditional mean <span class="math inline">\(E(Y|X)\)</span>.</p></li>
<li><p>Predicting a binary outcome is a version of a classification problem in which observations fall into two classes and the objective is to identify the combination of factors <span class="math inline">\(X\)</span> that best predicts class membership.</p>
<p><code>-</code> Binary prediction problem is prevalent in the statistical learning literature, which has its own collection of algorithms for classification problems.</p></li>
<li><p>Some important features of the Bernoulli distribution</p>
<p><code>-</code> Even though there are two outcomes in the binary setting, the frequency distribution of the outcome is completely determined by the probability of one of the outcomes, conventionally taken to be <span class="math inline">\(p=P(Y=1)\)</span>, because the probability of the alternative outcome is <span class="math inline">\(1-p\)</span>.</p>
<p><code>-</code> Classical statistical inference is concerned with identifying predictors <span class="math inline">\(X\)</span> associated with the likelihood of <span class="math inline">\(Y\)</span> taking the value 1 rather than 0.</p>
<p><code>-</code> The odds of <span class="math inline">\(Y\)</span> being 1 (rather than zero) are written as <span class="math inline">\(p/(1-p)\)</span>.</p>
<p><code>-</code> Logistic regression identifies predictors of higher versus lower odds of <span class="math inline">\(Y\)</span> taking the value 1.</p>
<p><code>-</code> The mean of <span class="math inline">\(Y\)</span>, <span class="math inline">\(E(Y)\)</span>, is p. </p>
<p><code>-</code> Since the range of <span class="math inline">\(Y\)</span> is from zero to one, the mean is somewhere in between.</p>
<p><code>-</code> The variance of <span class="math inline">\(Y\)</span>, <span class="math inline">\(Var(Y)\)</span>, is <span class="math inline">\(p(1-p)\)</span>.</p>
<p><code>-</code> Thus, the variance is not independent of the mean as is the case with the normal distribution.</p>
<p><code>-</code> Instead, there is a very specific relationship between the mean and the variance.</p></li>
<li><p>When we have a set of <span class="math inline">\(n\)</span> independent Bernoulli variables, the total number of positive outcomes has a binomial distribution, and this total has mean <span class="math inline">\(np\)</span> and variance <span class="math inline">\(np(1-p)\)</span>.</p>
<p><code>-</code> Thus, the total number of re-admissions after surgery at a specific hospital might be binomial, where <span class="math inline">\(n\)</span> is the number of surgeries performed at that hospital.</p></li>
<li><p>Probability mass function</p></li>
</ul>
<p><span class="math display">\[ P(X = x) = \binom{n}{x}p^x(1-p)^{n-x}, \quad x=0,1,...,n\]</span></p>
<p><img src="fig/fig2.2.png" /></p>
<ul>
<li>Figure 2.2 shows several binomial distributions with different <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>.</li>
</ul>
</div>
<div id="pmf-plot" class="section level3" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> pmf plot</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="chapter2.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="chapter2.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1-3"><a href="chapter2.html#cb1-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.8</span>)</span>
<span id="cb1-4"><a href="chapter2.html#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="chapter2.html#cb1-5" aria-hidden="true" tabindex="-1"></a>ps10 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">10</span>, p[<span class="dv">1</span>]) ,<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">10</span>, p[<span class="dv">2</span>]), <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">10</span>, p[<span class="dv">3</span>]))</span>
<span id="cb1-6"><a href="chapter2.html#cb1-6" aria-hidden="true" tabindex="-1"></a>ps30 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="dv">30</span>, p[<span class="dv">1</span>]) ,<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="dv">30</span>, p[<span class="dv">2</span>]), <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="dv">30</span>, p[<span class="dv">3</span>]))</span>
<span id="cb1-7"><a href="chapter2.html#cb1-7" aria-hidden="true" tabindex="-1"></a>ps50 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">50</span>, <span class="dv">50</span>, p[<span class="dv">1</span>]) ,<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">50</span>, <span class="dv">50</span>, p[<span class="dv">2</span>]), <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">50</span>, <span class="dv">50</span>, p[<span class="dv">3</span>]))</span>
<span id="cb1-8"><a href="chapter2.html#cb1-8" aria-hidden="true" tabindex="-1"></a>ps100 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">100</span>, p[<span class="dv">1</span>]) ,<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">100</span>, p[<span class="dv">2</span>]), <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">100</span>, p[<span class="dv">3</span>]))</span>
<span id="cb1-9"><a href="chapter2.html#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="chapter2.html#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="chapter2.html#cb1-11" aria-hidden="true" tabindex="-1"></a>data10 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">fx  =</span> ps10, <span class="at">p =</span> <span class="fu">rep</span>(p, <span class="at">each =</span> <span class="dv">11</span>))</span>
<span id="cb1-12"><a href="chapter2.html#cb1-12" aria-hidden="true" tabindex="-1"></a>data30 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="at">fx  =</span> ps30, <span class="at">p =</span> <span class="fu">rep</span>(p, <span class="at">each =</span> <span class="dv">31</span>))</span>
<span id="cb1-13"><a href="chapter2.html#cb1-13" aria-hidden="true" tabindex="-1"></a>data50 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">50</span>, <span class="at">fx  =</span> ps50, <span class="at">p =</span> <span class="fu">rep</span>(p, <span class="at">each =</span> <span class="dv">51</span>))</span>
<span id="cb1-14"><a href="chapter2.html#cb1-14" aria-hidden="true" tabindex="-1"></a>data100 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="at">fx  =</span> ps100, <span class="at">p =</span> <span class="fu">rep</span>(p, <span class="at">each =</span> <span class="dv">101</span>))</span>
<span id="cb1-15"><a href="chapter2.html#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="chapter2.html#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="chapter2.html#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="chapter2.html#cb1-18" aria-hidden="true" tabindex="-1"></a>pmf10 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data10, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(x), <span class="at">y =</span> fx, <span class="at">col =</span> <span class="fu">as.factor</span>(p), <span class="at">group =</span> p)) <span class="sc">+</span></span>
<span id="cb1-19"><a href="chapter2.html#cb1-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb1-20"><a href="chapter2.html#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb1-21"><a href="chapter2.html#cb1-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Binomial Dist. when n = 10&quot;</span>,</span>
<span id="cb1-22"><a href="chapter2.html#cb1-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb1-23"><a href="chapter2.html#cb1-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb1-24"><a href="chapter2.html#cb1-24" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb1-25"><a href="chapter2.html#cb1-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb1-26"><a href="chapter2.html#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="chapter2.html#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="chapter2.html#cb1-28" aria-hidden="true" tabindex="-1"></a>pmf30 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data30, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> fx, <span class="at">col =</span> <span class="fu">as.factor</span>(p), <span class="at">group =</span> p)) <span class="sc">+</span></span>
<span id="cb1-29"><a href="chapter2.html#cb1-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb1-30"><a href="chapter2.html#cb1-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb1-31"><a href="chapter2.html#cb1-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Binomial Dist. when n = 30&quot;</span>,</span>
<span id="cb1-32"><a href="chapter2.html#cb1-32" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb1-33"><a href="chapter2.html#cb1-33" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb1-34"><a href="chapter2.html#cb1-34" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb1-35"><a href="chapter2.html#cb1-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb1-36"><a href="chapter2.html#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="chapter2.html#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="chapter2.html#cb1-38" aria-hidden="true" tabindex="-1"></a>pmf50 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data50, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> fx, <span class="at">col =</span> <span class="fu">as.factor</span>(p), <span class="at">group =</span> p)) <span class="sc">+</span></span>
<span id="cb1-39"><a href="chapter2.html#cb1-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb1-40"><a href="chapter2.html#cb1-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb1-41"><a href="chapter2.html#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Binomial Dist. when n = 50&quot;</span>,</span>
<span id="cb1-42"><a href="chapter2.html#cb1-42" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb1-43"><a href="chapter2.html#cb1-43" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb1-44"><a href="chapter2.html#cb1-44" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb1-45"><a href="chapter2.html#cb1-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb1-46"><a href="chapter2.html#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="chapter2.html#cb1-47" aria-hidden="true" tabindex="-1"></a>pmf100 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data100, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> fx, <span class="at">col =</span> <span class="fu">as.factor</span>(p), <span class="at">group =</span> p)) <span class="sc">+</span></span>
<span id="cb1-48"><a href="chapter2.html#cb1-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb1-49"><a href="chapter2.html#cb1-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb1-50"><a href="chapter2.html#cb1-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Binomial Dist. when n = 100&quot;</span>,</span>
<span id="cb1-51"><a href="chapter2.html#cb1-51" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb1-52"><a href="chapter2.html#cb1-52" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb1-53"><a href="chapter2.html#cb1-53" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb1-54"><a href="chapter2.html#cb1-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb1-55"><a href="chapter2.html#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="chapter2.html#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(pmf10, pmf30, pmf50, pmf100, <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-1-1.png" width="1440" /></p>
</div>
<div id="comparison-with-simulated-value" class="section level3" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> comparison with simulated value</h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="chapter2.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:gridExtra&#39;:
## 
##     combine</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="chapter2.html#cb7-1" aria-hidden="true" tabindex="-1"></a>simul <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">10000</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.6</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb7-2"><a href="chapter2.html#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(simul) <span class="ot">&lt;-</span> <span class="st">&quot;simul&quot;</span></span>
<span id="cb7-3"><a href="chapter2.html#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="chapter2.html#cb7-4" aria-hidden="true" tabindex="-1"></a>simul1 <span class="ot">&lt;-</span> simul <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(simul) <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">prob =</span> n<span class="sc">/</span><span class="dv">10000</span>)</span>
<span id="cb7-5"><a href="chapter2.html#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="chapter2.html#cb7-6" aria-hidden="true" tabindex="-1"></a>sim_plot <span class="ot">&lt;-</span> simul1 <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> simul, <span class="at">y =</span> prob)) <span class="sc">+</span> </span>
<span id="cb7-7"><a href="chapter2.html#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb7-8"><a href="chapter2.html#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;10000 trials ; Simuation of Bionomial Dist. with n =10, p = 0.6&quot;</span>)</span>
<span id="cb7-9"><a href="chapter2.html#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="chapter2.html#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="chapter2.html#cb7-11" aria-hidden="true" tabindex="-1"></a>t_prob <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">y =</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="fl">0.6</span>))</span>
<span id="cb7-12"><a href="chapter2.html#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="chapter2.html#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="chapter2.html#cb7-14" aria-hidden="true" tabindex="-1"></a>sim_plot <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">data =</span> t_prob, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb7-15"><a href="chapter2.html#cb7-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> t_prob,  <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li><p>The binomial distribution only results from a set of Bernoulli variables if the total number <span class="math inline">\(n\)</span> is fixed, and only if the Bernoulli variables are independent.</p></li>
<li><p>If we are considering the number of re-admissions given the total number of surgeries performed at a specific hospital, the requirement of independence may be violated by the clustering of patients within surgeons;</p>
<p><code>-</code> Patients treated by the same surgeon may be more similar to one another in terms of their risk of re-admission than patients treated by other surgeons.</p>
<p><code>-</code> This kind of clustering induces correlation between patients treated by the same surgeon.</p></li>
</ul>
</div>
<div id="the-multinomial-distribution-for-categorical-outcomes" class="section level3" number="2.3.4">
<h3><span class="header-section-number">2.3.4</span> The Multinomial Distribution for Categorical Outcomes</h3>
<ul>
<li><p>The multinomial distribution: generalization of the binomial to the setting where there are multiple types of outcomes beyond just positive or negative.</p>
<p><code>-</code> Example 1: treatment choice when there are more than two treatments, such as surgery, radiation, or hormonal therapy for cancer.</p>
<p><code>-</code> Example 2: responses to a survey question about health status, with responses being on a five-point scale.</p></li>
<li><p>In the first example, we would describe the outcome as multinomial with three (unordered) categories.</p></li>
<li><p>In the second example, we could describe the outcome as multinomial with five (ordered) categories.</p></li>
<li><p>probability mass function</p></li>
</ul>
<p><span class="math display">\[P(x_1, x_2, ... , x_k \; ; \; n_1, n_2, ..., n_k) = \frac{n!}{x_1!x_2! \cdots x_k!} p_{1}^{x_1}p_{2}^{x_2} \cdots p_{k}^{x_k}\]</span></p>
<p><span class="math inline">\(\sum_{i=1}^{k} X_i = n\)</span>, <span class="math inline">\(E(X_i) \; =\;np_i\)</span>, <span class="math inline">\(Var(X_i)\;=\;np_i(1-p_i)\)</span></p>
<ul>
<li><p>As in the binomial setting, attention focuses on the probabilities or frequencies of each category or, equivalently, the probability that <span class="math inline">\(Y\)</span> falls into each category.</p></li>
<li><p>In the binary setting, we considered <span class="math inline">\(p\)</span> and <span class="math inline">\(1-p\)</span>; in the multinomial setting, we have multiple pass many as the possible values of <span class="math inline">\(Y\)</span>.</p>
<p><code>-</code> However, the probabilities must add up to 1 because each observation must fall into one of the categories.</p>
<p><code>-</code> Thus, in the case of <span class="math inline">\(K\)</span> categories, the distribution has <span class="math inline">\(K-1\)</span> parameters.</p>
<p><code>-</code> The multinomial distribution of self-reported health status on a five-point scale would have four independent categories.</p></li>
<li><p>Multinomial regression is concerned with identifying the factors that predict the likelihood of an outcome being in one category rather than another.</p>
<p><code>-</code> Example: studying how a diabetes diagnosis impacts self-reported health, we would want to understand how <span class="math inline">\(P=(Y=k)\)</span>, the probability that <span class="math inline">\(Y\)</span> will take on category <span class="math inline">\(k\)</span>, changes depending on diabetes status.</p></li>
</ul>
</div>
<div id="the-poisson-and-negative-binomial-distributions-for-counts" class="section level3" number="2.3.5">
<h3><span class="header-section-number">2.3.5</span> The Poisson and Negative Binomial Distributions for Counts</h3>
<ul>
<li><p>In the study of health care outcomes, we often study counts:</p>
<p><code>-</code> Numbers of doctor visits</p>
<p><code>-</code> Numbers of prescriptions filled</p>
<p><code>-</code> Numbers of procedures of a specific type performed in a facility over a month or a year.</p></li>
<li><p>The most basic parametric distribution for count data</p>
<p><code>-</code> Poisson distribution</p></li>
<li><p>The Poisson distribution: probability that a count of events in a given time interval will be zero, one, two, and so on.</p>
<p><code>-</code> Events occur at a constant rate in a memoryless fashion (i.e., the chance that an event will occur within a specified interval is independent of the time elapsed since the last event).</p>
<p><code>-</code> The Poisson distribution is the distribution of the number of such events in a specified time interval.</p></li>
<li><p>Probability mass function</p></li>
</ul>
<p><span class="math display">\[P(x) =  \frac{e^{-\lambda} \; \lambda^x}{x!}, \quad x= 0,1,2, \ldots\]</span></p>
<p><span class="math inline">\(\sum P(x) = 1\)</span>, <span class="math inline">\(E(X) = \lambda\)</span>, <span class="math inline">\(var(X) = \lambda\)</span></p>
<p><img src="fig/fig2.3.png" /></p>
<ul>
<li>Figure 2.3 shows several Poisson distributions with different means.</li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="chapter2.html#cb8-1" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">21</span>), <span class="fu">rep</span>(<span class="dv">4</span>, <span class="dv">21</span>), <span class="fu">rep</span>(<span class="dv">10</span>, <span class="dv">21</span>))</span>
<span id="cb8-2"><a href="chapter2.html#cb8-2" aria-hidden="true" tabindex="-1"></a>pois <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">lambda =</span> <span class="dv">1</span>), <span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">lambda =</span> <span class="dv">4</span>), <span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">lambda =</span> <span class="dv">10</span>))</span>
<span id="cb8-3"><a href="chapter2.html#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="chapter2.html#cb8-4" aria-hidden="true" tabindex="-1"></a>data_pois <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">lambda =</span> lambda, <span class="at">x =</span> <span class="fu">rep</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">3</span>), <span class="at">fx =</span> pois)</span>
<span id="cb8-5"><a href="chapter2.html#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="chapter2.html#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="chapter2.html#cb8-7" aria-hidden="true" tabindex="-1"></a>data_pois <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> pois, <span class="at">col =</span> <span class="fu">as.factor</span>(lambda), <span class="at">group =</span> lambda)) <span class="sc">+</span></span>
<span id="cb8-8"><a href="chapter2.html#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb8-9"><a href="chapter2.html#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb8-10"><a href="chapter2.html#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;Poisson Dist. when &quot;</span>, lambda, <span class="st">&quot; = 1, 4, 10&quot;</span>)),</span>
<span id="cb8-11"><a href="chapter2.html#cb8-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb8-12"><a href="chapter2.html#cb8-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb8-13"><a href="chapter2.html#cb8-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb8-14"><a href="chapter2.html#cb8-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name =</span> <span class="fu">expression</span>(lambda))</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li>comparison with simulated value</li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="chapter2.html#cb9-1" aria-hidden="true" tabindex="-1"></a>simul_pois <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="dv">10000</span>, <span class="at">lambda =</span> <span class="dv">5</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb9-2"><a href="chapter2.html#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(simul_pois) <span class="ot">&lt;-</span> <span class="st">&quot;simul&quot;</span></span>
<span id="cb9-3"><a href="chapter2.html#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="chapter2.html#cb9-4" aria-hidden="true" tabindex="-1"></a>simul1_pois <span class="ot">&lt;-</span> simul_pois <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(simul) <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">prob =</span> n<span class="sc">/</span><span class="dv">10000</span>)</span>
<span id="cb9-5"><a href="chapter2.html#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="chapter2.html#cb9-6" aria-hidden="true" tabindex="-1"></a>sim_pois_plot <span class="ot">&lt;-</span> simul1_pois <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> simul, <span class="at">y =</span> prob)) <span class="sc">+</span> </span>
<span id="cb9-7"><a href="chapter2.html#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>,  <span class="at">fill =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb9-8"><a href="chapter2.html#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">20</span>)) <span class="sc">+</span></span>
<span id="cb9-9"><a href="chapter2.html#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;10000 trials ; Simuation of Poisson Dist. with lambda = 5&quot;</span>)</span>
<span id="cb9-10"><a href="chapter2.html#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="chapter2.html#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="chapter2.html#cb9-12" aria-hidden="true" tabindex="-1"></a>t_prob_pois <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">y =</span> <span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb9-13"><a href="chapter2.html#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="chapter2.html#cb9-14" aria-hidden="true" tabindex="-1"></a>sim_pois_plot <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">data =</span> t_prob_pois, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb9-15"><a href="chapter2.html#cb9-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> t_prob_pois,  <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li><p>One important feature of the Poisson distribution</p>
<p><code>-</code> Its mean and variance are equal.</p>
<p><code>-</code> This, together with the basic assumptions upon which it is based, makes the Poisson distribution highly restrictive for modeling count health data.</p></li>
<li><p>In practice, counts of medical events and procedures almost never satisfy the assumptions that generate a Poisson distribution.</p>
<p><code>-</code> Most often, the variance of a count outcome is considerably larger than its mean value.</p></li>
</ul>
<p><img src="fig/fig2.4.png" /></p>
<ul>
<li><p>Figure 2.4 is a histogram of outpatient visits among participants who reported a previous diagnosis of a stroke in the MEPS 2017 data.</p></li>
<li><p>The histogram for the observed data is graphed next to a histogram reflecting a Poisson distribution with the same average number of visits (15).</p></li>
<li><p>The observed data histogram shows higher frequencies at the extremes of the range, with considerably more patients with no visits and a longer right tail than the Poisson data histogram.</p></li>
<li><p>In fact, the variance of the observed number of visits is 24, more than 15 times greater than the observed mean. We say that the observed number of visits is overdispersed.</p></li>
<li><p>When a count outcome is overdispersed:</p>
<p><code>-</code> we look to an alternative model for count data that accommodate a variance that is larger than the mean.</p>
<p><code>-</code> The negative binomial distribution provides such an alternative.</p>
<p><code>-</code> Like the Poisson, it is appropriate for discrete, non-negative outcomes, but, unlike the Poisson, its variance always exceeds its mean.</p></li>
<li><p>The mechanism of overdispersion that leads to the negative binomial distribution arises from considering that individuals are heterogeneous in their count data outcomes in a manner that goes beyond observed predictors.</p></li>
<li><p>Probability mass function</p></li>
</ul>
<p><span class="math display">\[ P(Y = y) = P(y \; failures \;in \; X_1,\ldots, X_{r+y-1} \; and \; X_{r+y+1} = 1) \\\\ = \binom{r+y-1}{r-1}p^{r}(1-p)\; , \; y = 0,1,2,\ldots\]</span></p>
<p><span class="math inline">\(E(Y) = \frac{r(1-p)}{p}\)</span>, <span class="math inline">\(Var(Y) = \frac{r(1-p)}{p^2}\)</span></p>
</div>
<div id="pmf-plot-1" class="section level3" number="2.3.6">
<h3><span class="header-section-number">2.3.6</span> pmf plot</h3>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="chapter2.html#cb10-1" aria-hidden="true" tabindex="-1"></a>p_nb <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.8</span>)</span>
<span id="cb10-2"><a href="chapter2.html#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="chapter2.html#cb10-3" aria-hidden="true" tabindex="-1"></a>ps1_nb <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">1</span>, p[<span class="dv">1</span>]) ,<span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">1</span>, p[<span class="dv">2</span>]), <span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">1</span>, p[<span class="dv">3</span>]))</span>
<span id="cb10-4"><a href="chapter2.html#cb10-4" aria-hidden="true" tabindex="-1"></a>ps3_nb <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">3</span>, p[<span class="dv">1</span>]) ,<span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">3</span>, p[<span class="dv">2</span>]), <span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">3</span>, p[<span class="dv">3</span>]))</span>
<span id="cb10-5"><a href="chapter2.html#cb10-5" aria-hidden="true" tabindex="-1"></a>ps5_nb <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">5</span>, p[<span class="dv">1</span>]) ,<span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">5</span>, p[<span class="dv">2</span>]), <span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">5</span>, p[<span class="dv">3</span>]))</span>
<span id="cb10-6"><a href="chapter2.html#cb10-6" aria-hidden="true" tabindex="-1"></a>ps10_nb <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">10</span>, p[<span class="dv">1</span>]) ,<span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">10</span>, p[<span class="dv">2</span>]), <span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">10</span>, p[<span class="dv">3</span>]))</span>
<span id="cb10-7"><a href="chapter2.html#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="chapter2.html#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="chapter2.html#cb10-9" aria-hidden="true" tabindex="-1"></a>data1_nb <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">fx  =</span> ps1_nb, <span class="at">p =</span> <span class="fu">rep</span>(p, <span class="at">each =</span> <span class="dv">21</span>))</span>
<span id="cb10-10"><a href="chapter2.html#cb10-10" aria-hidden="true" tabindex="-1"></a>data3_nb <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">fx  =</span> ps3_nb, <span class="at">p =</span> <span class="fu">rep</span>(p, <span class="at">each =</span> <span class="dv">21</span>))</span>
<span id="cb10-11"><a href="chapter2.html#cb10-11" aria-hidden="true" tabindex="-1"></a>data5_nb <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">fx  =</span> ps5_nb, <span class="at">p =</span> <span class="fu">rep</span>(p, <span class="at">each =</span> <span class="dv">21</span>))</span>
<span id="cb10-12"><a href="chapter2.html#cb10-12" aria-hidden="true" tabindex="-1"></a>data10_nb <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">fx  =</span> ps10_nb, <span class="at">p =</span> <span class="fu">rep</span>(p, <span class="at">each =</span> <span class="dv">21</span>))</span>
<span id="cb10-13"><a href="chapter2.html#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="chapter2.html#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="chapter2.html#cb10-15" aria-hidden="true" tabindex="-1"></a>pmf1_nb <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data1_nb, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(x), <span class="at">y =</span> fx, <span class="at">col =</span> <span class="fu">as.factor</span>(p), <span class="at">group =</span> p)) <span class="sc">+</span></span>
<span id="cb10-16"><a href="chapter2.html#cb10-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb10-17"><a href="chapter2.html#cb10-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb10-18"><a href="chapter2.html#cb10-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;when r = 1 and p = 0.3, 0.5, 0.8&quot;</span>,</span>
<span id="cb10-19"><a href="chapter2.html#cb10-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb10-20"><a href="chapter2.html#cb10-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb10-21"><a href="chapter2.html#cb10-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb10-22"><a href="chapter2.html#cb10-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb10-23"><a href="chapter2.html#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="chapter2.html#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="chapter2.html#cb10-25" aria-hidden="true" tabindex="-1"></a>pmf3_nb <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data3_nb, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> fx, <span class="at">col =</span> <span class="fu">as.factor</span>(p), <span class="at">group =</span> p)) <span class="sc">+</span></span>
<span id="cb10-26"><a href="chapter2.html#cb10-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb10-27"><a href="chapter2.html#cb10-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb10-28"><a href="chapter2.html#cb10-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;when r = 3 and p = 0.3, 0.5, 0.8&quot;</span>,</span>
<span id="cb10-29"><a href="chapter2.html#cb10-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb10-30"><a href="chapter2.html#cb10-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb10-31"><a href="chapter2.html#cb10-31" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb10-32"><a href="chapter2.html#cb10-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb10-33"><a href="chapter2.html#cb10-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-34"><a href="chapter2.html#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="chapter2.html#cb10-35" aria-hidden="true" tabindex="-1"></a>pmf5_nb <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data5_nb, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> fx, <span class="at">col =</span> <span class="fu">as.factor</span>(p), <span class="at">group =</span> p)) <span class="sc">+</span></span>
<span id="cb10-36"><a href="chapter2.html#cb10-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb10-37"><a href="chapter2.html#cb10-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb10-38"><a href="chapter2.html#cb10-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;when r = 5 and p = 0.3, 0.5, 0.8&quot;</span>,</span>
<span id="cb10-39"><a href="chapter2.html#cb10-39" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb10-40"><a href="chapter2.html#cb10-40" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb10-41"><a href="chapter2.html#cb10-41" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb10-42"><a href="chapter2.html#cb10-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb10-43"><a href="chapter2.html#cb10-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-44"><a href="chapter2.html#cb10-44" aria-hidden="true" tabindex="-1"></a>pmf10_nb <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data10_nb, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> fx, <span class="at">col =</span> <span class="fu">as.factor</span>(p), <span class="at">group =</span> p)) <span class="sc">+</span></span>
<span id="cb10-45"><a href="chapter2.html#cb10-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb10-46"><a href="chapter2.html#cb10-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb10-47"><a href="chapter2.html#cb10-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;when r = 10 and p = 0.3, 0.5, 0.8&quot;</span>,</span>
<span id="cb10-48"><a href="chapter2.html#cb10-48" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb10-49"><a href="chapter2.html#cb10-49" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb10-50"><a href="chapter2.html#cb10-50" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;p&quot;</span>) <span class="sc">+</span> </span>
<span id="cb10-51"><a href="chapter2.html#cb10-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb10-52"><a href="chapter2.html#cb10-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-53"><a href="chapter2.html#cb10-53" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(pmf1_nb, pmf3_nb, pmf5_nb, pmf10_nb, <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">top =</span> ggpubr<span class="sc">::</span><span class="fu">text_grob</span>(<span class="at">label =</span> <span class="st">&quot;Negative Binomial Dist.&quot;</span>, <span class="at">size =</span> <span class="dv">20</span>))</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-5-1.png" width="1440" /></p>
<ul>
<li>When r = 1, <strong>Geometric Distribution</strong></li>
</ul>
</div>
<div id="comparison-with-simulated-value-1" class="section level3" number="2.3.7">
<h3><span class="header-section-number">2.3.7</span> comparison with simulated value</h3>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="chapter2.html#cb11-1" aria-hidden="true" tabindex="-1"></a>simul_nb <span class="ot">&lt;-</span> <span class="fu">rnbinom</span>(<span class="dv">10000</span>, <span class="dv">7</span>, <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb11-2"><a href="chapter2.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(simul_nb) <span class="ot">&lt;-</span> <span class="st">&quot;simul&quot;</span></span>
<span id="cb11-3"><a href="chapter2.html#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="chapter2.html#cb11-4" aria-hidden="true" tabindex="-1"></a>simul1_nb <span class="ot">&lt;-</span> simul_nb <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(simul) <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">prob =</span> n<span class="sc">/</span><span class="dv">10000</span>)</span>
<span id="cb11-5"><a href="chapter2.html#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="chapter2.html#cb11-6" aria-hidden="true" tabindex="-1"></a>sim_nb_plot <span class="ot">&lt;-</span> simul1_nb <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> simul, <span class="at">y =</span> prob)) <span class="sc">+</span> </span>
<span id="cb11-7"><a href="chapter2.html#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>,  <span class="at">fill =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb11-8"><a href="chapter2.html#cb11-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">20</span>)) <span class="sc">+</span></span>
<span id="cb11-9"><a href="chapter2.html#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;10000 trials ; Simuation of Nbionmial Dist. with r = 7, p = 0.5&quot;</span>)</span>
<span id="cb11-10"><a href="chapter2.html#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="chapter2.html#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="chapter2.html#cb11-12" aria-hidden="true" tabindex="-1"></a>t_prob_nb <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">y =</span> <span class="fu">dnbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">7</span>, <span class="fl">0.5</span>))</span>
<span id="cb11-13"><a href="chapter2.html#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="chapter2.html#cb11-14" aria-hidden="true" tabindex="-1"></a>sim_nb_plot <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">data =</span> t_prob_nb, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb11-15"><a href="chapter2.html#cb11-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> t_prob_nb,  <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li><p>When modeling outpatient visits, for example, one could imagine that each individual has a latent susceptibility that relates to the frequency with which they seek care in the outpatient setting.</p></li>
<li><p>Those individuals with low susceptibility would be expected to seek care rarely and have few or no outpatient visits, and those with high susceptibility would have many visits.</p></li>
<li><p>Formally, we can think of each person having a Poisson-distributed count outcome <span class="math inline">\(Y\)</span> , but, rather than everyone having the same mean <span class="math inline">\(\mu\)</span>, each individual, indexed by <span class="math inline">\(i\)</span>, has their own mean, which may be written as <span class="math inline">\(\mu r_i\)</span>.</p></li>
<li><p>Here, <span class="math inline">\(i\)</span> indexes individuals and <span class="math inline">\(r_i\)</span> is a latent, individual-specific multiplier, sometimes called a frailty, that modifies the overall mean and personalizes it.</p></li>
<li><p>We say that a person’s conditional mean given <span class="math inline">\(r_i\)</span> is <span class="math inline">\(\mu r_i\)</span>, and since the count outcome for person <span class="math inline">\(i\)</span> is Poisson distributed, the conditional variance for person <span class="math inline">\(i\)</span> is also <span class="math inline">\(\mu r_i\)</span>.</p></li>
<li><p>These are conditional means and variances since they are subject-specific and differ among individuals in the population.</p></li>
<li><p>They incorporate the notion of individual heterogeneity and add variability to the marginal distribution of <span class="math inline">\(Y\)</span>.</p></li>
<li><p>The negative binomial arises as the marginal distribution of <span class="math inline">\(Y\)</span> under a very specific distribution for the <span class="math inline">\(r_i\)</span>.</p></li>
<li><p>It turns out that if the <span class="math inline">\(r_i\)</span>s have a gamma distribution (described below) with mean 1 and variance <span class="math inline">\(\alpha\)</span>, then the marginal distribution of <span class="math inline">\(Y\)</span> is negative binomial with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\mu(1+\alpha \mu)\)</span>.</p></li>
<li><p>Mathematically, this result shows that latent heterogeneity in a Poisson setting will generate overdispersion and, under specific assumptions about the form of the heterogeneity, will produce a negative binomial rather than a Poisson distribution.</p></li>
<li><p>In practice, the negative binomial is often preferred over the Poisson for modeling count data outcomes due to its greater flexibility and ability to accommodate overdispersion. It should be remembered that the negative binomial model for count data is also quite specific in that it captures a particular mechanism—between-individual heterogeneity—for the overdispersion and makes specific assumptions about how this heterogeneity manifests in the population.</p></li>
<li><p>The notion that between-individual heterogeneity might lead to inflation of overall variance arises over and over again in the analysis of health outcomes.</p></li>
<li><p>The representation of this heterogeneity via a latent, individual-specific factor that varies across individuals according to a specified distribution is the foundation for random effects and frailty models in the settings of clustered, longitudinal, and failure-time outcomes.</p></li>
<li><p>Mathematical details aside, the way in which this additional heterogeneity affects overall variability is the same across settings. Allowing individuals to deviate from a common mean outcome in a personalized way changes the spread of the marginal distribution of the outcome.</p></li>
<li><p>The histogram of the outcome expands to reflect a greater frequency of more extreme outcomes (from individuals with very low and very high frailties) and leads to greater mass in the tails of the distribution as illustrated in the left panel of Fig. 2.4.</p></li>
<li><p>This is what we mean by overdispersion relative to the Poisson distribution.</p></li>
</ul>
</div>
<div id="the-normal-distribution-for-continuous-outcomes" class="section level3" number="2.3.8">
<h3><span class="header-section-number">2.3.8</span> The Normal Distribution for Continuous Outcomes</h3>
<ul>
<li><p>Normal distribution</p>
<p><code>-</code> Symmetric bell shape</p>
<p><code>-</code> Two parameters: mean <span class="math inline">\(\mu\)</span> (center of symmetry), standard deviation <span class="math inline">\(\sigma\)</span> (measure of the variability of the values around the mean)</p></li>
</ul>
<p>*Probability density funciton</p>
<p><span class="math display">\[ f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}, \; -\infty &lt; x &lt; \infty, \; -\infty&lt; \mu&lt;\infty,\; \sigma^2 &gt; 0\]</span></p>
<p><span class="math inline">\(E(X) = \mu\)</span>, <span class="math inline">\(Var(X) = \sigma^2\)</span></p>
<p><img src="fig/fig2.5.png" /></p>
<ul>
<li><p>Figure 2.5 shows several normal distributions with mean <span class="math inline">\(\mu=0\)</span> and different values for the SD <span class="math inline">\(\sigma\)</span>.</p>
<p><code>-</code> About 67% of the observations occur within one SD and about 95% occur within 2 SDs of the mean.</p></li>
<li><p>pdf plot</p></li>
</ul>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="chapter2.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>)), <span class="fu">aes</span>(x)) <span class="sc">+</span></span>
<span id="cb12-2"><a href="chapter2.html#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;N(0,1)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb12-3"><a href="chapter2.html#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;N(-2,1)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb12-4"><a href="chapter2.html#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">2</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;N(2,1)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb12-5"><a href="chapter2.html#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">name =</span> <span class="st">&quot;x&quot;</span>, <span class="at">breaks =</span> <span class="sc">-</span><span class="dv">5</span><span class="sc">:</span><span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb12-6"><a href="chapter2.html#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">colour =</span> <span class="st">&quot;Dist.&quot;</span>) <span class="sc">+</span></span>
<span id="cb12-7"><a href="chapter2.html#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>( <span class="st">&quot;Normal Dist. when &quot;</span>, mu, <span class="st">&quot; = -2, 0, 2&quot;</span>)))</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="chapter2.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>)), <span class="fu">aes</span>(x)) <span class="sc">+</span></span>
<span id="cb13-2"><a href="chapter2.html#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;N(0,1)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb13-3"><a href="chapter2.html#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">2</span>)), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;N(0,2)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb13-4"><a href="chapter2.html#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">2</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;N(0,4)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb13-5"><a href="chapter2.html#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">name =</span> <span class="st">&quot;x&quot;</span>, <span class="at">breaks =</span> <span class="sc">-</span><span class="dv">5</span><span class="sc">:</span><span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb13-6"><a href="chapter2.html#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">colour =</span> <span class="st">&quot;Dist.&quot;</span>) <span class="sc">+</span></span>
<span id="cb13-7"><a href="chapter2.html#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>( <span class="st">&quot;Normal Dist. when &quot;</span>, sigma<span class="sc">^</span><span class="dv">2</span>, <span class="st">&quot; = 1,2,4&quot;</span>)))</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-7-2.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li>comparison with simulated value</li>
</ul>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="chapter2.html#cb14-1" aria-hidden="true" tabindex="-1"></a>simul_norm <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb14-2"><a href="chapter2.html#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(simul_norm) <span class="ot">&lt;-</span> <span class="st">&quot;simul&quot;</span></span>
<span id="cb14-3"><a href="chapter2.html#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="chapter2.html#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="chapter2.html#cb14-5" aria-hidden="true" tabindex="-1"></a>sim_norm_plot <span class="ot">&lt;-</span> simul_norm <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> simul)) <span class="sc">+</span> </span>
<span id="cb14-6"><a href="chapter2.html#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">fill =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>,<span class="fu">aes</span>(<span class="at">y=</span>..density..), <span class="at">binwidth =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb14-7"><a href="chapter2.html#cb14-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;10000 trials ; Simuation of Normal Dist. with &quot;</span>, mu, <span class="st">&quot; = 0, &quot;</span>, sigma<span class="sc">^</span><span class="dv">2</span>, <span class="st">&quot; = 1&quot;</span>)))</span>
<span id="cb14-8"><a href="chapter2.html#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="chapter2.html#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="chapter2.html#cb14-10" aria-hidden="true" tabindex="-1"></a>sim_norm_plot <span class="sc">+</span> <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li><p>In many contexts, being more than 2 SDs from the mean is considered an atypical observation, and being 3 or more SDs from the mean is considered an “outlier.”</p></li>
<li><p>If <span class="math inline">\(Y\)</span> has a normal distribution (mean <span class="math inline">\(\mu\)</span>, standard deviation <span class="math inline">\(\sigma\)</span>), we call <span class="math inline">\(Y-\mu\)</span> the centered variable and <span class="math inline">\(Z=(Y-\mu)/\sigma\)</span> a standardized variable.</p>
<p><code>-</code> The standardized variable: mean 0 and SD 1.</p>
<p><code>-</code> If <span class="math inline">\(Y\)</span> is normal, <span class="math inline">\(Z\)</span>: standard normal distribution.</p>
<p><code>-</code> The percentiles of <span class="math inline">\(Z\)</span> are regularly used for statistical inference.</p></li>
<li><p>While the normal model approximates the distribution of many random variables, such as height or weight, it is by no means the optimal model for most health care outcomes.</p>
<p><code>-</code> One of the most important distributions because of the <strong>central limit theorem (CLT)</strong>.</p>
<p><code>-</code> <strong>CLT</strong>: distribution of sums of large numbers of independent random variables can be approximated by a normal distribution.</p>
<p><code>-</code> The distribution of the sample mean and many of the parameter estimates are well approximated by the normal distribution.</p></li>
</ul>
</div>
<div id="the-gamma-and-lognormal-distributions-for-right-skewed-outcomes" class="section level3" number="2.3.9">
<h3><span class="header-section-number">2.3.9</span> The Gamma and Lognormal Distributions for Right-Skewed Outcomes</h3>
<ul>
<li><p>Gamma distribution</p>
<p><code>-</code> Appropriate for non-negative, continuous outcomes</p>
<p><code>-</code> Highly right-skewed, like medical expenditures.</p></li>
<li><p>Gamma probability density funciton</p></li>
</ul>
<p><span class="math display">\[ f(x\;;\;\alpha, \; \beta) = \frac{1}{\Gamma(\alpha)\beta^\alpha}x^{\alpha-1} e^{-\frac{x}{\beta}}, \; x&gt;0, \;\alpha&gt;0, \; \beta&gt;0\]</span></p>
<p><span class="math inline">\(E(X) = \alpha\beta\)</span>, <span class="math inline">\(Var(X) = \alpha \beta^2\)</span></p>
<ul>
<li>gamma function <span class="math inline">\(\Gamma(\alpha) = \int_{0}^{\infty} \; t^{\alpha-1}e^t \;dt\)</span></li>
</ul>
<p><img src="fig/fig2.6.png" /></p>
<ul>
<li><p>Figure 2.6 graphs different gamma distributions and demonstrates the flexibility of the functional form.</p></li>
<li><p>pdf plot</p></li>
</ul>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="chapter2.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)), <span class="fu">aes</span>(x,y)) <span class="sc">+</span></span>
<span id="cb15-2"><a href="chapter2.html#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dgamma, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">1</span>, <span class="fl">0.5</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;Gamma(1,0.5)&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb15-3"><a href="chapter2.html#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dgamma, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;Gamma(1,1)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb15-4"><a href="chapter2.html#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dgamma, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">3</span>, <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;Gamma(3,1)&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb15-5"><a href="chapter2.html#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dgamma, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">3</span>, <span class="dv">2</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;Gamma(3,2)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb15-6"><a href="chapter2.html#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dgamma, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">5</span>, <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;Gamma(5,1)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb15-7"><a href="chapter2.html#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dgamma, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;Gamma(5,5)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb15-8"><a href="chapter2.html#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="at">label =</span> <span class="st">&quot;Gamma Dist. with different parameters&quot;</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li>comparison with simulated value</li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="chapter2.html#cb16-1" aria-hidden="true" tabindex="-1"></a>simul_gamma <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">10000</span>, <span class="dv">3</span>,<span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb16-2"><a href="chapter2.html#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(simul_gamma) <span class="ot">&lt;-</span> <span class="st">&quot;simul&quot;</span></span>
<span id="cb16-3"><a href="chapter2.html#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="chapter2.html#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="chapter2.html#cb16-5" aria-hidden="true" tabindex="-1"></a>sim_gamma_plot <span class="ot">&lt;-</span> simul_gamma <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> simul)) <span class="sc">+</span> </span>
<span id="cb16-6"><a href="chapter2.html#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">fill =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>,<span class="fu">aes</span>(<span class="at">y=</span>..density..), <span class="at">binwidth =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb16-7"><a href="chapter2.html#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;10000 trials ; Simuation of Gamma Dist. with &quot;</span>, alpha, <span class="st">&quot; = 3, &quot;</span>, beta, <span class="st">&quot; = 2&quot;</span>)))</span>
<span id="cb16-8"><a href="chapter2.html#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="chapter2.html#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="chapter2.html#cb16-10" aria-hidden="true" tabindex="-1"></a>sim_gamma_plot <span class="sc">+</span> <span class="fu">stat_function</span>(<span class="at">fun =</span> dgamma, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">3</span>,<span class="dv">2</span>), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li><p>Two parameters: denote by <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p>
<p><code>-</code> mean: <span class="math inline">\(\alpha/\beta\)</span> and the variance: <span class="math inline">\(\alpha/\beta^2\)</span>.</p>
<p><code>-</code> Variance is related to the mean and can be greater than or less than the mean, depending on the value of <span class="math inline">\(\beta\)</span>.</p></li>
<li><p>Lognormal distribution</p>
<p><code>-</code> For modeling right-skewed outcomes: lognormal.</p>
<p><code>-</code> If its log has a normal distribution.</p>
<p><code>-</code> Arises from exponentiating a normal random variable.</p></li>
<li><p>If <span class="math inline">\(Y\)</span> has a <span class="math inline">\(N(\mu, \sigma^2)\)</span> distribution, then we say that <span class="math inline">\(exp(Y)\)</span> has a lognormal distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>. Its mean is not <span class="math inline">\(exp(μ)\)</span> but rather:</p></li>
</ul>
<p><span class="math display">\[
E[exp (Y )]=exp(\mu + \frac{1}{2}\sigma^2).
\]</span></p>
<ul>
<li>Probability density function</li>
</ul>
<p><span class="math display">\[ f_Y(y) = \frac{1}{y \sigma \sqrt{2\pi}} exp (-\frac{(ln \;y-\mu)^2}{2 \sigma^2}) \;, \; y &gt;0\]</span></p>
<p><img src="fig/fig2.7.png" /></p>
<ul>
<li><p>Figure 2.7 graphs several lognormal distributions.</p></li>
<li><p>The figure shows the PDFs for <span class="math inline">\(exp(Y)\)</span>, where the mean of <span class="math inline">\(Y\)</span> is zero and the standard deviation of <span class="math inline">\(Y\)</span> varies from 0.25 to 2.</p></li>
</ul>
</div>
<div id="pdf-plot" class="section level3" number="2.3.10">
<h3><span class="header-section-number">2.3.10</span> pdf plot</h3>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="chapter2.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">20</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)), <span class="fu">aes</span>(x,y)) <span class="sc">+</span></span>
<span id="cb17-2"><a href="chapter2.html#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dlnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;lognormal(0, 0.5)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb17-3"><a href="chapter2.html#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dlnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">1</span>, <span class="fl">0.5</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;lognormal(1, 0.5)&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb17-4"><a href="chapter2.html#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dlnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;lognormal(1, 1)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb17-5"><a href="chapter2.html#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dlnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">2</span>, <span class="fl">0.5</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;lognormal(2, 0.5)&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb17-6"><a href="chapter2.html#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dlnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">2</span>, <span class="dv">1</span>), <span class="fu">aes</span>(<span class="at">colour =</span> <span class="st">&quot;lognormal(2, 1)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb17-7"><a href="chapter2.html#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="at">label =</span> <span class="st">&quot;Log Normal Dist. with different parameters&quot;</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;f(x)&quot;</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="comparison-with-simulated-value-2" class="section level3" number="2.3.11">
<h3><span class="header-section-number">2.3.11</span> comparison with simulated value</h3>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="chapter2.html#cb18-1" aria-hidden="true" tabindex="-1"></a>simul_lnorm <span class="ot">&lt;-</span> <span class="fu">rlnorm</span>(<span class="dv">10000</span>, <span class="dv">1</span>,<span class="fl">0.5</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb18-2"><a href="chapter2.html#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(simul_lnorm) <span class="ot">&lt;-</span> <span class="st">&quot;simul&quot;</span></span>
<span id="cb18-3"><a href="chapter2.html#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="chapter2.html#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="chapter2.html#cb18-5" aria-hidden="true" tabindex="-1"></a>sim_lnorm_plot <span class="ot">&lt;-</span> simul_lnorm <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> simul)) <span class="sc">+</span> </span>
<span id="cb18-6"><a href="chapter2.html#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">fill =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>,<span class="fu">aes</span>(<span class="at">y=</span>..density..), <span class="at">binwidth =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb18-7"><a href="chapter2.html#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;10000 trials ; Simuation of Log Normal Dist. with &quot;</span>, mu, <span class="st">&quot; = 1, &quot;</span>, sigma<span class="sc">^</span><span class="dv">2</span>, <span class="st">&quot; = 0.5&quot;</span>)))</span>
<span id="cb18-8"><a href="chapter2.html#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="chapter2.html#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="chapter2.html#cb18-10" aria-hidden="true" tabindex="-1"></a>sim_lnorm_plot <span class="sc">+</span> <span class="fu">stat_function</span>(<span class="at">fun =</span> dlnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="dv">1</span>,<span class="fl">0.5</span>),<span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="hdsbook_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li><p>Any regression analysis that logs the dependent variable before running the regression is implicitly assuming the outcome follows a lognormal distribution.</p>
<p><code>-</code> Logging the outcome variable and then conducting a regression analysis based on the normal distribution equates to assuming that the original outcome (before logging) is lognormal.</p>
<p><code>-</code> Lognormal distribution was traditionally favored for modeling medical costs because it can have a heavy-tailed distribution, well suited for capturing a non-trivial frequency of exceptionally large observations.</p></li>
<li><p>But, retransforming regression coefficients to the metric of original scale is not always straightforward.</p></li>
<li><p>Retransformation issues with respect to the mean using the MEPS data.</p>
<p><code>-</code> Suppose <span class="math inline">\(Y\)</span> reflects the log of a health expenditure outcome, and the mean of <span class="math inline">\(Y\)</span> is <span class="math inline">\(\mu\)</span>. And then what is the mean of expenditures?</p>
<p><code>-</code> The mean of expenditures is <span class="math inline">\(exp(\mu)\)</span>?</p></li>
</ul>
<p><img src="fig/table2.2.png" /></p>
<ul>
<li><p>Table 2.2 shows medical costs from the MEPS 2017 data.</p>
<p><code>-</code> Three columns of mean estimates corresponding to three types of costs: total, inpatient, and outpatient medical expenditures for the year.</p>
<p><code>-</code> Some subjects had zero expenditures for one or more of these outcomes, and they were excluded for simplicity.</p>
<p><code>-</code> First column: <span class="math inline">\(E(Y)\)</span>,</p>
<p><code>-</code> Second column: <span class="math inline">\(E[log(Y)]\)</span></p>
<p><code>-</code> Third column: <span class="math inline">\(exp(E[log(Y)])\)</span></p></li>
<li><p>Although mathematically <span class="math inline">\(E(Y)=exp{log[E(Y)]}\)</span>, the third column does not get us back to the first column.</p></li>
<li><p>We cannot simply exchange the calculation of the mean of a variable and its log; the order of the operations is important.</p></li>
<li><p>Indeed, in each case, the first column is greater than the third column, reflecting the general relationship:</p></li>
</ul>
<p><span class="math display">\[
E(Y) = E(exp[log(Y)]) \ge exp(E[log(Y)]).
\]</span></p>
<ul>
<li><p>In fact, when we exponentiate a normal random variable, the mean depends not only on the mean of the original random variable but also on its variance.</p></li>
<li><p>Formally, if <span class="math inline">\(E[log(Y)]= \mu\)</span> and <span class="math inline">\(Var[log(Y)]= \sigma^2\)</span>, then:</p></li>
</ul>
<p><span class="math display">\[
E(Y) = exp(\mu +\frac{1}{2}\sigma^2) = exp(\mu) × exp(\frac{1}{2}\sigma^2).
\]</span></p>
<ul>
<li>If the log-transformed outcome is truly normally distributed, the median is not affected by the order of operations, and the median of <span class="math inline">\(exp(Y)\)</span> is equal to <span class="math inline">\(exp(median(Y))\)</span>. Thus, an alternative to modeling the mean of <span class="math inline">\(Y\)</span> in this setting would be to use a quantile regression model.</li>
</ul>
</div>
</div>
<div id="hypothesis-testing-and-statistical-inference" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Hypothesis Testing and Statistical Inference</h2>
<ul>
<li><p><strong>Hypothesis testing</strong> is the most well-known—and the most controversial—tool for statistical inference.</p></li>
<li><p><strong>Inference</strong>: process by which sample estimates are used to answer research questions and address specified hypotheses about the population.</p></li>
<li><p>Hypothesis testing is a statistical procedure that is used to reach a yes–no decision about a hypothesis based on a sample estimate of the quantity of interest (e.g., the sample mean or a regression coefficient).</p>
<p><code>-</code> Satistical procedure used to reach a decision about a hypothesis based on a sample while quantifying the risk that the decision made is wrong.</p>
<p><code>-</code> One-way street, permitting only one decision: rejection of a specified (null) hypothesis <span class="math inline">\(H_0\)</span>, which is typically set up to be the opposite of what we wish to investigate.</p>
<p><code>-</code> Example: if we hypothesize that inpatient expenditures depend on self-reported health, we would set up our null hypothesis <span class="math inline">\(H_0\)</span> to be that these two random variables are not associated.</p>
<p><code>-</code> Rejecting <span class="math inline">\(H_0\)</span> would amount to “proving” our hypothesis.</p>
<p><code>-</code> Reject <span class="math inline">\(H_0\)</span> if the sample data appear to contradict it; specifically, if our estimate is not close to the hypothesized value.</p></li>
<li><p>The core of the hypothesis testing procedure</p>
<p><code>-</code> To control the chance that this is a mistake.</p>
<p><code>-</code> * To calculate the chance of mistakenly rejecting <span class="math inline">\(H_0\)</span>, we assume that the null hypothesis is indeed correct.</p>
<p><code>-</code> Then, we calculate the p-value, which is the probability of obtaining an estimate as or more extreme than that observed, where more extreme means further away from <span class="math inline">\(H_0\)</span>.</p>
<p><code>-</code> Low p-value means that our estimate is not consistent with <span class="math inline">\(H_0\)</span>.</p>
<p><code>-</code> We infer that there is only a small chance that the data we observed were generated under the null hypothesis and therefore a correspondingly low chance of being wrong by rejecting it.</p>
<p><code>-</code> If the p-value is small enough (e.g., less than 0.05), we reject the null hypothesis and cite the p-value as a measure of the strength of evidence in support of this decision.</p></li>
<li><p>Note the difference between these two interpretations: the first is a statement about the hypothesis, and the second is a statement about the data.</p>
<p><code>-</code>* We can only make statements about the data and their likelihood under <span class="math inline">\(H_0\)</span>.</p>
<p><code>-</code> One-way structure of the procedure only permits inferring that the observed data are inconsistent with <span class="math inline">\(H_0\)</span>.</p>
<p><code>-</code> There is no converse; we cannot infer that the observed data are consistent with <span class="math inline">\(H_0\)</span>, even if the p-value is large.</p>
<p><code>-</code> In this case, we can only issue a statement that we do not have evidence to reject <span class="math inline">\(H_0\)</span>.</p></li>
<li><p>The historical convention is that a p-value below 0.05 is “statistically significant” and justifies rejection of the null hypothesis.</p></li>
<li><p>What are the problems with a standard 0.05 threshold for a p-value?
<code>-</code> For one thing, p-values may be small even in the absence of practically significant evidence against the null hypothesis.</p>
<p><code>-</code> This frequently occurs when sample sizes are very large, as is the case in many publicly available health care databases.</p></li>
<li><p>It is not uncommon in such settings to obtain an estimate of the coefficient of interest that is close to zero but has a tiny p-value.</p></li>
<li><p>Conversely, p-values may be larger than 0.05 even when the observed evidence against the hypothesis is compelling.</p>
<p><code>-</code> This happens most often when the sample is small and there is enough uncertainty that we cannot tell whether the observed data are really inconsistent with <span class="math inline">\(H_0\)</span>.</p></li>
<li><p>We say that the <strong>power</strong> of the test is inadequate, where power is defined as the probability of correctly rejecting <span class="math inline">\(H_0\)</span> if it is indeed false.</p>
<p><code>-</code> Power is closely linked to sample size, and an important step in planning or designing a study is to make sure that the sample size is large enough so that practically important departures from <span class="math inline">\(H_0\)</span> can be detected.</p></li>
<li><p>The existence of a standard 0.05 threshold can lead to manipulation when there are incentives to rejecting H0.</p>
<p><code>-</code> A dataset can be “p-hacked” by applying multiple methods or models and then reporting only the results of those that lead to a small p-value without reporting the others.</p></li>
<li><p>Methodological manipulations:</p>
<p><code>-</code> Exclusion criteria (e.g., restricting to subjects within a certain age range)</p>
<p><code>-</code> Choosing a specific metric for variables (e.g., dichotomizing a continuous covariate at a carefully selected cut point)</p>
<p><code>-</code> Choosing how to process data (e.g., dropping subjects with certain kinds of missing data)</p>
<p><code>-</code> Using a specific test (e.g., performing a t-test rather than a non-parametric Wilcoxon test).</p></li>
<li><p>By making certain choices, p-values can be manipulated to produce results that end up being statistically significant.</p></li>
<li><p>It is reasonable to apply multiple methods to confirm robustness of any inferences, but these should all be reported, particularly if they do not all produce the same conclusion.</p></li>
<li><p>Further issue</p>
<p><code>-</code> When there are multiple comparisons made in a dataset, the chance of at least one producing a small p-value increases.</p>
<p><code>-</code> Analyses involving multiple comparisons may occur when there is no specific scientific question driving the analysis and in multiple regression with more than a single covariate.</p>
<p><code>-</code> Example: suppose we are interested in understanding the correlates of total medical expenditures, but we have not formulated any hypotheses about specific dependencies.</p>
<p><code>-</code> If we test each available covariate individually and use the 0.05 threshold to select which are significant correlates of total expenditures, the probability of incorrectly rejecting the null hypothesis each time will be 0.05, but the probability of incorrectly rejecting the null hypothesis at least once could be considerably greater than 0.05.</p>
<p><code>-</code> If we conduct <span class="math inline">\(k\)</span> independent tests, the probability of at least one incorrect rejection is <span class="math inline">\(1-(1-0.05)k\)</span>, which works out to 0.23 for <span class="math inline">\(k=5\)</span> tests and to 0.40 for <span class="math inline">\(k=10\)</span> tests.</p></li>
<li><p>Many different approaches have been advanced to deal with the multiple comparisons problem.</p>
<p><code>-</code> The simplest and most common is to conduct each test using a more stringent criterion to reject the null hypothesis, so that the overall error rate remains at or close to 0.05.</p>
<p><code>-</code> When there are very large numbers of tests, for example, in the setting of a high-dimensional genomic analysis, alternative approaches have been developed based on controlling the false discovery rate.</p></li>
<li><p><strong>While many academic research journals and reviewers still expect p-values to be reported, there is growing recognition of the limitations of p-values and the need for reproducibility</strong>.</p></li>
</ul>
<!-- ```{r} -->
<!-- # library(MEPS) -->
<!-- # library(tidyverse) -->
<!-- # dset <- read_MEPS(file="h201") -->
<!-- ``` -->
<!-------------------- End --------------->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["hdsbook.pdf", "hdsbook.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
