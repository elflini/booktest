<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Appendix | Mathematical Statistics</title>
  <meta name="description" content="This is a Mathematical Statistics" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Appendix | Mathematical Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a Mathematical Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Appendix | Mathematical Statistics" />
  
  <meta name="twitter:description" content="This is a Mathematical Statistics" />
  

<meta name="author" content="Jin Hyun Nam" />


<meta name="date" content="2024-08-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter11.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Mathematical Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Contents</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>1.1</b> Sample Spaces and Events</a></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#algebra-of-events"><i class="fa fa-check"></i><b>1.2</b> Algebra of Events</a></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#experiments-with-symmetries"><i class="fa fa-check"></i><b>1.3</b> Experiments with Symmetries</a></li>
<li class="chapter" data-level="1.4" data-path="chapter1.html"><a href="chapter1.html#composition-of-experiments-counting-rules"><i class="fa fa-check"></i><b>1.4</b> Composition of Experiments: Counting Rules</a></li>
<li class="chapter" data-level="1.5" data-path="chapter1.html"><a href="chapter1.html#sampling-at-random"><i class="fa fa-check"></i><b>1.5</b> Sampling at Random</a></li>
<li class="chapter" data-level="1.6" data-path="chapter1.html"><a href="chapter1.html#binomial-multinomial-coefficients"><i class="fa fa-check"></i><b>1.6</b> Binomial &amp; Multinomial Coefficients</a></li>
<li class="chapter" data-level="1.7" data-path="chapter1.html"><a href="chapter1.html#discrete-probability-distributions"><i class="fa fa-check"></i><b>1.7</b> Discrete Probability Distributions</a></li>
<li class="chapter" data-level="1.8" data-path="chapter1.html"><a href="chapter1.html#subjective-probability"><i class="fa fa-check"></i><b>1.8</b> Subjective Probability</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#probability-functions"><i class="fa fa-check"></i><b>2.1</b> Probability Functions</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#joint-distributions"><i class="fa fa-check"></i><b>2.2</b> Joint Distributions</a></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#conditional-probability"><i class="fa fa-check"></i><b>2.3</b> Conditional Probability</a></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#bayes-theorem-law-of-inverse-probability"><i class="fa fa-check"></i><b>2.4</b> Bayes Theorem (Law of Inverse Probability)</a></li>
<li class="chapter" data-level="2.5" data-path="chapter2.html"><a href="chapter2.html#statistical-independence-of-random-variables"><i class="fa fa-check"></i><b>2.5</b> Statistical Independence of Random Variables</a></li>
<li class="chapter" data-level="2.6" data-path="chapter2.html"><a href="chapter2.html#exchangeability"><i class="fa fa-check"></i><b>2.6</b> Exchangeability</a></li>
<li class="chapter" data-level="2.7" data-path="chapter2.html"><a href="chapter2.html#application-probability-of-winning-in-craps"><i class="fa fa-check"></i><b>2.7</b> Application: Probability of Winning in Craps</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> Expectations of Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#the-mean"><i class="fa fa-check"></i><b>3.1</b> The Mean</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#expectation-of-a-function"><i class="fa fa-check"></i><b>3.2</b> Expectation of a Function</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#variability"><i class="fa fa-check"></i><b>3.3</b> Variability</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#covariance-and-correlation"><i class="fa fa-check"></i><b>3.4</b> Covariance and Correlation</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#sums-of-random-variables"><i class="fa fa-check"></i><b>3.5</b> Sums of Random Variables</a></li>
<li class="chapter" data-level="3.6" data-path="chapter3.html"><a href="chapter3.html#probability-generating-functions"><i class="fa fa-check"></i><b>3.6</b> Probability Generating Functions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Bernoulli and Related Random Variables</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#sampling-bernoulli-populations"><i class="fa fa-check"></i><b>4.1</b> Sampling Bernoulli Populations</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#binomial-distribution"><i class="fa fa-check"></i><b>4.2</b> Binomial Distribution</a></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>4.3</b> Hypergeometric Distribution</a></li>
<li class="chapter" data-level="4.4" data-path="chapter4.html"><a href="chapter4.html#geometric-distribution"><i class="fa fa-check"></i><b>4.4</b> Geometric Distribution</a></li>
<li class="chapter" data-level="4.5" data-path="chapter4.html"><a href="chapter4.html#negative-binomial-distribution"><i class="fa fa-check"></i><b>4.5</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="4.6" data-path="chapter4.html"><a href="chapter4.html#negative-hypergeometric-distribution"><i class="fa fa-check"></i><b>4.6</b> Negative Hypergeometric Distribution</a></li>
<li class="chapter" data-level="4.7" data-path="chapter4.html"><a href="chapter4.html#approximating-binomial-probabilities"><i class="fa fa-check"></i><b>4.7</b> Approximating Binomial Probabilities</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="chapter4.html"><a href="chapter4.html#normal-approximation-to-the-binomial"><i class="fa fa-check"></i><b>4.7.1</b> Normal approximation to the Binomial</a></li>
<li class="chapter" data-level="4.7.2" data-path="chapter4.html"><a href="chapter4.html#poisson-approximation-to-the-binomial"><i class="fa fa-check"></i><b>4.7.2</b> Poisson Approximation to the Binomial</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="chapter4.html"><a href="chapter4.html#poisson-distribution"><i class="fa fa-check"></i><b>4.8</b> Poisson Distribution</a></li>
<li class="chapter" data-level="4.9" data-path="chapter4.html"><a href="chapter4.html#law-of-large-numbers"><i class="fa fa-check"></i><b>4.9</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="4.10" data-path="chapter4.html"><a href="chapter4.html#multinomial-distributions"><i class="fa fa-check"></i><b>4.10</b> Multinomial Distributions</a></li>
<li class="chapter" data-level="4.11" data-path="chapter4.html"><a href="chapter4.html#using-probability-generating-functions"><i class="fa fa-check"></i><b>4.11</b> Using Probability Generating Functions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#cumulative-distribution-function-cdf"><i class="fa fa-check"></i><b>5.1</b> Cumulative Distribution Function (CDF)</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#density-and-the-probability-element"><i class="fa fa-check"></i><b>5.2</b> Density and the Probability Element</a></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#the-median-and-other-percentiles"><i class="fa fa-check"></i><b>5.3</b> The Median and Other Percentiles</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#expected-value"><i class="fa fa-check"></i><b>5.4</b> Expected Value</a></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#expected-value-of-a-function"><i class="fa fa-check"></i><b>5.5</b> Expected Value of a Function</a></li>
<li class="chapter" data-level="5.6" data-path="chapter5.html"><a href="chapter5.html#average-deviations"><i class="fa fa-check"></i><b>5.6</b> Average Deviations</a></li>
<li class="chapter" data-level="5.7" data-path="chapter5.html"><a href="chapter5.html#bivariate-distributions"><i class="fa fa-check"></i><b>5.7</b> Bivariate Distributions</a></li>
<li class="chapter" data-level="5.8" data-path="chapter5.html"><a href="chapter5.html#several-variables"><i class="fa fa-check"></i><b>5.8</b> Several Variables</a></li>
<li class="chapter" data-level="5.9" data-path="chapter5.html"><a href="chapter5.html#covariance-and-correlation-1"><i class="fa fa-check"></i><b>5.9</b> Covariance and Correlation</a></li>
<li class="chapter" data-level="5.10" data-path="chapter5.html"><a href="chapter5.html#independence"><i class="fa fa-check"></i><b>5.10</b> Independence</a></li>
<li class="chapter" data-level="5.11" data-path="chapter5.html"><a href="chapter5.html#conditional-distributions"><i class="fa fa-check"></i><b>5.11</b> Conditional Distributions</a></li>
<li class="chapter" data-level="5.12" data-path="chapter5.html"><a href="chapter5.html#moment-generating-functions"><i class="fa fa-check"></i><b>5.12</b> Moment Generating Functions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Families of Continuous Distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#normal-distributions"><i class="fa fa-check"></i><b>6.1</b> Normal Distributions</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#exponential-distributions"><i class="fa fa-check"></i><b>6.2</b> Exponential Distributions</a></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#gamma-distributions"><i class="fa fa-check"></i><b>6.3</b> Gamma Distributions</a></li>
<li class="chapter" data-level="6.4" data-path="chapter6.html"><a href="chapter6.html#chi-squared-distributions"><i class="fa fa-check"></i><b>6.4</b> Chi Squared Distributions</a></li>
<li class="chapter" data-level="6.5" data-path="chapter6.html"><a href="chapter6.html#distributions-for-reliability"><i class="fa fa-check"></i><b>6.5</b> Distributions for Reliability</a></li>
<li class="chapter" data-level="6.6" data-path="chapter6.html"><a href="chapter6.html#t-f-and-beta-distributions"><i class="fa fa-check"></i><b>6.6</b> <span class="math inline">\(t\)</span>, <span class="math inline">\(F\)</span>, and Beta Distributions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Organizing &amp; Describing Data</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#frequency-distributions"><i class="fa fa-check"></i><b>7.1</b> Frequency Distributions</a></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#data-on-continuous-variables"><i class="fa fa-check"></i><b>7.2</b> Data on Continuous Variables</a></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#order-statistics"><i class="fa fa-check"></i><b>7.3</b> Order Statistics</a></li>
<li class="chapter" data-level="7.4" data-path="chapter7.html"><a href="chapter7.html#data-analysis"><i class="fa fa-check"></i><b>7.4</b> Data Analysis</a></li>
<li class="chapter" data-level="7.5" data-path="chapter7.html"><a href="chapter7.html#the-sample-mean"><i class="fa fa-check"></i><b>7.5</b> The Sample Mean</a></li>
<li class="chapter" data-level="7.6" data-path="chapter7.html"><a href="chapter7.html#measures-of-dispersion"><i class="fa fa-check"></i><b>7.6</b> Measures of Dispersion</a></li>
<li class="chapter" data-level="7.7" data-path="chapter7.html"><a href="chapter7.html#correlation"><i class="fa fa-check"></i><b>7.7</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Samples, Statistics, &amp; Sampling Distributions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#random-sampling"><i class="fa fa-check"></i><b>8.1</b> Random Sampling</a></li>
<li class="chapter" data-level="8.2" data-path="chapter8.html"><a href="chapter8.html#likelihood"><i class="fa fa-check"></i><b>8.2</b> Likelihood</a></li>
<li class="chapter" data-level="8.3" data-path="chapter8.html"><a href="chapter8.html#sufficient-statistics"><i class="fa fa-check"></i><b>8.3</b> Sufficient Statistics</a></li>
<li class="chapter" data-level="8.4" data-path="chapter8.html"><a href="chapter8.html#sampling-distributions"><i class="fa fa-check"></i><b>8.4</b> Sampling Distributions</a></li>
<li class="chapter" data-level="8.5" data-path="chapter8.html"><a href="chapter8.html#simulating-sampling-distributions"><i class="fa fa-check"></i><b>8.5</b> Simulating Sampling Distributions</a></li>
<li class="chapter" data-level="8.6" data-path="chapter8.html"><a href="chapter8.html#order-statistics-1"><i class="fa fa-check"></i><b>8.6</b> Order Statistics</a></li>
<li class="chapter" data-level="8.7" data-path="chapter8.html"><a href="chapter8.html#moments-of-sample-means-and-proportionssp"><i class="fa fa-check"></i><b>8.7</b> Moments of Sample Means and Proportionssp</a></li>
<li class="chapter" data-level="8.8" data-path="chapter8.html"><a href="chapter8.html#the-central-limit-theorem-clt"><i class="fa fa-check"></i><b>8.8</b> The Central Limit Theorem (CLT)</a></li>
<li class="chapter" data-level="8.9" data-path="chapter8.html"><a href="chapter8.html#using-the-moment-generating-function"><i class="fa fa-check"></i><b>8.9</b> Using the Moment Generating Function</a></li>
<li class="chapter" data-level="8.10" data-path="chapter8.html"><a href="chapter8.html#normal-populations"><i class="fa fa-check"></i><b>8.10</b> Normal Populations</a></li>
<li class="chapter" data-level="8.11" data-path="chapter8.html"><a href="chapter8.html#updating-prior-probabilities-via-likelihood"><i class="fa fa-check"></i><b>8.11</b> Updating Prior Probabilities Via Likelihood</a></li>
<li class="chapter" data-level="8.12" data-path="chapter8.html"><a href="chapter8.html#some-conjudate-families"><i class="fa fa-check"></i><b>8.12</b> Some conjudate Families</a></li>
<li class="chapter" data-level="8.13" data-path="chapter8.html"><a href="chapter8.html#predictive-distributions"><i class="fa fa-check"></i><b>8.13</b> Predictive Distributions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Estimation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#point-estimation"><i class="fa fa-check"></i><b>9.1</b> Point Estimation</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#errors-in-estimation"><i class="fa fa-check"></i><b>9.2</b> Errors in Estimation</a></li>
<li class="chapter" data-level="9.3" data-path="chapter9.html"><a href="chapter9.html#consistency"><i class="fa fa-check"></i><b>9.3</b> Consistency</a></li>
<li class="chapter" data-level="9.4" data-path="chapter9.html"><a href="chapter9.html#large-sample-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> Large Sample Confidence Intervals</a></li>
<li class="chapter" data-level="9.5" data-path="chapter9.html"><a href="chapter9.html#determining-sample-size"><i class="fa fa-check"></i><b>9.5</b> Determining Sample Size</a></li>
<li class="chapter" data-level="9.6" data-path="chapter9.html"><a href="chapter9.html#small-sample-confidence-intervals-for-mu_x"><i class="fa fa-check"></i><b>9.6</b> Small Sample Confidence Intervals for <span class="math inline">\(\mu_X\)</span></a></li>
<li class="chapter" data-level="9.7" data-path="chapter9.html"><a href="chapter9.html#the-distribution-of-t"><i class="fa fa-check"></i><b>9.7</b> The Distribution of <span class="math inline">\(T\)</span></a></li>
<li class="chapter" data-level="9.8" data-path="chapter9.html"><a href="chapter9.html#pivotal-quantities"><i class="fa fa-check"></i><b>9.8</b> Pivotal Quantities</a></li>
<li class="chapter" data-level="9.9" data-path="chapter9.html"><a href="chapter9.html#estimating-a-mean-difference"><i class="fa fa-check"></i><b>9.9</b> Estimating a Mean Difference</a></li>
<li class="chapter" data-level="9.10" data-path="chapter9.html"><a href="chapter9.html#umvue"><i class="fa fa-check"></i><b>9.10</b> UMVUE</a></li>
<li class="chapter" data-level="9.11" data-path="chapter9.html"><a href="chapter9.html#bayes-estimators"><i class="fa fa-check"></i><b>9.11</b> Bayes Estimators</a></li>
<li class="chapter" data-level="9.12" data-path="chapter9.html"><a href="chapter9.html#efficiency"><i class="fa fa-check"></i><b>9.12</b> Efficiency</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chapter10.html"><a href="chapter10.html"><i class="fa fa-check"></i><b>10</b> Significance Testing</a>
<ul>
<li class="chapter" data-level="10.1" data-path="chapter10.html"><a href="chapter10.html#hypotheses"><i class="fa fa-check"></i><b>10.1</b> Hypotheses</a></li>
<li class="chapter" data-level="10.2" data-path="chapter10.html"><a href="chapter10.html#assessing-the-evidence"><i class="fa fa-check"></i><b>10.2</b> Assessing the Evidence</a></li>
<li class="chapter" data-level="10.3" data-path="chapter10.html"><a href="chapter10.html#one-sample-z-tests"><i class="fa fa-check"></i><b>10.3</b> One Sample <span class="math inline">\(Z\)</span> Tests</a></li>
<li class="chapter" data-level="10.4" data-path="chapter10.html"><a href="chapter10.html#one-sample-t-tests"><i class="fa fa-check"></i><b>10.4</b> One Sample <span class="math inline">\(t\)</span> Tests</a></li>
<li class="chapter" data-level="10.5" data-path="chapter10.html"><a href="chapter10.html#some-nonparametric-tests"><i class="fa fa-check"></i><b>10.5</b> Some Nonparametric Tests</a></li>
<li class="chapter" data-level="10.6" data-path="chapter10.html"><a href="chapter10.html#probability-of-the-null-hypothesis"><i class="fa fa-check"></i><b>10.6</b> Probability of the Null Hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chapter11.html"><a href="chapter11.html"><i class="fa fa-check"></i><b>11</b> Tests as Decision Rules</a>
<ul>
<li class="chapter" data-level="11.1" data-path="chapter11.html"><a href="chapter11.html#rejection-regions-and-errors"><i class="fa fa-check"></i><b>11.1</b> Rejection Regions and Errors</a></li>
<li class="chapter" data-level="11.2" data-path="chapter11.html"><a href="chapter11.html#the-power-function"><i class="fa fa-check"></i><b>11.2</b> The Power function</a></li>
<li class="chapter" data-level="11.3" data-path="chapter11.html"><a href="chapter11.html#choosing-a-sample-size"><i class="fa fa-check"></i><b>11.3</b> Choosing a Sample Size</a></li>
<li class="chapter" data-level="11.4" data-path="chapter11.html"><a href="chapter11.html#most-powerful-tests"><i class="fa fa-check"></i><b>11.4</b> Most Powerful Tests</a></li>
<li class="chapter" data-level="11.5" data-path="chapter11.html"><a href="chapter11.html#uniformly-most-powerful-tests"><i class="fa fa-check"></i><b>11.5</b> Uniformly Most Powerful Tests</a></li>
<li class="chapter" data-level="11.6" data-path="chapter11.html"><a href="chapter11.html#likelihood-ratio-tests"><i class="fa fa-check"></i><b>11.6</b> Likelihood Ratio Tests</a></li>
<li class="chapter" data-level="11.7" data-path="chapter11.html"><a href="chapter11.html#bayesian-testing"><i class="fa fa-check"></i><b>11.7</b> Bayesian Testing</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="chapter12.html"><a href="chapter12.html"><i class="fa fa-check"></i><b>12</b> Appendix</a>
<ul>
<li class="chapter" data-level="12.1" data-path="chapter12.html"><a href="chapter12.html#greek-alphabet"><i class="fa fa-check"></i><b>12.1</b> Greek Alphabet</a></li>
<li class="chapter" data-level="12.2" data-path="chapter12.html"><a href="chapter12.html#abbreviations"><i class="fa fa-check"></i><b>12.2</b> Abbreviations</a></li>
<li class="chapter" data-level="12.3" data-path="chapter12.html"><a href="chapter12.html#practice-exams"><i class="fa fa-check"></i><b>12.3</b> PRACTICE EXAMS</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematical Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter12" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Appendix<a href="chapter12.html#chapter12" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="greek-alphabet" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Greek Alphabet<a href="chapter12.html#greek-alphabet" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><img src="fig12/fig11_6.jpg" /></p>
</div>
<div id="abbreviations" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Abbreviations<a href="chapter12.html#abbreviations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>BF: Bayes Factor. If <span class="math inline">\(H\)</span> is a hypothesis and <span class="math inline">\(T\)</span> is a sufficient statistic, then</li>
</ul>
<p><span class="math display">\[
BF = \frac{Posterior \ odds \ of \ H}{Prior \ odds \ of \ H}=\frac{P(H|T = t)/P(H^c|T = t)}{P(H)/P(H^c)}=\frac{f_{T|H}(t|H)}{f_{T|H^c} (t|H^c)}
\]</span></p>
<ul>
<li>CDF or cdf: Cumulative Distribution Function. If <span class="math inline">\(X\)</span> is a random variable,
then</li>
</ul>
<p><span class="math display">\[
F_X(x) = P(X ≤ x)
\]</span></p>
<p>is the cdf of <span class="math inline">\(X\)</span>.</p>
<ul>
<li>CLT: Central Limit Theorem. If <span class="math inline">\(X_1, X_2, \ldots , X_n\)</span> is a random sample of size <span class="math inline">\(n\)</span> from a population with mean <span class="math inline">\(\mu X\)</span> and variance <span class="math inline">\(\sigma^2_X\)</span>, then, the distribution of</li>
</ul>
<p><span class="math display">\[
Z_n =\frac{\bar X-\mu_X}{\sigma_X /\sqrt{n}}
\]</span></p>
<p>converges to <span class="math inline">\(N(0, 1)\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>.</p>
<ul>
<li>CRLB: Cramer-Rao Lower Bound. The CRLB is the lower bound on the variance of an unbiased estimator of <span class="math inline">\(g(\theta)\)</span>. The bound is</li>
</ul>
<p><span class="math display">\[
CRLB = \frac{[\frac{\partial g(\theta)}{\partial \theta}]^2}{I_\theta},
\]</span></p>
<p>where <span class="math inline">\(I_\theta\)</span> is Fisher’s information.</p>
<ul>
<li>LR: Likelihood Ratio. When testing a simple null against a simple alternative, the LR is</li>
</ul>
<p><span class="math display">\[
\lambda =\frac{f_0(x)}{f_1(x)}.
\]</span></p>
<ul>
<li>When testing a composite null against a composite alternative, the LR is</li>
</ul>
<p><span class="math display">\[
\lambda =\frac{\underset{\theta \in \theta_0}{sup}f(x|\theta)}{\underset{\theta \in \theta_a}{sup}f(x|\theta)},
\]</span></p>
<p>where <span class="math inline">\(\theta_0\)</span> and <span class="math inline">\(\theta_a\)</span> are the parameter spaces under <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span>, respectively.</p>
<ul>
<li><p>LRT: Likelihood Ratio Test. The LRT of <span class="math inline">\(H_0\)</span> versus <span class="math inline">\(H_a\)</span> is to reject <span class="math inline">\(H_0\)</span> for small values of the LR. The critical value is chosen so that the size of the test is <span class="math inline">\(\alpha\)</span>.</p></li>
<li><p>MGF or mgf: Moment Generating Function. If <span class="math inline">\(X\)</span> is a random variable, then</p></li>
</ul>
<p><span class="math display">\[
\psi_X (t) = E(e^{tX})
\]</span></p>
<p>is the mgf of <span class="math inline">\(X\)</span>.</p>
<ul>
<li><p>MLE: Maximum Likelihood Estimator. Suppose that <span class="math inline">\(X_i, X_2, \ldots , X_n\)</span> is a random sample from <span class="math inline">\(f_X(x|\theta)\)</span>, where <span class="math inline">\(\theta\)</span> is a <span class="math inline">\(k \times 1\)</span> vector of parameters. A maximum likelihood estimator of <span class="math inline">\(\theta\)</span> is any value <span class="math inline">\(\hat \theta\)</span> that maximizes the likelihood function and is a point in the parameter space or on the boundary of the parameter space.</p></li>
<li><p>MSE: Mean Square Error. If <span class="math inline">\(T\)</span> is an estimator of a parameter, <span class="math inline">\(\theta\)</span>, then</p></li>
</ul>
<p><span class="math display">\[
MSE_T (\theta) = E(T − \theta)^2 = \sigma^2_T + bias^2,
\]</span></p>
<p>where bias = <span class="math inline">\(E(T − \theta)\)</span>.</p>
<ul>
<li>PDF or pdf: Probability Density Function. If <span class="math inline">\(X\)</span> is a continuous random variable, then<br />
</li>
</ul>
<p><span class="math display">\[
\frac{d}{dx} F_X(x)=f_X (x)
\]</span></p>
<p>is the pdf of <span class="math inline">\(X\)</span>.</p>
<ul>
<li>PF or pf: Probability Function. If <span class="math inline">\(X\)</span> is a discrete random variable, then</li>
</ul>
<p><span class="math display">\[
P(X = x) = f_X(x)
\]</span></p>
<p>is the pf of <span class="math inline">\(X\)</span>. The terms pf and pmf are interchangeable.</p>
<ul>
<li>PGF or pgf: Probability Generating Function. If <span class="math inline">\(X\)</span> is a random variable, then</li>
</ul>
<p><span class="math display">\[
\eta_X(t) = E(t^X)
\]</span></p>
<p>is the pgf of <span class="math inline">\(X\)</span>.</p>
<ul>
<li><p>The pgf is most useful for discrete random variables.</p></li>
<li><p>PMF or pmf: Probability Mass Function. If <span class="math inline">\(X\)</span> is a discrete random variable, then</p></li>
</ul>
<p><span class="math display">\[
P(X = x) = f_X(x)
\]</span></p>
<p>is the pmf of X. The terms pmf and pf are interchangeable.</p>
<ul>
<li><p>RV or rv: Random Variable.</p></li>
<li><p>UMP Test: Uniformly Most Powerful Test. A UMP test of <span class="math inline">\(H_0\)</span> against <span class="math inline">\(H_a\)</span> is most powerful regardless of the value of the parameter under <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span></p></li>
</ul>
<p><br></p>
</div>
<div id="practice-exams" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> PRACTICE EXAMS<a href="chapter12.html#practice-exams" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Series and Limits</li>
</ul>
<p><span class="math display">\[
\begin{align}
&amp;\sum_{i=1}^{n}r^i=\left\{\begin{matrix}
\frac{1-r^{n+1}}{1-r} \  \ if \ r \ne 1 &amp; \\
n+1 \ \ if \ r=1 &amp;
\end{matrix}\right.
\sum_{i=1}^{\infty}r^i=\left\{\begin{matrix}
\frac{1-r^{n+1}}{1-r} \   \ if \ |r|&lt;1 &amp;  &amp; \\
\infty \   \   \   \   \   \   \   \ if \ r&gt;1&amp;  &amp; \\
undefined \   \ if \ r&lt;-1 &amp;  &amp;
\end{matrix}\right.\\
&amp;(a + b)^n=\sum_{i=0}^{n}\binom{n}{i}a^ib^{n-i} \    \   \   \   \   \
ln(1 + ε)=-\sum_{i=1}^{\infty}\frac{(−ε)^i}{i}if|ε|&lt;1 \\
&amp;ln(1 + ε) = ε + o(ε) \    \ if|ε|&lt;1 \\
&amp;\underset{n\rightarrow\infty}{lim}(1 +\frac{a}{n}+o(n^{-1}))^n=e^a \   \   \   \   \
e^a=\sum_{i=1}^{n}\frac{a^i}{i^!}
\end{align}
\]</span></p>
<ul>
<li>Distribution of Selected Sums &amp; Expectations</li>
</ul>
<p><span class="math display">\[
\begin{align}
&amp;X_i \sim iid \ Bern(\theta) =⇒ E(X_i) = \theta; \ Var(X_i) = \theta(1 − \theta); \ and \ \sum_{i=1}^{n} X_i \sim Bin(n, \theta)\\
&amp;X_i \sim iid \ Geom(\theta) =⇒ E(X_i) = \frac{1}{\theta}; \ Var(Xi) =\frac{1 − \theta}{\theta^2}; \ and \ \sum_{i=1}^{n} X_i \sim NegBin(n, \theta)\\
&amp;X_i \sim iid \ Poi(\lambda) =⇒ E(X_i) = \lambda; \ Var(X_i) = \lambda; \ and \ \sum_{i=1}^{n} X_i \sim  Poi(n\lambda)\\
&amp;X_i \sim iid \ Expon(\lambda) =⇒ E(X_i) = \frac{1}{\lambda}; \ Var(X_i) = \frac{1}{\lambda^2}; \ and \ \sum_{i=1}^{n} X_i \sim Gamma(n, \lambda)\\
&amp;X_i \sim iid \ NegBin(k, \theta) =⇒ E(X_i) = \frac{k}{\theta};\ Var(X_i) = \frac{k(1 − \theta)}{\theta^2}; \ and \sum_{i=1}^{n} X_i \sim NegBin(n, \theta)\\
\end{align}
\]</span></p>
<ol style="list-style-type: decimal">
<li>Suppose <span class="math inline">\(X \sim Gam(\alpha, \lambda)\)</span>;<br />
</li>
</ol>
<p><span class="math display">\[
f_X(x)=\frac{x^{\alpha−1} \lambda^{\alpha} e^{-\lambda x}}{\Gamma(\alpha)}I_{(0,\infty)}(x),
\]</span></p>
<p>where <span class="math inline">\(\alpha &gt; 0\)</span> and <span class="math inline">\(\lambda &gt; 0\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Verify that the mgf of <span class="math inline">\(X\)</span> is</li>
</ol>
<p><span class="math display">\[
\psi_X (t)=(\frac{\lambda}{\lambda-t})^\alpha.
\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>For what values of t does the mgf exist?</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(W_1, \ldots , W_n\)</span> is a random sample of size <span class="math inline">\(n\)</span> from <span class="math inline">\(Exp(\lambda)\)</span>;</li>
</ol>
<p><span class="math display">\[
f_W (w) = \lambda e^{−\lambda w}I_{(0,\infty)}(w),
\]</span></p>
<p>where <span class="math inline">\(\lambda &gt; 0\)</span>. Use mgfs to obtain the distribution of <span class="math inline">\(Y =\sum_{i=1}^{n} W_i\)</span>.
Hint: The mgf of <span class="math inline">\(W\)</span> can be obtained from question #1 because the exponential distribution is a special case of the gamma distribution.</p>
<ol start="3" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X\)</span> is a random variable with mgf</li>
</ol>
<p><span class="math display">\[
\psi_X (t) = \frac{1}{1-t}.
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Give the pdf of <span class="math inline">\(X\)</span>.</p></li>
<li><p>Derive an expression for <span class="math inline">\(E(X^r)\)</span>; <span class="math inline">\(r = 0, 1, 2, \ldots.\)</span></p></li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X \sim N(\mu_X, \sigma^2_X)\)</span>; <span class="math inline">\(Y \sim N(\mu_Y, \sigma^2_Y)\)</span>; and that <span class="math inline">\(X \Perp Y\)</span>. The mgf of <span class="math inline">\(X\)</span> is</li>
</ol>
<p><span class="math display">\[
\psi_X(t) = exp\left \{t\mu_X+\frac{t^2\sigma^2_X}{2}\right \}
\]</span></p>
<p>C.3. EXAM 2</p>
<ol style="list-style-type: lower-alpha">
<li><p>Verify that <span class="math inline">\(E(X) = \mu_X\)</span> and that <span class="math inline">\(Var(X) = \sigma^2_X\)</span>.</p></li>
<li><p>Prove that <span class="math inline">\(X − Y \sim N(\mu_X − \mu_Y , \sigma^2_X + \sigma^2_Y)\)</span>.</p></li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X \sim LogN(\mu, \sigma^2)\)</span>. Compute</li>
</ol>
<p><span class="math display">\[
Pr(e^\mu≤ X ≤ e^{\mu+\sigma})
\]</span></p>
<ol start="6" style="list-style-type: decimal">
<li>Let <span class="math inline">\(W_i\)</span> for <span class="math inline">\(i = 1, \ldots , n\)</span> and <span class="math inline">\(X_i\)</span> for <span class="math inline">\(i = 1, \ldots , m\)</span> be iid random variables, each with distribution <span class="math inline">\(N(0, \sigma^2)\)</span>.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Give the distribution of</li>
</ol>
<p><span class="math display">\[
U =\sum_{i=1}^{n}(\frac{W_i}{\sigma})^2
\]</span></p>
<p>Justify your answer. Hint: First give the distribution of <span class="math inline">\(W_i/\sigma\)</span>.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Give the distribution of</li>
</ol>
<p><span class="math display">\[
V =(\frac{m}{n})(\frac{\sum_{i=1}^{n}W^2_i}{\sum_{i=1}^{m}X^2_i})
\]</span></p>
<p>Justify your answer.</p>
<ol start="7" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X_i\)</span> is a random sample of size <span class="math inline">\(n\)</span> from an infinite sized population having mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Let <span class="math inline">\(\bar X\)</span> be the sample mean.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Verify that <span class="math inline">\(E(\bar X) = \mu\)</span></p></li>
<li><p>Verify that <span class="math inline">\(Var(\bar X) = \sigma^2/n\)</span></p></li>
<li><p>Let <span class="math inline">\(S^2\)</span> be the sample variance;</p></li>
</ol>
<p><span class="math display">\[
S^2=\frac{1}{n-1} \sum_{i=1}^{n}(X_i-\bar X)^2=\frac{1}{n-1}[\sum_{i=1}^{n}X^2_i-n\bar X^2].
\]</span></p>
<p>Verify that <span class="math inline">\(E(S^2) = \sigma^2\)</span>.</p>
<ol start="7" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X_i\)</span> is a random sample of size <span class="math inline">\(n\)</span> from an infinite sized population having mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Let <span class="math inline">\(\bar X\)</span> be the sample mean.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Verify that <span class="math inline">\(E(\bar X) = \mu\)</span></p></li>
<li><p>Verify that <span class="math inline">\(Var(\bar X) = \sigma^2/n.\)</span></p></li>
<li><p>Let <span class="math inline">\(S^2\)</span> be the sample variance;</p></li>
</ol>
<p><span class="math display">\[
S^2=\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar X)^2=\frac{1}{n-1}[\sum_{i=1}^{n}X^2_i-n\bar X^2].
\]</span></p>
<p>Verify that <span class="math inline">\(E(S^2) = \sigma^2\)</span>.</p>
<p>C.3 Exam 2</p>
<ol style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X_1, X_2, \ldots , X_n\)</span> is a random sample of size <span class="math inline">\(n\)</span> from <span class="math inline">\(f_X (x|\alpha, \beta)\)</span>, where</li>
</ol>
<p><span class="math display">\[
f_X (x|\alpha, \beta) =\frac{\alpha\beta^\alpha}{x^{\alpha+1}}I_{(\beta,\infty)}(x),
\]</span></p>
<p>where <span class="math inline">\(\alpha &gt; 0\)</span> and <span class="math inline">\(\beta &gt; 0\)</span> are unknown parameters. This distribution is called the Pareto<span class="math inline">\((\alpha, \beta)\)</span> distribution.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Find a two dimensional sufficient statistic.</p></li>
<li><p>Verify that the pdf of <span class="math inline">\(X_{(1)}\)</span> is Pareto<span class="math inline">\((n\alpha, \beta)\)</span>. That is,</p></li>
</ol>
<p><span class="math display">\[
f_{X(1)} (x|\alpha, \beta) = \frac{n\alpha\beta^{n\alpha}}{x^{n\alpha+1}}I_{(\beta,\infty)}(x).
\]</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>The joint sampling distribution of the sufficient statistics can be studied using simulation. Let <span class="math inline">\(U_1, U_2, \ldots , U_n\)</span> be a random sample from <span class="math inline">\(Unif(0, 1)\)</span>. Show how <span class="math inline">\(U_i\)</span> can be transformed into a random variable having a <span class="math inline">\(Pareto(\alpha, \beta)\)</span> distribution.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X \sim Gamma(\alpha, \lambda)\)</span>, where <span class="math inline">\(\lambda\)</span> is known.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Verify that the distribution of X belongs to the exponential family.</p></li>
<li><p>Let <span class="math inline">\(X_1, X_2, \ldots , X_n\)</span> be a random sample from the <span class="math inline">\(Gamma(\alpha, \lambda)\)</span> distribution, where <span class="math inline">\(\lambda\)</span> is known. Use the results from part (a) to find a sufficient statistic.</p></li>
<li><p>Give the likelihood function that corresponds to part (b).</p></li>
</ol>
<p><span class="math display">\[
f_{X|\theta}(x|\theta) = \theta(1 − \theta)^{x−1}I_{1,2,...}(x).
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Verify that <span class="math inline">\(T =\sum_{i=1}^{n}\)</span> is a sufficient statistic.</p></li>
<li><p>Verify that the conditional distribution <span class="math inline">\(P(X = x|T = t)\)</span> does not depend on <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Suppose that the investigator’s prior beliefs about <span class="math inline">\(\theta\)</span> can be summarized as <span class="math inline">\(\theta \sim Beta(\alpha, \beta)\)</span>.</p></li>
</ol>
<p>Find the posterior distribution of <span class="math inline">\(\theta\)</span> and find the expectation of <span class="math inline">\(\theta\)</span> conditional on <span class="math inline">\(T = t\)</span>.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Let <span class="math inline">\(Z_1, Z_2, \ldots , Z_k\)</span> be a sequence of future <span class="math inline">\(Geom(\theta)\)</span> random variables and let <span class="math inline">\(Y=\sum_{i=1}^{k} Z_i\)</span>. Find the posterior predictive distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(T\)</span>. That is, find <span class="math inline">\(f_{Y |T} (y|t)\)</span>.</li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Let <span class="math inline">\(X_1, X_2, \ldots , X_n\)</span> be a random sample of size <span class="math inline">\(n\)</span> from a distribution having mean <span class="math inline">\(\mu\)</span>, variance <span class="math inline">\(\sigma^2\)</span>. Define <span class="math inline">\(Z_n\)</span> as</li>
</ol>
<p><span class="math display">\[
Z_n=\frac{\bar X − \mu}{\sigma/\sqrt{n}}.
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>State the central limit theorem.</p></li>
<li><p>Verify that</p></li>
</ol>
<p><span class="math display">\[
Z_n =\sum_{i=1}^{n}U_i,\ where  \ U_i=\frac{Z^∗_i}{\sqrt{n}} \ and \ Z^∗_i=\frac{X_i − \mu}{\sigma}.
\]</span></p>
<p>C.4. EXAM 3</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Assume that X has a moment generating function. Verify that</li>
</ol>
<p><span class="math display">\[
\psi_{Zn}(t) = [\psi_{Ui}(t)]^n.
\]</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li><p>Verify that the mean and variance of <span class="math inline">\(U_i\)</span> are 0 and <span class="math inline">\(n^{−1}\)</span>, respectively.</p></li>
<li><p>Complete the proof of the central limit theorem.</p></li>
</ol>
<p>C.4 Exam 3</p>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(X\)</span> be a random variable; let <span class="math inline">\(h(X)\)</span> be a non-negative function whose expectation exists; and let k be any positive number.
Chebyshev’s inequality reveals that</li>
</ol>
<p><span class="math display">\[
P [h(X) ≥ k] ≤ \frac{E [h(X)]}{k}
\]</span></p>
<p>or, equivalently, that</p>
<p><span class="math display">\[
P [h(X) &lt; k] ≥ 1-\frac{E [h(X)]}{k}.
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Define what it means for an estimator Tn to be consistent for a parameter <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Use Chebyshev’s inequality to verify that <span class="math inline">\(\underset{n\rightarrow\infty}{lim} \ MSE_{T_n}(\theta)=0 \Longrightarrow T_n \xrightarrow[]{prob} \theta\)</span>.</p></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X_1, X_2, \ldots , X_n\)</span> is a random sample from Bern<span class="math inline">\((\theta)\)</span>.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Give the likelihood function.</p></li>
<li><p>Find a sufficient statistic.</p></li>
<li><p>Verify that the score function is</p></li>
</ol>
<p><span class="math display">\[
S(\theta|X) =\frac{\sum_{i=1}^{n}X_i-n\theta}{\theta(1 − \theta)}
\]</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li><p>Derive the MLE of <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Derive the MLE of <span class="math inline">\(\frac{1}{\theta}\)</span>.</p></li>
<li><p>Derive Fisher’s information.</p></li>
<li><p>Verify or refute the claim that the MLE of <span class="math inline">\(\theta\)</span> is the minimum variance unbiased estimator of <span class="math inline">\(\theta\)</span>.</p></li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X_i \sim iid\)</span> <span class="math inline">\(Expon(\lambda)\)</span> for <span class="math inline">\(i = 1, \ldots , n\)</span>. It can be shown that <span class="math inline">\(Y =\sum_{i=1}^{n}Xi\)</span> is sufficient and that <span class="math inline">\(Y \sim Gamma(n, \lambda)\)</span>.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Derive the moment generating function of <span class="math inline">\(Q = 2\lambda \ \sum_{i=1}^{n} Xi\)</span> and verify that <span class="math inline">\(Q\)</span> is a pivotal quantity. Use the moment generating function of <span class="math inline">\(Q\)</span> to determine its distribution.</p></li>
<li><p>Use <span class="math inline">\(Q\)</span> to find a <span class="math inline">\(100(1 − \alpha)\%\)</span> confidence interval for <span class="math inline">\(\lambda\)</span>.</p></li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Suppose that <span class="math inline">\(X_1, X_2, \ldots , X_n\)</span> is a random sample from <span class="math inline">\(f_X (x|\theta)\)</span>, where</li>
</ol>
<p><span class="math display">\[
f_X (x|\theta) = \theta x^{\theta−1} I_{(0,1)}(x) \ and \ \theta &gt; 0.
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Verify or refute the claim that the distribution of <span class="math inline">\(X\)</span> belongs to the exponential class.</p></li>
<li><p>Find the most powerful test of <span class="math inline">\(H_0 : \theta = \theta_0\)</span> versus <span class="math inline">\(H_a : \theta = \theta_a\)</span>, where <span class="math inline">\(\theta_a &gt; \theta_0\)</span>.</p></li>
<li><p>Find the most uniformly powerful test of <span class="math inline">\(H_0 : \theta = \theta_0\)</span> versus <span class="math inline">\(H_a : \theta &gt; \theta_0\)</span>.</p></li>
<li><p>Suppose that the investigator’s prior beliefs about <span class="math inline">\(\theta\)</span> can be summarized as <span class="math inline">\(\theta \sim Gamma(\alpha, \lambda)\)</span>.</p></li>
</ol>
<p>Find the posterior distribution of <span class="math inline">\(\theta\)</span>. Hint: write xi as <span class="math inline">\(x_i = e^{ln(x_i)}\)</span>.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Find the Bayes estimator of <span class="math inline">\(\theta\)</span> based on a squared error loss function.</li>
</ol>
<!-------------------------------------->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter11.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Mathematical Statistics.pdf", "Mathematical Statistics.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
