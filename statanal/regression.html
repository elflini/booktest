<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 회귀분석 | Statistical Analysis</title>
  <meta name="description" content="This is a Statistical Analysis" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 회귀분석 | Statistical Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a Statistical Analysis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 회귀분석 | Statistical Analysis" />
  
  <meta name="twitter:description" content="This is a Statistical Analysis" />
  

<meta name="author" content="Jin Hyun Nam" />


<meta name="date" content="2023-02-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="category.html"/>
<link rel="next" href="glm.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>머리말</a></li>
<li class="chapter" data-level="1" data-path="ttest.html"><a href="ttest.html"><i class="fa fa-check"></i><b>1</b> 평균차이 검정</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ttest.html"><a href="ttest.html#일표본-t-검정"><i class="fa fa-check"></i><b>1.1</b> 일표본 <span class="math inline">\(t\)</span>-검정</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="ttest.html"><a href="ttest.html#with-r"><i class="fa fa-check"></i><b>1.1.1</b> With R</a></li>
<li class="chapter" data-level="1.1.2" data-path="ttest.html"><a href="ttest.html#with-sas"><i class="fa fa-check"></i><b>1.1.2</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="ttest.html"><a href="ttest.html#독립표본-t-검정"><i class="fa fa-check"></i><b>1.2</b> 독립표본 <span class="math inline">\(t\)</span>-검정</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="ttest.html"><a href="ttest.html#두-모분산-비의-검정"><i class="fa fa-check"></i><b>1.2.1</b> 두 모분산 비의 검정</a></li>
<li class="chapter" data-level="1.2.2" data-path="ttest.html"><a href="ttest.html#with-r-1"><i class="fa fa-check"></i><b>1.2.2</b> With R</a></li>
<li class="chapter" data-level="1.2.3" data-path="ttest.html"><a href="ttest.html#with-sas-1"><i class="fa fa-check"></i><b>1.2.3</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ttest.html"><a href="ttest.html#대응표본-t-검정"><i class="fa fa-check"></i><b>1.3</b> 대응표본 <span class="math inline">\(t\)</span>-검정</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="ttest.html"><a href="ttest.html#with-r-2"><i class="fa fa-check"></i><b>1.3.1</b> With R</a></li>
<li class="chapter" data-level="1.3.2" data-path="ttest.html"><a href="ttest.html#with-sas-2"><i class="fa fa-check"></i><b>1.3.2</b> with SAS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>2</b> 분산분석</a>
<ul>
<li class="chapter" data-level="2.1" data-path="anova.html"><a href="anova.html#분산분석"><i class="fa fa-check"></i><b>2.1</b> 분산분석</a></li>
<li class="chapter" data-level="2.2" data-path="anova.html"><a href="anova.html#일원배치-분산분석"><i class="fa fa-check"></i><b>2.2</b> 일원배치 분산분석</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="anova.html"><a href="anova.html#사후분석다중검정"><i class="fa fa-check"></i><b>2.2.1</b> 사후분석(다중검정)</a></li>
<li class="chapter" data-level="2.2.2" data-path="anova.html"><a href="anova.html#with-r-3"><i class="fa fa-check"></i><b>2.2.2</b> With R</a></li>
<li class="chapter" data-level="2.2.3" data-path="anova.html"><a href="anova.html#with-sas-3"><i class="fa fa-check"></i><b>2.2.3</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="anova.html"><a href="anova.html#이원배치-분산분석"><i class="fa fa-check"></i><b>2.3</b> 이원배치 분산분석</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="anova.html"><a href="anova.html#교호작용"><i class="fa fa-check"></i><b>2.3.1</b> 교호작용</a></li>
<li class="chapter" data-level="2.3.2" data-path="anova.html"><a href="anova.html#with-r-4"><i class="fa fa-check"></i><b>2.3.2</b> With R</a></li>
<li class="chapter" data-level="2.3.3" data-path="anova.html"><a href="anova.html#with-sas-4"><i class="fa fa-check"></i><b>2.3.3</b> With SAS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="nonpara.html"><a href="nonpara.html"><i class="fa fa-check"></i><b>3</b> 비모수 검정</a>
<ul>
<li class="chapter" data-level="3.1" data-path="nonpara.html"><a href="nonpara.html#정규성-검정"><i class="fa fa-check"></i><b>3.1</b> 정규성 검정</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="nonpara.html"><a href="nonpara.html#with-r-5"><i class="fa fa-check"></i><b>3.1.1</b> With R</a></li>
<li class="chapter" data-level="3.1.2" data-path="nonpara.html"><a href="nonpara.html#with-sas-5"><i class="fa fa-check"></i><b>3.1.2</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="nonpara.html"><a href="nonpara.html#윌콕슨-부호순위-검정"><i class="fa fa-check"></i><b>3.2</b> 윌콕슨 부호순위 검정</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="nonpara.html"><a href="nonpara.html#with-r-6"><i class="fa fa-check"></i><b>3.2.1</b> With R</a></li>
<li class="chapter" data-level="3.2.2" data-path="nonpara.html"><a href="nonpara.html#with-sas-6"><i class="fa fa-check"></i><b>3.2.2</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="nonpara.html"><a href="nonpara.html#윌콕슨-순위합-검정"><i class="fa fa-check"></i><b>3.3</b> 윌콕슨 순위합 검정</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="nonpara.html"><a href="nonpara.html#with-r-7"><i class="fa fa-check"></i><b>3.3.1</b> With R</a></li>
<li class="chapter" data-level="3.3.2" data-path="nonpara.html"><a href="nonpara.html#with-sas-7"><i class="fa fa-check"></i><b>3.3.2</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="nonpara.html"><a href="nonpara.html#크루스칼-왈리스-검정"><i class="fa fa-check"></i><b>3.4</b> 크루스칼-왈리스 검정</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="nonpara.html"><a href="nonpara.html#with-r-8"><i class="fa fa-check"></i><b>3.4.1</b> With R</a></li>
<li class="chapter" data-level="3.4.2" data-path="nonpara.html"><a href="nonpara.html#with-sas-8"><i class="fa fa-check"></i><b>3.4.2</b> With SAS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="category.html"><a href="category.html"><i class="fa fa-check"></i><b>4</b> 분할표 검정</a>
<ul>
<li class="chapter" data-level="4.1" data-path="category.html"><a href="category.html#상대위험률과-오즈비"><i class="fa fa-check"></i><b>4.1</b> 상대위험률과 오즈비</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="category.html"><a href="category.html#상대위험률"><i class="fa fa-check"></i><b>4.1.1</b> 상대위험률</a></li>
<li class="chapter" data-level="4.1.2" data-path="category.html"><a href="category.html#오즈비"><i class="fa fa-check"></i><b>4.1.2</b> 오즈비</a></li>
<li class="chapter" data-level="4.1.3" data-path="category.html"><a href="category.html#with-r-9"><i class="fa fa-check"></i><b>4.1.3</b> With R</a></li>
<li class="chapter" data-level="4.1.4" data-path="category.html"><a href="category.html#with-sas-9"><i class="fa fa-check"></i><b>4.1.4</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="category.html"><a href="category.html#독립성-검정"><i class="fa fa-check"></i><b>4.2</b> 독립성 검정</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="category.html"><a href="category.html#with-r-10"><i class="fa fa-check"></i><b>4.2.1</b> With R</a></li>
<li class="chapter" data-level="4.2.2" data-path="category.html"><a href="category.html#with-sas-10"><i class="fa fa-check"></i><b>4.2.2</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="category.html"><a href="category.html#동질성-검정"><i class="fa fa-check"></i><b>4.3</b> 동질성 검정</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="category.html"><a href="category.html#with-r-11"><i class="fa fa-check"></i><b>4.3.1</b> With R</a></li>
<li class="chapter" data-level="4.3.2" data-path="category.html"><a href="category.html#with-sas-11"><i class="fa fa-check"></i><b>4.3.2</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="category.html"><a href="category.html#fisher의-정확-검정"><i class="fa fa-check"></i><b>4.4</b> Fisher의 정확 검정</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="category.html"><a href="category.html#with-r-12"><i class="fa fa-check"></i><b>4.4.1</b> With R</a></li>
<li class="chapter" data-level="4.4.2" data-path="category.html"><a href="category.html#with-sas-12"><i class="fa fa-check"></i><b>4.4.2</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="category.html"><a href="category.html#맥니마-검정"><i class="fa fa-check"></i><b>4.5</b> 맥니마 검정</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="category.html"><a href="category.html#이론적-배경"><i class="fa fa-check"></i><b>4.5.1</b> 이론적 배경</a></li>
<li class="chapter" data-level="4.5.2" data-path="category.html"><a href="category.html#with-r-13"><i class="fa fa-check"></i><b>4.5.2</b> With R</a></li>
<li class="chapter" data-level="4.5.3" data-path="category.html"><a href="category.html#with-sas-13"><i class="fa fa-check"></i><b>4.5.3</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="category.html"><a href="category.html#cochran-mantel-haenzel-test"><i class="fa fa-check"></i><b>4.6</b> Cochran-Mantel-Haenzel test</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="category.html"><a href="category.html#with-r-14"><i class="fa fa-check"></i><b>4.6.1</b> With R</a></li>
<li class="chapter" data-level="4.6.2" data-path="category.html"><a href="category.html#with-sas-14"><i class="fa fa-check"></i><b>4.6.2</b> With SAS</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="category.html"><a href="category.html#진단법의-평가"><i class="fa fa-check"></i><b>4.7</b> 진단법의 평가</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="category.html"><a href="category.html#민감도와-특이도"><i class="fa fa-check"></i><b>4.7.1</b> 민감도와 특이도</a></li>
<li class="chapter" data-level="4.7.2" data-path="category.html"><a href="category.html#양성예측도와-음성예측도"><i class="fa fa-check"></i><b>4.7.2</b> 양성예측도와 음성예측도</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>5</b> 회귀분석</a>
<ul>
<li class="chapter" data-level="5.1" data-path="regression.html"><a href="regression.html#상관분석"><i class="fa fa-check"></i><b>5.1</b> 상관분석</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="regression.html"><a href="regression.html#상관계수"><i class="fa fa-check"></i><b>5.1.1</b> 상관계수</a></li>
<li class="chapter" data-level="5.1.2" data-path="regression.html"><a href="regression.html#스피어만-상관계수"><i class="fa fa-check"></i><b>5.1.2</b> 스피어만 상관계수</a></li>
<li class="chapter" data-level="5.1.3" data-path="regression.html"><a href="regression.html#켄달의-타우"><i class="fa fa-check"></i><b>5.1.3</b> 켄달의 타우</a></li>
<li class="chapter" data-level="5.1.4" data-path="regression.html"><a href="regression.html#편상관계수"><i class="fa fa-check"></i><b>5.1.4</b> 편상관계수</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="regression.html"><a href="regression.html#단순선형회귀분석"><i class="fa fa-check"></i><b>5.2</b> 단순선형회귀분석</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="regression.html"><a href="regression.html#최소제곱법"><i class="fa fa-check"></i><b>5.2.1</b> 최소제곱법</a></li>
<li class="chapter" data-level="5.2.2" data-path="regression.html"><a href="regression.html#회귀계수-추정"><i class="fa fa-check"></i><b>5.2.2</b> 회귀계수 추정</a></li>
<li class="chapter" data-level="5.2.3" data-path="regression.html"><a href="regression.html#회귀계수-가설검정"><i class="fa fa-check"></i><b>5.2.3</b> 회귀계수 가설검정</a></li>
<li class="chapter" data-level="5.2.4" data-path="regression.html"><a href="regression.html#결정계수"><i class="fa fa-check"></i><b>5.2.4</b> 결정계수</a></li>
<li class="chapter" data-level="5.2.5" data-path="regression.html"><a href="regression.html#예제"><i class="fa fa-check"></i><b>5.2.5</b> 예제</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="regression.html"><a href="regression.html#다중선형회귀분석"><i class="fa fa-check"></i><b>5.3</b> 다중선형회귀분석</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="regression.html"><a href="regression.html#변수-선택"><i class="fa fa-check"></i><b>5.3.1</b> 변수 선택</a></li>
<li class="chapter" data-level="5.3.2" data-path="regression.html"><a href="regression.html#결정계수-1"><i class="fa fa-check"></i><b>5.3.2</b> 결정계수</a></li>
<li class="chapter" data-level="5.3.3" data-path="regression.html"><a href="regression.html#표준화-회귀계수"><i class="fa fa-check"></i><b>5.3.3</b> 표준화 회귀계수</a></li>
<li class="chapter" data-level="5.3.4" data-path="regression.html"><a href="regression.html#다중공선성"><i class="fa fa-check"></i><b>5.3.4</b> 다중공선성</a></li>
<li class="chapter" data-level="5.3.5" data-path="regression.html"><a href="regression.html#더미변수가변수"><i class="fa fa-check"></i><b>5.3.5</b> 더미변수(가변수)</a></li>
<li class="chapter" data-level="5.3.6" data-path="regression.html"><a href="regression.html#회귀모형에-대한-가정-검토"><i class="fa fa-check"></i><b>5.3.6</b> 회귀모형에 대한 가정 검토</a></li>
<li class="chapter" data-level="5.3.7" data-path="regression.html"><a href="regression.html#예제-1"><i class="fa fa-check"></i><b>5.3.7</b> 예제</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>6</b> 일반화 선형모형</a>
<ul>
<li class="chapter" data-level="6.1" data-path="glm.html"><a href="glm.html#the-generalized-linear-models"><i class="fa fa-check"></i><b>6.1</b> The Generalized Linear models</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="glm.html"><a href="glm.html#the-general-linear-model"><i class="fa fa-check"></i><b>6.1.1</b> The General Linear Model</a></li>
<li class="chapter" data-level="6.1.2" data-path="glm.html"><a href="glm.html#generalized-linear-models-glms"><i class="fa fa-check"></i><b>6.1.2</b> Generalized Linear Models (GLMs)</a></li>
<li class="chapter" data-level="6.1.3" data-path="glm.html"><a href="glm.html#normal-glms-as-a-special-case"><i class="fa fa-check"></i><b>6.1.3</b> Normal GLMs as a Special Case</a></li>
<li class="chapter" data-level="6.1.4" data-path="glm.html"><a href="glm.html#modelling-binomial-data"><i class="fa fa-check"></i><b>6.1.4</b> Modelling Binomial Data</a></li>
<li class="chapter" data-level="6.1.5" data-path="glm.html"><a href="glm.html#modelling-poisson-data"><i class="fa fa-check"></i><b>6.1.5</b> Modelling Poisson Data</a></li>
<li class="chapter" data-level="6.1.6" data-path="glm.html"><a href="glm.html#transformation-vs.-glms"><i class="fa fa-check"></i><b>6.1.6</b> Transformation vs. GLMs</a></li>
<li class="chapter" data-level="6.1.7" data-path="glm.html"><a href="glm.html#exponential-family"><i class="fa fa-check"></i><b>6.1.7</b> Exponential Family</a></li>
<li class="chapter" data-level="6.1.8" data-path="glm.html"><a href="glm.html#canonical-links"><i class="fa fa-check"></i><b>6.1.8</b> Canonical Links</a></li>
<li class="chapter" data-level="6.1.9" data-path="glm.html"><a href="glm.html#estimation-of-the-model-parameters"><i class="fa fa-check"></i><b>6.1.9</b> Estimation of the Model Parameters</a></li>
<li class="chapter" data-level="6.1.10" data-path="glm.html"><a href="glm.html#distribution-and-link-function"><i class="fa fa-check"></i><b>6.1.10</b> Distribution and Link Function</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="glm.html"><a href="glm.html#medical-cost-data-analysis"><i class="fa fa-check"></i><b>6.2</b> Medical Cost Data Analysis</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="glm.html"><a href="glm.html#health-care-cost"><i class="fa fa-check"></i><b>6.2.1</b> health care cost</a></li>
<li class="chapter" data-level="6.2.2" data-path="glm.html"><a href="glm.html#regression-analysis-with-log-transformation"><i class="fa fa-check"></i><b>6.2.2</b> Regression analysis with log transformation</a></li>
<li class="chapter" data-level="6.2.3" data-path="glm.html"><a href="glm.html#gamma-generalized-linear-models"><i class="fa fa-check"></i><b>6.2.3</b> Gamma generalized linear models</a></li>
<li class="chapter" data-level="6.2.4" data-path="glm.html"><a href="glm.html#transformation-vs.-glms-1"><i class="fa fa-check"></i><b>6.2.4</b> Transformation vs. GLMs</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="glm.html"><a href="glm.html#binary-and-categorical-data-analysis"><i class="fa fa-check"></i><b>6.3</b> Binary and Categorical data Analysis</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="glm.html"><a href="glm.html#overview-of-logistic-regression-model"><i class="fa fa-check"></i><b>6.3.1</b> Overview of Logistic Regression Model</a></li>
<li class="chapter" data-level="6.3.2" data-path="glm.html"><a href="glm.html#binary-outcomes"><i class="fa fa-check"></i><b>6.3.2</b> Binary Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="glm.html"><a href="glm.html#poisson-regression"><i class="fa fa-check"></i><b>6.4</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="glm.html"><a href="glm.html#example-danish-lung-cancer-counts"><i class="fa fa-check"></i><b>6.4.1</b> Example: Danish Lung Cancer Counts</a></li>
<li class="chapter" data-level="6.4.2" data-path="glm.html"><a href="glm.html#what-about-accounting-for-population-size"><i class="fa fa-check"></i><b>6.4.2</b> What About Accounting for Population Size?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="survival.html"><a href="survival.html"><i class="fa fa-check"></i><b>7</b> 생존분석</a>
<ul>
<li class="chapter" data-level="7.1" data-path="survival.html"><a href="survival.html#생존분석"><i class="fa fa-check"></i><b>7.1</b> 생존분석</a></li>
<li class="chapter" data-level="7.2" data-path="survival.html"><a href="survival.html#비모수적-생존함수-추정"><i class="fa fa-check"></i><b>7.2</b> 비모수적 생존함수 추정</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="survival.html"><a href="survival.html#생명표-방법"><i class="fa fa-check"></i><b>7.2.1</b> 생명표 방법</a></li>
<li class="chapter" data-level="7.2.2" data-path="survival.html"><a href="survival.html#누적한계추정법"><i class="fa fa-check"></i><b>7.2.2</b> 누적한계추정법</a></li>
<li class="chapter" data-level="7.2.3" data-path="survival.html"><a href="survival.html#생존분포-비교"><i class="fa fa-check"></i><b>7.2.3</b> 생존분포 비교</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="survival.html"><a href="survival.html#모수적-생존함수-추정과-회귀모형"><i class="fa fa-check"></i><b>7.3</b> 모수적 생존함수 추정과 회귀모형</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="survival.html"><a href="survival.html#지수분포"><i class="fa fa-check"></i><b>7.3.1</b> 지수분포</a></li>
<li class="chapter" data-level="7.3.2" data-path="survival.html"><a href="survival.html#와이블분포"><i class="fa fa-check"></i><b>7.3.2</b> 와이블분포</a></li>
<li class="chapter" data-level="7.3.3" data-path="survival.html"><a href="survival.html#감마분포"><i class="fa fa-check"></i><b>7.3.3</b> 감마분포</a></li>
<li class="chapter" data-level="7.3.4" data-path="survival.html"><a href="survival.html#로그정규분포"><i class="fa fa-check"></i><b>7.3.4</b> 로그정규분포</a></li>
<li class="chapter" data-level="7.3.5" data-path="survival.html"><a href="survival.html#로그로지스틱분포"><i class="fa fa-check"></i><b>7.3.5</b> 로그로지스틱분포</a></li>
<li class="chapter" data-level="7.3.6" data-path="survival.html"><a href="survival.html#곰페르츠분포"><i class="fa fa-check"></i><b>7.3.6</b> 곰페르츠분포</a></li>
<li class="chapter" data-level="7.3.7" data-path="survival.html"><a href="survival.html#회귀모형aft"><i class="fa fa-check"></i><b>7.3.7</b> 회귀모형(AFT)</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="survival.html"><a href="survival.html#cox-비례위험모형"><i class="fa fa-check"></i><b>7.4</b> Cox 비례위험모형</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="survival.html"><a href="survival.html#시간에-따라-변화하는-공변량이-있을-경우"><i class="fa fa-check"></i><b>7.4.1</b> 시간에 따라 변화하는 공변량이 있을 경우</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="survival.html"><a href="survival.html#경쟁위험모형"><i class="fa fa-check"></i><b>7.5</b> 경쟁위험모형</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="survival.html"><a href="survival.html#원인별-누적발생함수"><i class="fa fa-check"></i><b>7.5.1</b> 원인별 누적발생함수</a></li>
<li class="chapter" data-level="7.5.2" data-path="survival.html"><a href="survival.html#원인별-위험함수"><i class="fa fa-check"></i><b>7.5.2</b> 원인별 위험함수</a></li>
<li class="chapter" data-level="7.5.3" data-path="survival.html"><a href="survival.html#누적발생함수에-대한-회귀분석"><i class="fa fa-check"></i><b>7.5.3</b> 누적발생함수에 대한 회귀분석</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="survival.html"><a href="survival.html#sas-실습"><i class="fa fa-check"></i><b>7.6</b> SAS 실습</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="survival.html"><a href="survival.html#생명표-방법-1"><i class="fa fa-check"></i><b>7.6.1</b> 생명표 방법</a></li>
<li class="chapter" data-level="7.6.2" data-path="survival.html"><a href="survival.html#누적한계추정법-1"><i class="fa fa-check"></i><b>7.6.2</b> 누적한계추정법</a></li>
<li class="chapter" data-level="7.6.3" data-path="survival.html"><a href="survival.html#생존분포-비교-1"><i class="fa fa-check"></i><b>7.6.3</b> 생존분포 비교</a></li>
<li class="chapter" data-level="7.6.4" data-path="survival.html"><a href="survival.html#parametric-model"><i class="fa fa-check"></i><b>7.6.4</b> Parametric Model</a></li>
<li class="chapter" data-level="7.6.5" data-path="survival.html"><a href="survival.html#aft-model"><i class="fa fa-check"></i><b>7.6.5</b> AFT model</a></li>
<li class="chapter" data-level="7.6.6" data-path="survival.html"><a href="survival.html#cox-비례위험모형-1"><i class="fa fa-check"></i><b>7.6.6</b> Cox 비례위험모형</a></li>
<li class="chapter" data-level="7.6.7" data-path="survival.html"><a href="survival.html#cox-비례위험모형---time-dependent-covariate"><i class="fa fa-check"></i><b>7.6.7</b> Cox 비례위험모형 - time dependent covariate</a></li>
<li class="chapter" data-level="7.6.8" data-path="survival.html"><a href="survival.html#competing-risks"><i class="fa fa-check"></i><b>7.6.8</b> Competing Risks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="psm.html"><a href="psm.html"><i class="fa fa-check"></i><b>8</b> 성향점수(propensity score)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="psm.html"><a href="psm.html#observational-study"><i class="fa fa-check"></i><b>8.1</b> Observational Study?</a>
<ul>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#randomized-controlled-trials-gold-standard"><i class="fa fa-check"></i>Randomized Controlled Trials ("gold standard")</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#characteristics-of-rcts"><i class="fa fa-check"></i>Characteristics of RCTs</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#what-is-observational-data"><i class="fa fa-check"></i>What is Observational Data?</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#confounding-due-to-selection-bias"><i class="fa fa-check"></i>Confounding due to Selection Bias</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#impact-of-selection-bias-on-analytic-inferences"><i class="fa fa-check"></i>Impact of Selection Bias on Analytic Inferences</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#statistical-adjustment-for-observational-data"><i class="fa fa-check"></i>Statistical Adjustment for Observational Data</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#addressing-selection-bias-with-exact-matching"><i class="fa fa-check"></i>Addressing Selection Bias with Exact Matching</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#matching-on-specific-variables"><i class="fa fa-check"></i>Matching on Specific Variables</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#matching-on-specific-variables-1"><i class="fa fa-check"></i>Matching on Specific Variables</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="psm.html"><a href="psm.html#propensity-score"><i class="fa fa-check"></i><b>8.2</b> Propensity Score?</a>
<ul>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#general-procedure"><i class="fa fa-check"></i>General Procedure</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#choosing-variables-for-propensity-scores"><i class="fa fa-check"></i>Choosing Variables for Propensity Scores</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#calculate-propensity-score"><i class="fa fa-check"></i>Calculate Propensity Score</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#initial-checks-balance-across-groups"><i class="fa fa-check"></i>Initial Checks: Balance across Groups</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#check-balance-of-covariates"><i class="fa fa-check"></i>Check Balance of Covariates</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#assess-balance-with-standardized-differences"><i class="fa fa-check"></i>Assess Balance with Standardized Differences</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#balance-of-covariates-caution"><i class="fa fa-check"></i>Balance of Covariates: Caution</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#matching-and-weighting-strategies"><i class="fa fa-check"></i>Matching and Weighting Strategies</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#choices-when-matching-sample-by-propensity-score"><i class="fa fa-check"></i>Choices When Matching Sample by Propensity Score</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#which-strategy-to-chooose"><i class="fa fa-check"></i>Which Strategy to Chooose?</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#evaluate-balance-in-sample-matched-or-weighted"><i class="fa fa-check"></i>Evaluate Balance in Sample Matched or Weighted</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#visualization-of-standardized-differences"><i class="fa fa-check"></i>Visualization of Standardized Differences</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#plots-of-covariates-between-groups"><i class="fa fa-check"></i>Plots of Covariates between Groups</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="psm.html"><a href="psm.html#propensity-score-methods"><i class="fa fa-check"></i><b>8.3</b> Propensity Score Methods</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="psm.html"><a href="psm.html#propensity-score-matching"><i class="fa fa-check"></i><b>8.3.1</b> Propensity Score Matching</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#general-procedure-for-propensity-score-matching"><i class="fa fa-check"></i>General Procedure for Propensity Score Matching</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#greedy-matching"><i class="fa fa-check"></i>Greedy Matching</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#mahalanobis-metric-matching"><i class="fa fa-check"></i>Mahalanobis Metric Matching</a></li>
<li class="chapter" data-level="8.3.2" data-path="psm.html"><a href="psm.html#stratification-using-propensity-score"><i class="fa fa-check"></i><b>8.3.2</b> Stratification using Propensity Score</a></li>
<li class="chapter" data-level="8.3.3" data-path="psm.html"><a href="psm.html#inverse-probability-of-treatment-weighting"><i class="fa fa-check"></i><b>8.3.3</b> Inverse Probability of Treatment Weighting</a></li>
<li class="chapter" data-level="8.3.4" data-path="psm.html"><a href="psm.html#propensity-score-adjustment-as-covariate"><i class="fa fa-check"></i><b>8.3.4</b> Propensity Score Adjustment as Covariate</a></li>
<li class="chapter" data-level="8.3.5" data-path="psm.html"><a href="psm.html#property-of-propensity-score"><i class="fa fa-check"></i><b>8.3.5</b> Property of Propensity Score</a></li>
<li class="chapter" data-level="" data-path="psm.html"><a href="psm.html#property-of-observational-studies"><i class="fa fa-check"></i>Property of Observational Studies</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="psm.html"><a href="psm.html#practice---sas"><i class="fa fa-check"></i><b>8.4</b> Practice - SAS</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="psm.html"><a href="psm.html#greedy-nearest-neighbor-matching"><i class="fa fa-check"></i><b>8.4.1</b> Greedy Nearest Neighbor Matching</a></li>
<li class="chapter" data-level="8.4.2" data-path="psm.html"><a href="psm.html#propensity-score-stratification"><i class="fa fa-check"></i><b>8.4.2</b> Propensity Score Stratification</a></li>
<li class="chapter" data-level="8.4.3" data-path="psm.html"><a href="psm.html#inverse-probability-treatment-weighting"><i class="fa fa-check"></i><b>8.4.3</b> Inverse Probability Treatment Weighting</a></li>
<li class="chapter" data-level="8.4.4" data-path="psm.html"><a href="psm.html#matching-with-existing-propensity-scores"><i class="fa fa-check"></i><b>8.4.4</b> Matching with Existing propensity scores</a></li>
<li class="chapter" data-level="8.4.5" data-path="psm.html"><a href="psm.html#matching-with-existing-propensity-scores-1"><i class="fa fa-check"></i><b>8.4.5</b> Matching with Existing propensity scores</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> 회귀분석<a href="regression.html#regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="상관분석" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> 상관분석<a href="regression.html#상관분석" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="상관계수" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> 상관계수<a href="regression.html#상관계수" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>상관분석(correlation analysis)은 서로 관련된다고 예측되는 두 개의
수치형 변수들에 대해 선형적으로 얼마나 연관성이 있는지 알아보는 분석
방법</p></li>
<li><p>한 변수의 값이 증가할 때 다른 변수의 값도 증가하는 경향이 있는
경우에는 두 변수가 양의 상관관계가 있다고 하고, 한 변수의 값이
증가할 때 다른 변수의 값이 감소하는 경향이 있는 경우에는 두 변수가
음의 상관관계가 있다고 함</p></li>
<li><p>상관분석에 사용되는 변수의 척도는 원칙적으로 수치형이어야 함. 그러나
순서형 변수라 하더라도 각 범주들의 간격이 등간격이라고 볼 수 있거나,
몇 개의 순서형 변수들의 합으로 만들어진 변수는 상관분석이 가능</p></li>
<li><p>상관관계의 크기는 상관계수(correlation coefficient)로 표현</p></li>
<li><p>산점도(scatter plot)는 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>의 쌍으로 된 값
<span class="math inline">\((x_1,y_1), \cdots, (x_n ,y_n)\)</span>을 <span class="math inline">\(X, Y\)</span> 좌표평면위에 점으로 표시한
그림이며, 두 변수간 상관관계를 살펴보기에 적합</p></li>
<li><p><span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>의 산점도</p></li>
</ul>
<p><img src="regression/f1.jpg" style="width:65.0%" /></p>
<ul>
<li><p>이변량 상관계수(bivariate correlation coefficient)는 두 변수 간에
존재하는 상관계수를 의미</p></li>
<li><p>상관계수는 <span class="math inline">\(-1\)</span>과 <span class="math inline">\(1\)</span> 사이의 수치로 나타내며, 두 변수 사이의 관련성
중에서 직선관계의 정도만을 나타내기 때문에 두 변수 사이의 이차함수
관계이거나 또는 직선이 아닌 다른 관계가 존재하면 상관계수는 <span class="math inline">\(0\)</span>의
값으로 나타남</p></li>
<li><p>상관계수에 따른 산점도</p></li>
</ul>
<p><img src="regression/f2.jpg" style="width:95.0%" /></p>
<ul>
<li><p>일반적으로 상관계수는 피어슨 상관계수(Pearson correlation
coefficient)를 의미</p></li>
<li><p>대표본이거나 각 변수의 모집단 분포가 정규분포에 가깝다고 판단되는
경우에 피어슨 상관계수를 사용하며, 소표본이면서 정규성 가정을 하기가
어려우면 스피어만(Spearman) 순위상관계수 혹은 켄달의 타우(Kendall’s
tau)를 사용</p></li>
<li><p>피어슨 상관계수
<span class="math display">\[\rho=\frac{\sigma_{XY}}{\sqrt{\sigma_X^2}\sqrt{\sigma_Y^2}}=\frac{\sigma_{XY}}{\sigma_X\sigma_Y}, \hskip3pt -1 \le \rho \le 1\]</span></p></li>
<li><p>표본상관계수
<span class="math display">\[r=\frac{S_{XY}}{\sqrt{S_X^2}\sqrt{S_Y^2}}=\frac{S_{XY}}{S_XS_Y}, \hskip3pt -1 \le r \le 1\]</span></p></li>
</ul>
<p>여기서 <span class="math inline">\(S_X^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2\)</span>,
<span class="math inline">\(S_Y^2=\frac{1}{n-1}\sum_{i=1}^n(y_i-\bar{y})^2\)</span>,
<span class="math inline">\(S_{XY}=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})\)</span></p>
<ul>
<li><p>가설</p>
<ul>
<li><p><span class="math inline">\(H_0 : \rho=0\)</span> (두 변수간 상관관계가 없다)</p></li>
<li><p><span class="math inline">\(H_1 : \rho\ne 0\)</span> (두 변수간 상관관계가 있다) 또는 <span class="math inline">\(\rho &gt;0\)</span> 또는
<span class="math inline">\(\rho &lt;0\)</span></p></li>
</ul></li>
<li><p>검정통계량 <span class="math display">\[T=\frac{r}{\sqrt{\frac{1-r^2}{n-2}}} \sim t(n-2)\]</span></p></li>
<li><p>기각역(양측) <span class="math display">\[|T| &gt; t_{\alpha/2,n-2 }\]</span></p></li>
<li><p>기각역(단측)
<span class="math display">\[T &gt; t_{\alpha,n-2 } \quad \text{또는} \quad T &lt; -t_{\alpha,n-2 }\]</span></p></li>
</ul>
<p><br></p>
<p><br></p>
<p>예제) 다음은 <span class="math inline">\(322\)</span>명의 건강한 성인의 건강검진 자료이다. 자료에는 나이, 키,
몸무게, 허리둘레, BMI, 수축기 혈압 등의 정보가 담겨져 있다.허리둘레와
BMI의 산점도를 그리고 상관관계를 분석하라.</p>
<p><img src="regression/ex1.jpg" style="width:50.0%" /></p>
<div id="with-r-15" class="section level4 hasAnchor" number="5.1.1.1">
<h4><span class="header-section-number">5.1.1.1</span> With R<a href="regression.html#with-r-15" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>데이터 입력</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="regression.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#reg_data &lt;- read.csv(&quot;https://elflini.github.io/study/statanal/data/5.%20correlation_and_regression.csv&quot;, header=T)</span></span>
<span id="cb1-2"><a href="regression.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="regression.html#cb1-3" aria-hidden="true" tabindex="-1"></a>exdata <span class="ot">&lt;-</span> <span class="fu">url</span>(<span class="st">&quot;https://elflini.github.io/study/statanal/data/reg_data.rda&quot;</span>)</span>
<span id="cb1-4"><a href="regression.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="at">file=</span>exdata)</span>
<span id="cb1-5"><a href="regression.html#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="regression.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(reg_data)</span></code></pre></div>
<pre><code>##   age height weight waistline  BMI SBP
## 1  57    164   62.0        85 23.1 147
## 2  25    172   54.0        65 18.3 116
## 3  57    157   59.0        83 23.9 122
## 4  43    170   87.8       104 30.4 130
## 5  52    155   50.0        83 20.8 120
## 6  27    163   76.0        83 28.6 128</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Scatterplot matrix</li>
</ol>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="regression.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(reg_data)</span></code></pre></div>
<p><img src="Statistical-Analysis_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<ol start="3" style="list-style-type: decimal">
<li>상관분석</li>
</ol>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="regression.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor.test</span>(<span class="sc">~</span>waistline<span class="sc">+</span>BMI, <span class="at">data=</span>reg_data)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  waistline and BMI
## t = 23.906, df = 320, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7576655 0.8367351
## sample estimates:
##     cor 
## 0.80066</code></pre>
<p>결과를 살펴보면, 표본 상관계수는 0.80066으로 양의 상관관계가 높게 나타나며, P-valuesms &lt;.0001로 매우 유의하게 나타나는 것을 알 수 있다.</p>
</div>
<div id="with-sas-15" class="section level4 hasAnchor" number="5.1.1.2">
<h4><span class="header-section-number">5.1.1.2</span> With SAS<a href="regression.html#with-sas-15" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<blockquote>
<p>SAS Code</p>
</blockquote>
<pre><code>filename reg_data URL &quot;https://elflini.github.io/study/statanal/data/5.%20correlation_and_regression.csv&quot; termstr=crlf; 

proc import out=healthdata
datafile=reg_data
dbms=csv replace;
getnames=yes;
run;

proc sgscatter data=healthdata;
  title &quot;Scatterplot Matrix&quot;;
  matrix age height weight waistline bmi sbp;
run;

proc corr data=healthdata plots=matrix;
var waistline bmi;
run;</code></pre>
<p><img src="regression/ex2.jpg" style="width:55.0%" /></p>
<p><img src="regression/ex3.jpg" style="width:70.0%" /></p>
</div>
</div>
<div id="스피어만-상관계수" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> 스피어만 상관계수<a href="regression.html#스피어만-상관계수" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>소표본이거나 정규성 가정을 하기 어려운 경우, 특히 모집단의 분포가
대칭분포가 아니거나 대칭분포이지만 꼬리가 두터운 분포(상대적으로
아주 큰 값이나 작은 값이 <span class="math inline">\(1\%\)</span>이상 존재하는 경우)인 경우에는
비모수적 방법인 스피어만 순위상관계수(Spearman rank correlation
coefficient) 사용</p></li>
<li><p>두 변수 각각의 값이 <span class="math inline">\((x_1,y_1), \cdots, (x_n, y_n)\)</span>일 때
<span class="math inline">\(R=(r_1, \ldots, r_n)\)</span>을 <span class="math inline">\((x_1, \ldots, x_n)\)</span>의 순위,
<span class="math inline">\(S=(s_1,\ldots, s_n)\)</span>을 <span class="math inline">\((y_1, \ldots, y_n)\)</span>의 순위라 하자.</p></li>
<li><p>가설</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 독립이다.</p></li>
<li><p><span class="math inline">\(H_1\)</span>: 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 독립이 아니다.(상관관계가 있다)</p></li>
</ul></li>
<li><p>검정통계량 <span class="math display">\[r=\frac{S_{rs}}{S_rS_s}\]</span></p></li>
</ul>
<p>여기서 <span class="math inline">\(S_{rs}\)</span>는 <span class="math inline">\(R\)</span>과 <span class="math inline">\(S\)</span>의 공분산, <span class="math inline">\(S_r\)</span>과 <span class="math inline">\(S_s\)</span>는 각각 <span class="math inline">\(R\)</span>과
<span class="math inline">\(S\)</span>의 표준편차임</p>
<ul>
<li><p>만약 중복순위가 존재하지 않는다면 검정통계량은
<span class="math display">\[r=1-\frac{6\sum_{i=1}^n(R_i-S_i)^2}{n(n^2-1)}\]</span></p></li>
<li><p>스피어만 상관계수는 비모수적인 방법으로 스피어만 표를 통해 검정</p></li>
<li><p>만약 표본크기가 크다면 다음과 같이 근사 가능 <span class="math display">\[r \sim t(n-2)\]</span></p></li>
</ul>
</div>
<div id="켄달의-타우" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> 켄달의 타우<a href="regression.html#켄달의-타우" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>켄달의 타우(Kendall’s tau)는 측정형 변수나 순서형 변수들의
상관관계를 자료의 순위값에 의하여 계산하는 방법으로 주로 순서형
변수들의 상관관계를 나타냄</p></li>
<li><p>두 변수 각각의 값이 <span class="math inline">\((x_1,y_1), \cdots, (x_n, y_n)\)</span>일 때 모든
<span class="math inline">\(i&lt;j\)</span>에 대해 <span class="math inline">\(P=(x_i-x_j)(y_i-y_j)&gt;0\)</span>인 쌍의 개수이고
<span class="math inline">\(Q=(x_i-x_j)(y_i-y_j)&lt;0\)</span>인 쌍의 개수라 하자.</p></li>
<li><p>가설</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 독립이다.</p></li>
<li><p><span class="math inline">\(H_1\)</span>: 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 독립이 아니다.(상관관계가 있다)</p></li>
</ul></li>
<li><p>검정통계량 <span class="math display">\[\tau=\frac{P-Q}{P+Q}\]</span></p></li>
<li><p>스피어만과 마찬가지로 Kendall 표에 의해 검정</p></li>
</ul>
<p><br></p>
<p><br></p>
<p>예제) 다음은 6명의 건강한 성인의 나이와 수축기 혈압에 대한 자료이다. 나이와
수축기 혈압 사이에 상관관계가 있는지 검정하라.</p>
<p><img src="regression/ex4.jpg" style="width:40.0%" /></p>
<div id="with-r-16" class="section level4 hasAnchor" number="5.1.3.1">
<h4><span class="header-section-number">5.1.3.1</span> With R<a href="regression.html#with-r-16" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>데이터 입력</li>
</ol>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="regression.html#cb7-1" aria-hidden="true" tabindex="-1"></a>spearman <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="at">text=</span><span class="st">&#39;</span></span>
<span id="cb7-2"><a href="regression.html#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="st">patient age sbp</span></span>
<span id="cb7-3"><a href="regression.html#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="st">1 15 116</span></span>
<span id="cb7-4"><a href="regression.html#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="st">2 15 130</span></span>
<span id="cb7-5"><a href="regression.html#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="st">3 25 120</span></span>
<span id="cb7-6"><a href="regression.html#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="st">4 30 132</span></span>
<span id="cb7-7"><a href="regression.html#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="st">5 40 160</span></span>
<span id="cb7-8"><a href="regression.html#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="st">6 50 148&#39;</span>, <span class="at">header=</span>T</span>
<span id="cb7-9"><a href="regression.html#cb7-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-10"><a href="regression.html#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="regression.html#cb7-11" aria-hidden="true" tabindex="-1"></a>spearman</span></code></pre></div>
<pre><code>##   patient age sbp
## 1       1  15 116
## 2       2  15 130
## 3       3  25 120
## 4       4  30 132
## 5       5  40 160
## 6       6  50 148</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Spearman test</li>
</ol>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="regression.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor.test</span>(<span class="sc">~</span>age<span class="sc">+</span>sbp, <span class="at">data=</span>spearman, <span class="at">method=</span><span class="st">&quot;spearman&quot;</span>)</span></code></pre></div>
<pre><code>## Warning in cor.test.default(x = c(15L, 15L, 25L, 30L, 40L, 50L), y = c(116L, :
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  age and sbp
## S = 5.5766, p-value = 0.03606
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##      rho 
## 0.840668</code></pre>
<p>스피어만 상관계수는 0.840668로 나타나며, P-value는 0.03606으로 유의수준 5%하에서 유의한 것으로 나타난다.</p>
<ol start="3" style="list-style-type: decimal">
<li>Kendall tau test</li>
</ol>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="regression.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor.test</span>(<span class="sc">~</span>age<span class="sc">+</span>sbp, <span class="at">data=</span>spearman, <span class="at">method=</span><span class="st">&quot;kendall&quot;</span>)</span></code></pre></div>
<pre><code>## Warning in cor.test.default(x = c(15L, 15L, 25L, 30L, 40L, 50L), y = c(116L, :
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Kendall&#39;s rank correlation tau
## 
## data:  age and sbp
## z = 1.9127, p-value = 0.05578
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##       tau 
## 0.6900656</code></pre>
<p>켄달의 타우 값은 0.6907이며 P-value는 0.0558로 유의하지 않게 나타난다.</p>
</div>
<div id="with-sas-16" class="section level4 hasAnchor" number="5.1.3.2">
<h4><span class="header-section-number">5.1.3.2</span> With SAS<a href="regression.html#with-sas-16" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<blockquote>
<p>SAS Code</p>
</blockquote>
<pre><code>data healthdata;
input Patient   Age SBP;
cards;
1   15  116
2   15  130
3   25  120
4   30  132
5   40  160
6   50  148
;
run;

proc corr data=healthdata spearman kendall;
var age sbp;
run;</code></pre>
<p><img src="regression/ex6.jpg" style="width:55.0%" /></p>
</div>
</div>
<div id="편상관계수" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> 편상관계수<a href="regression.html#편상관계수" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>편상관계수(partial correlation coefficient)는 두 변수간의 상관성에
영향을 미치는 다른 변수를 통제하고 순수한 두 변수간의 상관관계를
의미함</p></li>
<li><p>세 변수 <span class="math inline">\(X_1, X_2, X_3\)</span>가 있다고 할 때 <span class="math inline">\(X_3\)</span>를 통제한 상태에서의
<span class="math inline">\(X_1\)</span>과 <span class="math inline">\(X_2\)</span>의 편상관계수
<span class="math display">\[r_{12,3}=\frac{r_{12}-r_{13}r_{23}}{\sqrt{1-r_{12}^2}\sqrt{1-r_{23}^2}}\]</span></p></li>
</ul>
<p>여기서 <span class="math inline">\(r_{ij}\)</span>는 <span class="math inline">\(X_i\)</span>와 <span class="math inline">\(X_j\)</span>간의 상관계수를 의미</p>
<ul>
<li><p>상관계수와 연관성 정도</p>
<ul>
<li><p><span class="math inline">\(1.0 \sim 0.7(-1.0\sim -0.7)\)</span> : 매우 강한 연관성</p></li>
<li><p><span class="math inline">\(0.7 \sim 0.4(-0.7\sim -0.4)\)</span> : 상당한 연관성</p></li>
<li><p><span class="math inline">\(0.4 \sim 0.2(-0.4\sim -0.2)\)</span> : 약간의 연관성</p></li>
<li><p><span class="math inline">\(0.2 \sim 0.0(-0.2\sim 0.0)\)</span> : 연관성이 없음</p></li>
</ul></li>
</ul>
<p><img src="regression/f3.jpg" style="width:90.0%" /></p>
<p><br></p>
<p><br></p>
<p>예제) 다음은 <span class="math inline">\(322\)</span>명의 건강한 성인의 건강검진 자료이다. 자료에는 나이, 키,
몸무게, 허리둘레, BMI, 수축기 혈압 등의 정보가 담겨져 있다. 체중의
영향을 고려한 허리둘레와 BMI의 편상관계수를 구하라.</p>
<p><img src="regression/ex1.jpg" style="width:50.0%" /></p>
<div id="with-r-17" class="section level4 hasAnchor" number="5.1.4.1">
<h4><span class="header-section-number">5.1.4.1</span> With R<a href="regression.html#with-r-17" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>데이터 입력</li>
</ol>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="regression.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#reg_data &lt;- read.csv(file=&quot;https://elflini.github.io/study/statanal/data/5.%20correlation_and_regression.csv&quot;, header=T)</span></span>
<span id="cb16-2"><a href="regression.html#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="regression.html#cb16-3" aria-hidden="true" tabindex="-1"></a>exdata <span class="ot">&lt;-</span> <span class="fu">url</span>(<span class="st">&quot;https://elflini.github.io/study/statanal/data/reg_data.rda&quot;</span>)</span>
<span id="cb16-4"><a href="regression.html#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="at">file=</span>exdata)</span>
<span id="cb16-5"><a href="regression.html#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="regression.html#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(reg_data)</span></code></pre></div>
<pre><code>##   age height weight waistline  BMI SBP
## 1  57    164   62.0        85 23.1 147
## 2  25    172   54.0        65 18.3 116
## 3  57    157   59.0        83 23.9 122
## 4  43    170   87.8       104 30.4 130
## 5  52    155   50.0        83 20.8 120
## 6  27    163   76.0        83 28.6 128</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>편상관계수</li>
</ol>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="regression.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ppcor)</span>
<span id="cb18-2"><a href="regression.html#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="regression.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(reg_data, <span class="fu">pcor.test</span>(waistline, BMI, weight))</span></code></pre></div>
<pre><code>##    estimate     p.value statistic   n gp  Method
## 1 0.5152468 3.64479e-23  10.73763 322  1 pearson</code></pre>
<p>편상관계수 추정량은 0.51525로 나타나며 P-value는 &lt;.0001로 매우 유의하게 나타난다.</p>
</div>
<div id="with-sas-17" class="section level4 hasAnchor" number="5.1.4.2">
<h4><span class="header-section-number">5.1.4.2</span> With SAS<a href="regression.html#with-sas-17" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<blockquote>
<p>SAS Code</p>
</blockquote>
<pre><code>filename reg_data URL &quot;https://elflini.github.io/study/statanal/data/5.%20correlation_and_regression.csv&quot; termstr=crlf; 

proc import out=healthdata
datafile=reg_data
dbms=csv replace;
getnames=yes;
run;

proc corr data=healthdata plots=matrix;
var waistline bmi;
partial weight;
run;</code></pre>
<p><img src="regression/ex8.jpg" style="width:80.0%" /></p>
</div>
</div>
</div>
<div id="단순선형회귀분석" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> 단순선형회귀분석<a href="regression.html#단순선형회귀분석" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>회귀모형(regression model)은 여러 개의 변수들 간의 관계를 나타내는
모형으로서 하나의 목적(종속, 반응) 변수 <span class="math inline">\(Y\)</span>를 설명한다고 생각되는
설명(독립) 변수 <span class="math inline">\(X_1, \ldots, X_n\)</span>의 선형 함수식으로 표현하는 통계적
모형</p></li>
<li><p>회귀모형은 선형회귀모형(linear regression model)과
비선형회귀모형(nonlinear regression model)이 있으며, <span class="math inline">\(Y\)</span>가
설명변수들의 선형함수식으로 표현되는 모형을 선형회귀모형,
설명변수들의 비선형함수식(다항함수, 지수함수, 로그함수 등)으로
표현되는 모형을 비선형회귀모형이라고 함</p></li>
<li><p>일반적으로 회귀분석은 선형회귀모형을 의미</p></li>
<li><p>회귀분석의 목적</p>
<ul>
<li><p>설명변수들과 반응변수 사이의 관계를 규정(기술적 목적)</p></li>
<li><p>설명변수들이 반응변수에 어떤 영향을 어느 정도 미치는지 설명</p></li>
<li><p>설명변수가 어떤 값으로 주어질 때 반응변수의 값은 얼마나 될지
예측</p></li>
</ul></li>
<li><p>선형회귀모형에서 설명변수가</p>
<ul>
<li><p>한 개만 포함된 경우: 단순선형회귀분석(simple linear regression)</p></li>
<li><p>두 개 이상이 포함된 경우: 다중선형회귀분석(multiple linear regression)</p></li>
</ul></li>
<li><p>회귀분석에서 사용되는 변수의 형태는 독립변수와 종속변수 모두
원칙적으로 수치형 변수를 사용해야 함</p></li>
<li><p>순서형 볌수의 경우 각 범주들의 간격이 등간격이거나, 몇 개의 순서형
변수들의 합으로 된 변수도 적용 가능</p>
<ul>
<li>독립변수의 경우 범주형 변수의 사용이 가능하나, 반드시 더미
변수(dummy variable) 형태로 바꾸어서 사용해야 함</li>
</ul></li>
<li><p>회귀분석을 위한 기본 가정</p>
<ul>
<li><p>독립변수 종속변수간의 선형적 관계</p>
<ul>
<li>회귀분석은 독립변수와 종속변수간의 선형식을 기반으로 함. 따라서
독립변수와 종속변수간의 선형관계를 가정할 수 있어야 함</li>
</ul></li>
<li><p>오차항의 등분산과 정규성</p>
<ul>
<li>오차항(error term)은 종속변수와 예측값 간의 차이를 의미. 이 오차항은
일정한 분산을 갖는 정규분포를 가정함</li>
</ul></li>
<li><p>오차항의 독립성</p>
<ul>
<li>오차항은 서로 독립이라는 가정이 필요</li>
</ul></li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li><p>단순선형회귀분석(simple linear regression analysis) : 하나의
목적변수에 대한 회귀모형을 만들 때 그 목적변수를 설명하는
독립변수로서 한 변수만을 고려하는 선형회귀모형을
단순선형회귀모형이라고 함</p></li>
<li><p>단순선형회귀모형</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
            y_i=\beta_0+\beta_1x_i+\epsilon_i , \,\,\, \epsilon_i \sim N(0, \sigma^2), \,\,\, i=1,\ldots, n
            \end{aligned}
\]</span></p>
<p><span class="math inline">\(\beta_0\)</span>: 절편(intercept), <span class="math inline">\(\beta_1\)</span>:
기울기(slope)</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>와 <span class="math inline">\(\beta_1\)</span>을 회귀모형의 모수 또는 회귀계수(regression
coefficient)라 함</li>
<li>기울기 <span class="math inline">\(\beta_1\)</span>은 독립변수 <span class="math inline">\(X\)</span>가 한 단위 증가할 때 종속변수 <span class="math inline">\(Y\)</span>의
값이 평균적으로 증가(감소)하는 양을 의미</li>
<li>오차 <span class="math inline">\(\epsilon_i\)</span>들은 서로 독립이며 <span class="math inline">\(N(0,\sigma^2)\)</span>인 정규분포를
따름</li>
</ul>
<p><br></p>
<ul>
<li><p>예) 아버지와의 아들의 키(Galton, 1886)</p>
<p><img src="regression/fit.jpg" style="width:65.0%" /></p></li>
</ul>
<p><br></p>
<ul>
<li>아버지의 키를 <span class="math inline">\(X\)</span>(독립, 설명), 아들의 키를 <span class="math inline">\(Y\)</span>(종속, 반응)로 두고
추정된 선형회귀모형</li>
</ul>
<p><span class="math display">\[
\hat{Y}= 95.91+0.45X
\]</span></p>
<ul>
<li>해석
<ul>
<li><span class="math inline">\(X\)</span>의 값이 한 단위 증가하면 <span class="math inline">\(Y\)</span>의 값이 <span class="math inline">\(0.45\)</span>만큼 증가한다. 즉,
아버지의 키와 아들의 키를 <span class="math inline">\(cm\)</span> 단위로 측정하였다면, 아버지의 키가
<span class="math inline">\(1cm\)</span> 증가하면 아들의 키는 <span class="math inline">\(0.45cm\)</span> 만큼 증가한다.</li>
</ul></li>
<li>예측
<ul>
<li>아버지의 키가 <span class="math inline">\(170cm\)</span>라고 하면, 이때 아들의 평균 신장은</li>
</ul></li>
</ul>
<p><span class="math display">\[
\hat{y}=95.91+0.45\times 170=172.41
\]</span>
<br></p>
<div id="최소제곱법" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> 최소제곱법<a href="regression.html#최소제곱법" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>회귀모형을 만들기 위해서는 회귀 계수를 추정해야 하며, 이는 반응변수
대 설명변수의 산점도에 있는 점들을 가장 잘 적합(best fit) 혹은
표현하는 직선을 찾는 것과 동일</p></li>
<li><p>통상적으로 최소제곱법(least squares method)을 이용하여 모수를
추정하며, 이 방법은 직선으로부터 각 점까지의 수직거리(vertical
distance)의 제곱합을 최소로 하는 직선의 방정식을 찾는 방법</p></li>
<li><p>이때 수직거리는 오차를 의미하며, 오차는 회귀모형을 통해 다음과 같이
표현 가능</p></li>
</ul>
<p><span class="math display">\[
\epsilon_i=y_i - \beta_0 - \beta_1x_i, \,\,\, i=1, \ldots, n
\]</span></p>
<ul>
<li><p>수직거리의 제곱합(오차 제곱합)
<span class="math display">\[
S(\beta_0, \beta_1 )= \sum_{i=1}^n\epsilon_i^2=\sum_{i=1}^n(y_i - \beta_0 - \beta_1x_i)^2
\]</span></p></li>
<li><p>회귀계수는 오차 제곱합 <span class="math inline">\(S(\beta_0, \beta_1 )\)</span>을 최소화하는
<span class="math inline">\(\beta_0\)</span>와 <span class="math inline">\(\beta_1\)</span>의 값을 추정하여 얻게 됨</p></li>
</ul>
</div>
<div id="회귀계수-추정" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> 회귀계수 추정<a href="regression.html#회귀계수-추정" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>추정된 회귀계수
<span class="math display">\[
\begin{aligned}
        \hat{\beta}_1=\frac{\sum_{i=1}^n(y_i-\bar{y})(x_i-\bar{x})}{\sum_{i=1}^n(x_i-\bar{x})^2}, \,\,\, \hat{\beta}_0=\bar{y}-\hat{\beta}_1\bar{x}
        \end{aligned}
\]</span></p></li>
<li><p>적합된 회귀모형(fitted model) 또는 최소제곱회귀선(least squares
regression line)</p></li>
</ul>
<p><span class="math display">\[
\hat{Y}=\hat{\beta}_0+\hat{\beta}_1X
\]</span></p>
<ul>
<li>적합값(fitted value)</li>
</ul>
<p><span class="math display">\[
\hat{y}_i=\hat{\beta}_0+\hat{\beta}_1x_i, \,\,\, i=1, \ldots, n
\]</span>
- 잔차(residual)</p>
<p><span class="math display">\[
e_i=y_i-\hat{y}_i=y_i - \hat{\beta}_0 - \hat{\beta}_1x_i, \,\,\, i=1, \ldots, n
\]</span></p>
<ul>
<li>잔차의 성질
<ul>
<li>잔차의 합은 항상 <span class="math inline">\(0\)</span>임. 이는 회귀선의 위쪽에 있는 점까지의 거리와
아래쪽에 있는 점까지의 거리의 합이 같다는 것을 의미. 따라서 회귀선은
평균과 같은 개념임</li>
</ul></li>
<li>오차의 분산추정: 회귀계수에 대한 구간추정이나 가설검정에 적용하기
위해 오차의 분산 추정이 필요</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
            \hat{\sigma}^2=\frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{n-2}=\frac{SSE}{n-2}
            \end{aligned}
\]</span></p>
<ul>
<li><p><span class="math inline">\(\hat{\sigma}^2\)</span>는 잔차평균제곱(MSE)이라 함</p></li>
<li><p>추정량의 기대값</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
            E(\hat{\beta}_0)=\beta_0, \,\,\, E(\hat{\beta}_1)=\beta_1
            \end{aligned}
\]</span></p>
<ul>
<li>추정량의 분산</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
            V(\hat{\beta}_0)=\sigma^2(1/n+\bar{X}^2/\sum_{i=1}^n(X_i-\bar{X})^2), \,\,\, V(\hat{\beta}_1)=\sigma^2/\sum_{i=1}^n(X_i-\bar{X})^2
            \end{aligned}
\]</span></p>
<ul>
<li>회귀계수의 구간추정</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
            \hat{\beta}_1 &amp;\pm t_{\alpha/2}(n-2)\hat{\sigma}\sqrt{1/\sum_{i=1}^n(X_i-\bar{X})^2}\\
            \hat{\beta}_0 &amp;\pm t_{\alpha/2}(n-2)\hat{\sigma}\sqrt{1/n+\bar{X}^2/\sum_{i=1}^n(X_i-\bar{X})^2}
            \end{aligned}
\]</span></p>
</div>
<div id="회귀계수-가설검정" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> 회귀계수 가설검정<a href="regression.html#회귀계수-가설검정" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>가설 <span class="math display">\[H_0: \beta_1=0, \,\,\, vs. \,\,\, H_1:\beta_1 \neq 0\]</span></p></li>
<li><p>검정통계량
<span class="math display">\[T_0=\hat{\beta}_1 / \sqrt{\hat{\sigma}^2/\sum_{i=1}^n(X_i-\bar{X})^2} \sim t(n-2)\]</span></p></li>
<li><p>기각역 <span class="math display">\[|T_0|&gt;t_{\alpha/2}(n-2)\]</span></p></li>
<li><p>분산분석: 회귀계수 <span class="math inline">\(\beta_1\)</span>에 대한 또 다른 검정 방법</p></li>
</ul>
<p><img src="regression/fit2.jpg" style="width:90.0%" /></p>
<p><br></p>
<ul>
<li>변동분해</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
            \sum_{i=1}^n(y_i-\bar{y})^2 &amp;= \sum_{i=1}^n(\hat{y}_i-\bar{y})^2+\sum_{i=1}^n(y_i-\hat{y}_i)^2\\
            SST &amp;= SSR + SSE
            \end{aligned}
\]</span></p>
<ul>
<li><p>검정통계량
<span class="math display">\[
F_0=\frac{SSR/(1)}{SSE/(n-2)}=\frac{MSR}{MSE}
\]</span></p></li>
<li><p>기각역: <span class="math inline">\(F_0 &gt; F_{\alpha}(1,n-2)\)</span></p></li>
</ul>
<p><br></p>
</div>
<div id="결정계수" class="section level3 hasAnchor" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> 결정계수<a href="regression.html#결정계수" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>결정계수(coefficient of determination)</p>
<ul>
<li>적합된 모형이 자료를 얼마나 잘 대표하는지를 나타내는 정도. 즉
회귀모형의 독립변수가 반응변수 <span class="math inline">\(Y\)</span>를 설명하는 정도를 나타내는 척도</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
            R^2=\frac{SSR}{SST}=1-\frac{SSE}{SST}
            \end{aligned}
\]</span></p>
<ul>
<li><p>결정계수는 <span class="math inline">\(0\le R^2 \le 1\)</span> 범위의 값으로 <span class="math inline">\(1\)</span>에 가까울수록 모형의
설명력은 높고 <span class="math inline">\(0\)</span>에 가까울수록 모형의 설명력은 낮은 것으로 평가</p></li>
<li><p>단순선형회귀모형의 경우, 결정계수 <span class="math inline">\(R^2\)</span>와 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>의 상관계수 <span class="math inline">\(r\)</span>은
<span class="math inline">\(R^2=r^2\)</span>의 관계를 가짐</p></li>
</ul>
</div>
<div id="예제" class="section level3 hasAnchor" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> 예제<a href="regression.html#예제" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>다음은 <span class="math inline">\(322\)</span>명의 건강한 성인의 건강검진 자료이다. 자료에는 나이, 키,
몸무게, 허리둘레, BMI, 수축기 혈압 등의 정보가 담겨져 있다. 허리둘레로 BMI를 예측하는 회귀식을 구하라.</li>
</ul>
<center>
<img src="regression/ex1.jpg" style="width:50.0%" />
</center>
<p><br></p>
<div id="with-r-18" class="section level4 hasAnchor" number="5.2.5.1">
<h4><span class="header-section-number">5.2.5.1</span> With R<a href="regression.html#with-r-18" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>데이터 입력</li>
</ol>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="regression.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#reg_data &lt;- read.csv(file=&quot;https://elflini.github.io/study/statanal/data/5.%20correlation_and_regression.csv&quot;, header=T)</span></span>
<span id="cb21-2"><a href="regression.html#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="regression.html#cb21-3" aria-hidden="true" tabindex="-1"></a>exdata <span class="ot">&lt;-</span> <span class="fu">url</span>(<span class="st">&quot;https://elflini.github.io/study/statanal/data/reg_data.rda&quot;</span>)</span>
<span id="cb21-4"><a href="regression.html#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="at">file=</span>exdata)</span>
<span id="cb21-5"><a href="regression.html#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="regression.html#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(reg_data)</span></code></pre></div>
<pre><code>##   age height weight waistline  BMI SBP
## 1  57    164   62.0        85 23.1 147
## 2  25    172   54.0        65 18.3 116
## 3  57    157   59.0        83 23.9 122
## 4  43    170   87.8       104 30.4 130
## 5  52    155   50.0        83 20.8 120
## 6  27    163   76.0        83 28.6 128</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>산점도 그리기</li>
</ol>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="regression.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(BMI<span class="sc">~</span>waistline, <span class="at">data=</span>reg_data, <span class="at">xlab=</span><span class="st">&quot;허리둘레&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;BMI&quot;</span>)</span></code></pre></div>
<p><img src="Statistical-Analysis_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<ol start="3" style="list-style-type: decimal">
<li>상관분석</li>
</ol>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="regression.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(reg_data, <span class="fu">cor.test</span>(BMI,waistline))</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  BMI and waistline
## t = 23.906, df = 320, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7576655 0.8367351
## sample estimates:
##     cor 
## 0.80066</code></pre>
<ul>
<li>BMI와 허리둘레간의 상관계수는 0.80으로 통계적으로 매우 유의하게 나타난다. 따라서 BMI와 허리둘레간에는 선형관계가 강한 것으로 보임</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>단순회귀 모형</li>
</ol>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="regression.html#cb26-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(BMI<span class="sc">~</span>waistline, <span class="at">data=</span>reg_data)</span>
<span id="cb26-2"><a href="regression.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary.aov</span>(fit)</span></code></pre></div>
<pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)    
## waistline     1   2732  2731.7   571.5 &lt;2e-16 ***
## Residuals   320   1530     4.8                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ul>
<li>회귀식이 통계적으로 유의한지를 검정하는 분산분석표를 살펴보면, F-통계량의 유의확률이 &lt;2e-16으로 유의수준 0.05보다 작다. 즉, 이 회귀식은 통계적으로 매우 유의하다고 할 수 있음
<ul>
<li>따라서 선형회귀모형으로 적합해도 문제가 없다할 수 있음</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="regression.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BMI ~ waistline, data = reg_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.5197 -1.3087 -0.0444  1.2532 12.0683 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.97611    1.25481  -3.169  0.00168 ** 
## waistline    0.33135    0.01386  23.906  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.186 on 320 degrees of freedom
## Multiple R-squared:  0.6411, Adjusted R-squared:  0.6399 
## F-statistic: 571.5 on 1 and 320 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li><p>회귀식의 상수(절편) 값은 -3.976이며, 유의확률은 0.0017로 통계적으로 유의하다. 하지만 회귀식의 절편은 특별히 유의성을 논하지 않음</p></li>
<li><p>허리둘레의 회귀계수는 0.33이고, 이 회귀계수의 통계적 유의성을 결정하는 t-값은 23.91로 유의확률이 &lt;2e-16이므로, 이 회귀계수는 통계적으로 매우 유의하다고 볼 수 있음</p></li>
<li><p>추정된 회귀식</p></li>
</ul>
<p><span class="math display">\[
\hat{BMI}=-3.976+0.33허리둘레
\]</span></p>
<ul>
<li><p>회귀식을 살펴보면 허리둘레가 1만큼 증가하면 BMI는 0.33씩 증가한다는 것을 의미함</p>
<ul>
<li>절편값은 -3.976으로, 허리둘레가 0일때 BMI의 평균을 의미하므로 의미가 없음</li>
</ul></li>
<li><p>만약, 허리둘레가 85이면 경우 예상 BMI는 <span class="math inline">\(-3.976+0.33\times 85=24.074\)</span>가 됨</p></li>
<li><p>결정계수 <span class="math inline">\(R^2=0.6411\)</span>은 총변동 중에서 회귀선에 의하여 설명되는 비율을 의미하는 것으로 BMI의 변동 중에서 <span class="math inline">\(64.11\%\)</span>가 허리둘레에 의해 설명된다는 것을 의미</p>
<ul>
<li><span class="math inline">\(R^2\)</span>값의 범위는 <span class="math inline">\(0\le R^2 \le 1\)</span>로, 모든 관찰값과 회귀식이 일치한다면 <span class="math inline">\(R^2=1\)</span>이 되어 독립변수와 종속변수간에 <span class="math inline">\(100\%\)</span>의 상관관계가 있다고 할 수 있음</li>
<li>즉, <span class="math inline">\(R^2\)</span>의 값이 1에 가까울수록 회귀선은 표본을 설명하는데 유용함</li>
</ul></li>
<li><p>추정된 회귀선</p></li>
</ul>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="regression.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(BMI<span class="sc">~</span>waistline, <span class="at">data=</span>reg_data, <span class="at">xlab=</span><span class="st">&quot;허리둘레&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;BMI&quot;</span>)</span>
<span id="cb30-2"><a href="regression.html#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(fit, <span class="at">col=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="Statistical-Analysis_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p><span class="math display">\[
\hat{BMI}=-3.976+0.33허리둘레
\]</span></p>
<ul>
<li>적합된 회귀식을 그림으로 표현하면 위와 같음
<ul>
<li>실제 BMI값과 회귀식을 통해 산출되는 BMI의 추정값이 다소 차이가 있음을 알 수 있음</li>
</ul></li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>잔차분석</li>
</ol>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="regression.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb31-2"><a href="regression.html#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit)</span></code></pre></div>
<p><img src="Statistical-Analysis_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<ul>
<li>잔차와 예측값을 나타낸 산점도(왼쪽 위)는 잔차의 등분산성, 선형성 등을 판단함
<ul>
<li>잔차 값이 0을 기준으로 고르게 퍼져 있으면 등분산성을 만족하는데 문제가 없음</li>
<li>잔차들이 특정한 패턴없이 무작위로 퍼져있다면 선형성을 가정하는데 문제가 없음</li>
</ul></li>
<li>표준화 잔차의 정규 Q-Q 도표(오른쪽 위)는 잔차(오차항)의 정규성을 살펴보는 그림
<ul>
<li>가운데 실선을 따라 점들이 모여 있을수록 정규성을 만족함</li>
</ul></li>
</ul>
</div>
<div id="with-sas-18" class="section level4 hasAnchor" number="5.2.5.2">
<h4><span class="header-section-number">5.2.5.2</span> With SAS<a href="regression.html#with-sas-18" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<blockquote>
<p>SAS Code</p>
</blockquote>
<pre><code>filename reg_data URL &quot;https://elflini.github.io/study/statanal/data/5.%20correlation_and_regression.csv&quot; termstr=crlf; 

proc import out=healthdata
datafile=reg_data
dbms=csv replace;
getnames=yes;
run;

proc corr data=healthdata plots=matrix;
var waistline bmi;
run;</code></pre>
<p><img src="regression/reg1.png" style="width:60.0%" /></p>
<p><img src="regression/reg2.png" style="width:60.0%" /></p>
<pre><code>ods graphics on;
proc reg data=healthdata plots=residuals plots=QQ;
model bmi=waistline;
run;
ods graphics off;</code></pre>
<p><img src="regression/ex10.jpg" style="width:60.0%" /></p>
<p><img src="regression/ex11.jpg" style="width:60.0%" /></p>
<p><img src="regression/ex12.jpg" style="width:50.0%" /></p>
<p><img src="regression/ex13.jpg" style="width:60.0%" /></p>
<p><img src="regression/ex14.jpg" style="width:70.0%" /></p>
</div>
</div>
</div>
<div id="다중선형회귀분석" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> 다중선형회귀분석<a href="regression.html#다중선형회귀분석" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>종속변수를 설명하는 독립변수들이 두 개 이상 있는 경우, 즉 여러 개의
독립변수들을 동시에 고려하는 선형회귀모형을
다중선형회귀모형(multiple linear regression model) 이라고 함</p></li>
<li><p>다중선형회귀모형</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
            y_i=\beta_0+\beta_1x_{1i}+\beta_2x_{2i}+\ldots +\beta_px_{pi}+\epsilon_i , \,\,\, \epsilon_i \sim N(0,\sigma^2), \,\,\, i=1,\ldots, n
            \end{aligned}
\]</span></p>
<p>       <span class="math inline">\(\beta_0\)</span>: 절편, <span class="math inline">\(\beta_j(j=1,\cdots ,p)\)</span>:
설명변수에 대한 회귀계수</p>
<ul>
<li><p>회귀계수 <span class="math inline">\(\beta_j\)</span>는 다른 설명변수의 값이 고정된 상태에서 <span class="math inline">\(x_j\)</span>가 한
단위 변동함에 따른 반응변수의 변동크기를 나타냄</p></li>
<li><p>오차 <span class="math inline">\(\epsilon_i\)</span>들은 서로 독립이며 <span class="math inline">\(N(0,\sigma^2)\)</span>인 정규분포를
따름</p></li>
<li><p>필요한 경우, 설명변수나 반응변수를 변환하여 선형회귀모형에 포함
가능</p></li>
</ul>
<p>       예) <span class="math inline">\(x^2\)</span>, <span class="math inline">\(1/x\)</span>, <span class="math inline">\(log(x)\)</span>, <span class="math inline">\(\sqrt{x}\)</span>, <span class="math inline">\(1/y\)</span>, <span class="math inline">\(log(y)\)</span></p>
<ul>
<li><p>다중회귀모형의 회귀계수 추정은 단순회귀와 마찬가지로 최소제곱법을
이용</p></li>
<li><p>오차제곱합
<span class="math display">\[S(\beta_0, \beta_1,\ldots, \beta_p )= \sum_{i=1}^n\epsilon_i^2=\sum_{i=1}^n(y_i - \beta_0 - \beta_1x_i-\cdots -\beta_px_{pi})^2\]</span></p></li>
<li><p>회귀계수는 오차 제곱합 <span class="math inline">\(S(\beta_0, \beta_1,\ldots, \beta_p )\)</span>을
최소화하는 <span class="math inline">\(\beta_i, \,\,\, i=0,\ldots, p\)</span>의 값을 추정하여 얻게 됨</p></li>
<li><p>추정된 회귀계수</p></li>
</ul>
<p><span class="math display">\[
\hat{\mathbf{\beta}}=(X&#39;X)^{-1}X&#39;\mathbf{y}
\]</span></p>
<p>       <span class="math inline">\(X\)</span>; design matrix</p>
<ul>
<li><p>추정된 회귀모형
<span class="math display">\[
\hat{Y}=\hat{\beta}_0+\hat{\beta}_1X_1+\hat{\beta}_2X_2+\ldots +\hat{\beta}_pX_p
\]</span></p></li>
<li><p>다중회귀모형은 적어도 하나의 독립변수가 종속변수에 선형적인 영향을
준다는 가정에서 만들어지기 때문에 추정된 회귀모형이 의미가 있기
위해서는 다음 가설에 대한 검정에서 유의한 결론이 나와야 함</p></li>
<li><p>회귀모형 가설</p>
<ul>
<li><span class="math inline">\(H_0 : \beta_1=\beta_2=\cdots=\beta_p=0\)</span></li>
<li><span class="math inline">\(H_1 :\)</span> 적어도 하나의 <span class="math inline">\(\beta_i \ne 0, \,\,\, i=1,\ldots, p\)</span></li>
</ul></li>
<li><p>가설검정을 위한 분산분석표</p>
<p><img src="regression/fit3.jpg" style="width:90.0%" /></p></li>
<li><p>검정통계량
<span class="math display">\[
F_0=\frac{MSR}{MSE}
\]</span></p></li>
<li><p>기각역
<span class="math display">\[
F_0 &gt; F_{\alpha}(p,n-1-p)
\]</span></p></li>
<li><p>설정한 회귀모형에 대한 검정에서 유의하다는 결론이 내려지면 추정된 회귀식은 종속변수 <span class="math inline">\(Y\)</span>를 예측하는 데 사용될 수 있음</p>
<ul>
<li>하지만 이것이 모형에 있는 모든 독립변수가 종속변수에 영향을 준다는
것을 의미하지 않음</li>
<li>회귀모형에 대한 검정에서는 검정에 사용된 여러 개의 독립변수 중에서
오직 한 개의 변수만이 종속변수에 영향을 주더라도 회귀모형이
유의하다는 결론이 나올 수 있기 때문</li>
<li>따라서 설정한 회귀모형에서 각각의 독립변수들이 종속변수에 영향을
주는지 알아보기 위한 검정이 필요</li>
</ul></li>
<li><p>각 회귀계수에 대한 가설</p>
<ul>
<li><span class="math inline">\(H_0 : \beta_i=0, \,\,\, i=1,\ldots, p\)</span></li>
<li><span class="math inline">\(H_1 :\beta_i \ne 0\)</span></li>
</ul></li>
<li><p>검정통계량</p></li>
</ul>
<p><span class="math display">\[
T=\frac{\hat{\beta}_i}{se(\hat{\beta}_i)} \sim t(n-1-p)
\]</span></p>
<ul>
<li>기각역</li>
</ul>
<p><span class="math display">\[
|T|&gt; t_{\alpha/2}(n-1-p)
\]</span></p>
<ul>
<li><p>각각의 회귀계수에 대한 검정에서 통계적으로 유의하지 않다고 판명된
독립변수는 모형에서 제거하고 다시 회귀분석을 실시하는 것이 좋음(항상
그런것은 아님)</p></li>
<li><p>만약 종속변수와 상관이 높은 독립변수인데도 불구하고 유의하지 않게
나타났다면 독립변수들간의 다중공선성(multicollinearity)을 의심해 볼
수 있음</p></li>
</ul>
<p><br></p>
<div id="변수-선택" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> 변수 선택<a href="regression.html#변수-선택" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>이론적인 배경이나 사전 경험이 있는 경우 모형에 포함시킬 독립변수들의
선택이 비교적 용이</p></li>
<li><p>일반적으로 종속변수를 설명해주는 독립변수들을 정확하게 선택하는 것은
쉽지 않음</p></li>
<li><p>종속변수를 설명한다고 생각되는 모든 가능한 독립변수들을 파악해서
회귀모형에 포함시킬 수도 있으나, 이런 많은 독립변수들을 모형에
포함시켜 분석하는 것은 다음과 같은 이유로 문제가 됨</p>
<ul>
<li>모형내의 변수의 값을 측정하고 유지하는 데 많은 시간과 돈이 필요</li>
<li>독립변수들 사이에서는 정보가 중복되기 쉬워서 종속변수에 대한
변수들의 영향력을 알기 어려워 짐</li>
<li>일반적으로 복잡한 모형보다는 간단한 모형을 선호</li>
<li>독립변수들 사이에 상관계수가 높은 경우에는 다중공선성 문제가 나타나
회귀모형이 불안해짐</li>
</ul></li>
<li><p>독립변수 중에서 종속변수에 큰 영향을 주는 변수만을 선택하여 모형에
포함시키고 종속변수에 별 영향을 주지 않는 변수는 제거할 필요가 있음.
이를 위한 방법을 변수 선택법(variable selection method)이라 함</p></li>
<li><p>일반적인 변수 선택법</p>
<ul>
<li>모든 변수를 다 쓰는 방법</li>
<li>전진 선택법(forward selection)</li>
<li>후진 제거법(backward elimination)</li>
<li>단계적 선택법(stepwise selection)</li>
<li>Best subset selection</li>
</ul></li>
<li><p>변수 선택 척도</p>
<ul>
<li>p-value</li>
<li>AIC, BIC</li>
</ul></li>
</ul>
<p><br></p>
</div>
<div id="결정계수-1" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> 결정계수<a href="regression.html#결정계수-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>결정계수 <span class="math inline">\(R^2\)</span>는 종속변수 <span class="math inline">\(Y\)</span>의 총변동 중에서 독립변수들에 의해
설명되는 <span class="math inline">\(Y\)</span> 변동의 비율로 정의</p></li>
<li><p>따라서 <span class="math inline">\(R^2\)</span>는 회귀모형에 있는 독립변수들이 <span class="math inline">\(Y\)</span>값을 얼마나 잘 설명해
주는가에 대한 측도로 사용</p></li>
<li><p>자연과학분야에서는 <span class="math inline">\(0.8\)</span>이상의 높은 <span class="math inline">\(R^2\)</span>값을 가지는 실험 자료를
종종 볼 수 있으나, 사회과학분야에서는 <span class="math inline">\(0.3\)</span> 이상의 <span class="math inline">\(R^2\)</span>값을 가지는
자료가 많지 않음</p></li>
<li><p><span class="math inline">\(R^2\)</span> 통계량에 대한 검정방법은 존재하지 않기 때문에 모형의 적합성에
대해 <span class="math inline">\(R^2\)</span>값으로 설명하는 것은 부적절함. 따라서 독립변수들의
설명력으로만 해석하고, 모형의 적합성에 대해서는 분산분석표에 의한
검정 결과를 사용하는 것이 좋음</p></li>
<li><p>설명력이 없는 설명변수가 모형에 추가되어도 결정계수는 증가</p></li>
<li><p>다중회귀 모형에서는 모형에 포함된 설명변수의 개수를 반영한 조정된
결정계수(adjusted coefficient of determination) 이용하는 것이 좋음</p></li>
<li><p>조정된 결정계수
<span class="math display">\[
\begin{aligned}
R^{2*}=1-\frac{SSE/(n-p)}{SST/(n-1)}
\end{aligned}
\]</span></p></li>
<li><p>조정된 결정계수와 결정계수의 관계
<span class="math display">\[
R^{2*}=1-\frac{n-1}{n-p}(1-R^2)
\]</span></p></li>
</ul>
<p><br></p>
</div>
<div id="표준화-회귀계수" class="section level3 hasAnchor" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> 표준화 회귀계수<a href="regression.html#표준화-회귀계수" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>추정된 회귀계수의 크기는 독립변수들의 측정단위에 영향을 받기 때문에
독립변수들이 종속변수에 주는 영향력을 비교하기위해 회귀계수의 크기를
직접 비교하면 안됨</p></li>
<li><p>예를 들어, 종속변수 체중에 영향을 주는 독립변수로 키를 고려한 경우
인치(inch) 단위를 사용한 경우의 회귀계수는 <span class="math inline">\(cm\)</span> 단위를 사용한 경우의
회귀계수의 <span class="math inline">\(2.5\)</span>배가 됨</p></li>
<li><p>독립변수들의 영향력을 비교하기 위해서는 측정단위에 관계없는
회귀계수가 필요하며, 이러한 회귀계수를 표준화 회귀계수(standardized
regression coefficient) 혹은 베타 계수(beta coefficient)라 함</p></li>
<li><p>회귀계수 <span class="math inline">\(\beta_i\)</span>와 표준화 회귀계수 <span class="math inline">\(\beta_i^*\)</span>의 관계</p></li>
</ul>
<p><span class="math display">\[
\beta_i = \beta_i^* \left( \frac{S_y}{S_i}  \right), \,\,\, i=1,\ldots, p
\]</span></p>
<ul>
<li>독립변수들 간 상관관계가 있을 경우 상대적인 중요도를 설명하는데
위험이 있을 수 있음</li>
</ul>
<p><br></p>
</div>
<div id="다중공선성" class="section level3 hasAnchor" number="5.3.4">
<h3><span class="header-section-number">5.3.4</span> 다중공선성<a href="regression.html#다중공선성" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>데이터로부터 추정된 다중회귀모형은 예측변수들 간에 상호의존관계가
심각하지 않다는 묵시적인 가정 하에서 시행됨</p></li>
<li><p>예측변수들 간의 강한 상관성을 공선성 혹은
다중공선성(multicollinearity) 문제라 함</p></li>
<li><p>다중공선성 문제는 회귀모형에서의 오류가 아닌 데이터의 결함에 의해
나타나는 결과</p></li>
<li><p>다중공선성 문제가 발생하면, 추정된 회귀계수의 부호가 사전에
기대한(이론적인) 것과 일치하지 않을 수 있으며 이론적으로 중요한
변수에 대한 회귀계수가 큰 표준오차를 가짐으로 인해 유의하지 않을 수
있음</p></li>
<li><p>다중공선성 문제는 분산팽창계수(variance inflation coefficient: VIF)
또는 VIF의 역수인 공차한계(tolerance)를 이용하여 판단</p></li>
<li><p>VIF <span class="math inline">\(&gt; 10\)</span> 또는 공차한계 <span class="math inline">\(&lt; 0.1\)</span>인 경우 다중공선성 문제가 있다고
판단</p></li>
</ul>
<p><br></p>
</div>
<div id="더미변수가변수" class="section level3 hasAnchor" number="5.3.5">
<h3><span class="header-section-number">5.3.5</span> 더미변수(가변수)<a href="regression.html#더미변수가변수" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>회귀분석에 사용되는 독립변수는 기본적으로 연속형 변수여야 함</p></li>
<li><p>범주형 변수를 독립변수로 사용할때는 더미변수(dummy variable)화 하여
사용함</p></li>
<li><p>더미변수화 하는 방법은 여러 가지가 존재하나 일반적으로 원래 변수가
지닌 범주의 개수보다 하나 적은 개수의 변수로 가변수화 함</p></li>
<li><p>예를 들어 <span class="math inline">\(X_4\)</span> 변수가 고졸=1, 전문대졸=2, 대졸=3의 값을 가지고
있다면,</p>
<p><img src="regression/fit5.jpg" style="width:90.0%" /></p></li>
</ul>
<p><br></p>
</div>
<div id="회귀모형에-대한-가정-검토" class="section level3 hasAnchor" number="5.3.6">
<h3><span class="header-section-number">5.3.6</span> 회귀모형에 대한 가정 검토<a href="regression.html#회귀모형에-대한-가정-검토" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>회귀분석을 적용하기 위해서는 다음과 같은 가정이 충족되어야 함</li>
</ul>
<p><span class="math display">\[
\epsilon_i \sim N(0, \sigma^2 ), \,\,\, i=1, \ldots n, \,\,\, \epsilon_i \text{들은 서로 독립}
\]</span></p>
<ul>
<li><p>가정이 만족되지 않으면 부석결과가 정확하지 않을 수 있고, 경우에
따라서는 전혀 다른 방향의 결론이 도출되기도 함</p></li>
<li><p>회귀 가정의 검토를 위해 <span class="math inline">\(\epsilon_i\)</span>의 추정값인 잔차
<span class="math inline">\(e_i=y_i-\hat{y}_i\)</span>를 사용</p></li>
<li><p>잔차를 통해 가정을 검토하는 분석을 잔차분석이라 함</p></li>
<li><p>잔차분석</p>
<ul>
<li>오차항의 정규성 검토</li>
<li>오차항의 등분산성 검토</li>
<li>오차항들간의 자기상관(autocorrelation) 검토(독립성)</li>
</ul></li>
<li><p>잔차분석</p></li>
</ul>
<p><img src="regression/fit4.jpg" style="width:60.0%" /></p>
<ul>
<li><p>자기상관(독립성) 문제는 더빈-왓슨(Durbin-Watson) 통계량을 이용하여
판단</p></li>
<li><p>더빈-왓슨 통계량은 인접하는 오차항들 <span class="math inline">\(\epsilon_i\)</span>와
<span class="math inline">\(\epsilon_{i-1}\)</span>간에 자기상관이 존재하는지 알아보는 검정법</p></li>
<li><p>검정통계량</p></li>
</ul>
<p><span class="math display">\[
d=\frac{\sum_{i=2}^n (e_i - e_{i-1})^2}{\sum_{i=1}^n e_i^2}, \,\,\, e_i : i\text{번째 잔차}
\]</span></p>
<ul>
<li><p>더빈-왓슨 통계량은 <span class="math inline">\(0\sim 4\)</span>의 범위를 가지며, 통계량 값이 <span class="math inline">\(2\)</span>보다
작을수록 오차항 사이의 양의 상관관계를, 통계량 값이 <span class="math inline">\(2\)</span>보다 클 수록
오차항 사이에 음의 상관관계를 가짐</p></li>
<li><p>통계량 값이 <span class="math inline">\(2\)</span>에 가까운 값을 가지면 오차항의 독립성이 만족되고, 이
때 자기상관 문제가 발생하지 않았다고 판단함</p></li>
<li><p>정규성과 등분산성은 정규 <span class="math inline">\(P-P\)</span> 또는 <span class="math inline">\(Q-Q\)</span> 도표와 잔차의 산점도로
간단히 확인 가능</p></li>
<li><p>회귀의 기본가정을 만족한다고 해서 반드시 그 모형이 좋은 모형이라고
말 할 수 없지만, 기본 가정을 만족하면 좋은 모형을 찾기가 수월해 짐</p></li>
<li><p>따라서 기본가정이 만족하지 않는 경우에는 가정을 만족하게끔
조절해주는 것이 좋음</p></li>
<li><p>이 외에 회귀계수에 영향을 주는 레버리지(leverage), Cook’s distance,
DFFIT 값 등을 고려</p></li>
<li><p>또한 모형 설정 시 가능한 교호작용을 고려하는 것이 좋음</p></li>
</ul>
<p><br></p>
</div>
<div id="예제-1" class="section level3 hasAnchor" number="5.3.7">
<h3><span class="header-section-number">5.3.7</span> 예제<a href="regression.html#예제-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>다음은 <span class="math inline">\(322\)</span>명의 건강한 성인의 건강검진 자료이다. 자료에는 나이, 키,
몸무게, 허리둘레, BMI, 수축기 혈압 등의 정보가 담겨져 있자. 이 자료를
바탕으로 수축기 혈압을 예측하는 회귀모형을 생성하라.</li>
</ul>
<center>
<img src="regression/ex1.jpg" style="width:50.0%" />
</center>
<div id="with-r-19" class="section level4 hasAnchor" number="5.3.7.1">
<h4><span class="header-section-number">5.3.7.1</span> With R<a href="regression.html#with-r-19" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>데이터 입력</li>
</ol>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="regression.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">#reg_data &lt;- read.csv(file=&quot;https://elflini.github.io/study/statanal/data/5.%20correlation_and_regression.csv&quot;, header=T)</span></span>
<span id="cb34-2"><a href="regression.html#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="regression.html#cb34-3" aria-hidden="true" tabindex="-1"></a>exdata <span class="ot">&lt;-</span> <span class="fu">url</span>(<span class="st">&quot;https://elflini.github.io/study/statanal/data/reg_data.rda&quot;</span>)</span>
<span id="cb34-4"><a href="regression.html#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="at">file=</span>exdata)</span>
<span id="cb34-5"><a href="regression.html#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="regression.html#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(reg_data)</span></code></pre></div>
<pre><code>##   age height weight waistline  BMI SBP
## 1  57    164   62.0        85 23.1 147
## 2  25    172   54.0        65 18.3 116
## 3  57    157   59.0        83 23.9 122
## 4  43    170   87.8       104 30.4 130
## 5  52    155   50.0        83 20.8 120
## 6  27    163   76.0        83 28.6 128</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>산점도 그리기</li>
</ol>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="regression.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(SBP<span class="sc">~</span>age<span class="sc">+</span>height<span class="sc">+</span>weight<span class="sc">+</span>waistline<span class="sc">+</span>BMI, <span class="at">data=</span>reg_data)</span></code></pre></div>
<p><img src="Statistical-Analysis_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<ol start="3" style="list-style-type: decimal">
<li>상관분석</li>
</ol>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="regression.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb37-2"><a href="regression.html#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rcorr</span>(<span class="fu">as.matrix</span>(reg_data))</span></code></pre></div>
<pre><code>##             age height weight waistline   BMI   SBP
## age        1.00  -0.47  -0.34      0.05 -0.06  0.19
## height    -0.47   1.00   0.59      0.17 -0.03 -0.16
## weight    -0.34   0.59   1.00      0.75  0.78  0.06
## waistline  0.05   0.17   0.75      1.00  0.80  0.21
## BMI       -0.06  -0.03   0.78      0.80  1.00  0.21
## SBP        0.19  -0.16   0.06      0.21  0.21  1.00
## 
## n= 322 
## 
## 
## P
##           age    height weight waistline BMI    SBP   
## age              0.0000 0.0000 0.3709    0.3180 0.0008
## height    0.0000        0.0000 0.0023    0.5330 0.0031
## weight    0.0000 0.0000        0.0000    0.0000 0.2564
## waistline 0.3709 0.0023 0.0000           0.0000 0.0002
## BMI       0.3180 0.5330 0.0000 0.0000           0.0001
## SBP       0.0008 0.0031 0.2564 0.0002    0.0001</code></pre>
<ul>
<li>SBP와 weight간의 상관계수는 0.06, 유의확률은 0.2564로 선형관계가 없는 것으로 나타났으며, age, height, waistline, BMI는 선형관계가 유의한 것으로 나타남</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>다중회귀 모형 - 모든 변수를 다 사용하는 경우</li>
</ol>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="regression.html#cb39-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(SBP<span class="sc">~</span>age<span class="sc">+</span>height<span class="sc">+</span>weight<span class="sc">+</span>waistline<span class="sc">+</span>BMI, <span class="at">data=</span>reg_data)</span>
<span id="cb39-2"><a href="regression.html#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SBP ~ age + height + weight + waistline + BMI, data = reg_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -43.449 -11.628  -1.081   9.635  64.919 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) -19.3598   141.9737  -0.136   0.8916  
## age           0.1899     0.1051   1.808   0.0716 .
## height        0.5913     0.8621   0.686   0.4933  
## weight       -1.0241     1.0141  -1.010   0.3133  
## waistline     0.3231     0.2206   1.465   0.1440  
## BMI           3.2248     2.7177   1.187   0.2363  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18.06 on 316 degrees of freedom
## Multiple R-squared:  0.09673,    Adjusted R-squared:  0.08243 
## F-statistic: 6.768 on 5 and 316 DF,  p-value: 5.187e-06</code></pre>
<ul>
<li><p>F-statistic에 대한 p-value가 5.187e-06으로 통계적으로 유의하게 나타난다. 따라서 선형모형이 성립함</p></li>
<li><p>회귀계수는 age가 0.1899, height는 0.5913, weight는 -1.0241, waistline는 0.3231, BMI는 3.2248로 나타났으나, 유의한 변수는 없는것으로 나타남</p></li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>다중공선성</li>
</ol>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="regression.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb41-2"><a href="regression.html#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit) </span></code></pre></div>
<pre><code>##        age     height     weight  waistline        BMI 
##   1.530112  57.004090 149.609824   3.710049  96.452809</code></pre>
<ul>
<li><p>다중공선성을 살펴보면, height, weight, BMI는 vif값이 10보다 크게 나타나기 때문에 다중공선성 문제가 있는것으로 보임</p>
<ul>
<li>즉, height, weight, BMI 간에는 독립을 유지하기 어렵기 때문에 회귀 계수를 왜곡시킴</li>
</ul></li>
<li><p>이 경우, 적절한 변수를 선택하여 모형을 다시 적합시켜야 함</p></li>
<li><p>여기서는 통계적 변수 선택법인 단계적선택법을 통해 적절한 변수를 선택하여 모형을 적합시킴</p></li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>다중선형회귀모형 - 단계적 선택법을 사용하는 경우</li>
</ol>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="regression.html#cb43-1" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">step</span>(fit)</span></code></pre></div>
<pre><code>## Start:  AIC=1869.63
## SBP ~ age + height + weight + waistline + BMI
## 
##             Df Sum of Sq    RSS    AIC
## - height     1    153.53 103267 1868.1
## - weight     1    332.81 103446 1868.7
## - BMI        1    459.45 103573 1869.1
## &lt;none&gt;                   103113 1869.6
## - waistline  1    700.11 103813 1869.8
## - age        1   1066.16 104179 1870.9
## 
## Step:  AIC=1868.11
## SBP ~ age + weight + waistline + BMI
## 
##             Df Sum of Sq    RSS    AIC
## &lt;none&gt;                   103267 1868.1
## - waistline  1    673.29 103940 1868.2
## - age        1   1063.68 104330 1869.4
## - weight     1   1253.53 104520 1870.0
## - BMI        1   2310.05 105577 1873.2</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="regression.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SBP ~ age + weight + waistline + BMI, data = reg_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -43.368 -11.600  -1.212   9.972  65.881 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  77.7238    11.1234   6.987 1.66e-11 ***
## age           0.1897     0.1050   1.807  0.07171 .  
## weight       -0.3387     0.1727  -1.962  0.05068 .  
## waistline     0.3166     0.2202   1.438  0.15152    
## BMI           1.3957     0.5241   2.663  0.00814 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18.05 on 317 degrees of freedom
## Multiple R-squared:  0.09538,    Adjusted R-squared:  0.08397 
## F-statistic: 8.356 on 4 and 317 DF,  p-value: 2.028e-06</code></pre>
<ul>
<li><p>R에서 step 함수를 이용한 단계적 선택법은 AIC를 기준으로 변수를 선택함</p></li>
<li><p>age, weight, waistline, BMI 변수가 선택됨</p></li>
</ul>
<ol start="7" style="list-style-type: decimal">
<li>다중공선성</li>
</ol>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="regression.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit2) </span></code></pre></div>
<pre><code>##       age    weight waistline       BMI 
##  1.530097  4.345072  3.703107  3.593545</code></pre>
<ul>
<li>결과를 살펴보면 선택된 변수간에는 다중공선성 문제는 없는 것으로 보임</li>
</ul>
<ol start="8" style="list-style-type: decimal">
<li>정규성 검정</li>
</ol>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="regression.html#cb49-1" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">residuals</span>(fit2)</span>
<span id="cb49-2"><a href="regression.html#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(res)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  res
## W = 0.97723, p-value = 5.509e-05</code></pre>
<ul>
<li><p>Shapiro-Wilk 검정을 통해 정규성을 살펴보면 p-value가 0.05보다 작기 때문에 정규성을 만족하지 않는 것으로 나옴</p></li>
<li><p>이 경우, SBP의 로그변환, Box-Cox 등을 이용할 수 있음음</p></li>
</ul>
<ol start="9" style="list-style-type: decimal">
<li>잔차그림</li>
</ol>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="regression.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb51-2"><a href="regression.html#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit2) </span></code></pre></div>
<p><img src="Statistical-Analysis_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<ol start="10" style="list-style-type: decimal">
<li>Durbin-Watson 자기상관검정</li>
</ol>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="regression.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span></code></pre></div>
<pre><code>## 필요한 패키지를 로딩중입니다: zoo</code></pre>
<pre><code>## 
## 다음의 패키지를 부착합니다: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="regression.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dwtest</span>(fit2, <span class="at">alternative=</span><span class="st">&quot;two.sided&quot;</span>) </span></code></pre></div>
<pre><code>## 
##  Durbin-Watson test
## 
## data:  fit2
## DW = 1.9474, p-value = 0.6362
## alternative hypothesis: true autocorrelation is not 0</code></pre>
<ul>
<li>더빈-왓슨 검정 결과 유의확률이 0.6362로 자기상관이 없는것으로 나타남남</li>
</ul>
<ol start="11" style="list-style-type: decimal">
<li>Leverage</li>
</ol>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="regression.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hatvalues</span>(fit) </span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
## 0.006263780 0.056560684 0.007520627 0.014101873 0.022966036 0.030273241 
##           7           8           9          10          11          12 
## 0.016542085 0.004954000 0.037609592 0.022427606 0.007841295 0.020545891 
##          13          14          15          16          17          18 
## 0.004887047 0.019174630 0.008196496 0.010742904 0.141884682 0.060329655 
##          19          20          21          22          23          24 
## 0.016438787 0.032161969 0.016177612 0.017056919 0.011148986 0.012303707 
##          25          26          27          28          29          30 
## 0.008758419 0.124222471 0.006610500 0.009393306 0.070828187 0.005981870 
##          31          32          33          34          35          36 
## 0.004303481 0.023225285 0.048619734 0.009744022 0.013232630 0.023704530 
##          37          38          39          40          41          42 
## 0.008668079 0.010724717 0.015565591 0.021265480 0.006545184 0.026680928 
##          43          44          45          46          47          48 
## 0.028585192 0.024528820 0.021478176 0.011027250 0.007718614 0.009099304 
##          49          50          51          52          53          54 
## 0.014846475 0.009151154 0.025390439 0.008105743 0.068098677 0.008460308 
##          55          56          57          58          59          60 
## 0.021505862 0.023215868 0.024650080 0.004275824 0.027760049 0.011027250 
##          61          62          63          64          65          66 
## 0.014548525 0.015845619 0.008707205 0.014399897 0.014397357 0.013838684 
##          67          68          69          70          71          72 
## 0.054305226 0.010796460 0.023817241 0.008268855 0.005967330 0.022751126 
##          73          74          75          76          77          78 
## 0.005630567 0.005252198 0.016929832 0.041030538 0.012494727 0.005993497 
##          79          80          81          82          83          84 
## 0.008270267 0.006378902 0.016596040 0.009027859 0.029284825 0.013765939 
##          85          86          87          88          89          90 
## 0.019885618 0.008913259 0.010789481 0.032293904 0.016913860 0.035170120 
##          91          92          93          94          95          96 
## 0.004860865 0.099972860 0.015585458 0.048621743 0.030439542 0.021101356 
##          97          98          99         100         101         102 
## 0.011214363 0.012203619 0.003733370 0.014642283 0.018422778 0.011058035 
##         103         104         105         106         107         108 
## 0.008158241 0.031878423 0.004510454 0.034607387 0.011331015 0.006517244 
##         109         110         111         112         113         114 
## 0.030128033 0.012192034 0.011177999 0.008531302 0.008380133 0.007469184 
##         115         116         117         118         119         120 
## 0.005965594 0.030905370 0.020958907 0.018838905 0.013194086 0.012459926 
##         121         122         123         124         125         126 
## 0.057361880 0.012942622 0.024980913 0.034994376 0.012170295 0.018245431 
##         127         128         129         130         131         132 
## 0.006022060 0.029477949 0.023792811 0.014707247 0.016485112 0.008992524 
##         133         134         135         136         137         138 
## 0.019228771 0.004980917 0.013734128 0.009619652 0.020537018 0.015317933 
##         139         140         141         142         143         144 
## 0.012263471 0.010700480 0.012312175 0.012894624 0.025411778 0.004604493 
##         145         146         147         148         149         150 
## 0.013222726 0.007093437 0.020701092 0.031061216 0.015180577 0.032675105 
##         151         152         153         154         155         156 
## 0.009280708 0.004132442 0.009550947 0.011528838 0.018812695 0.032493509 
##         157         158         159         160         161         162 
## 0.015982571 0.004904723 0.017221156 0.021167031 0.005155365 0.007286704 
##         163         164         165         166         167         168 
## 0.026668220 0.017507471 0.014616295 0.006927151 0.013406888 0.039863648 
##         169         170         171         172         173         174 
## 0.013333860 0.025476147 0.010310170 0.017093171 0.011289353 0.007379547 
##         175         176         177         178         179         180 
## 0.016852388 0.009641470 0.005232694 0.004564893 0.009491344 0.007622706 
##         181         182         183         184         185         186 
## 0.010103651 0.016919681 0.007094367 0.048726277 0.019945838 0.011449314 
##         187         188         189         190         191         192 
## 0.033682539 0.016112619 0.010937542 0.019518296 0.008817416 0.009432814 
##         193         194         195         196         197         198 
## 0.011159844 0.015935602 0.011346615 0.023707724 0.011454850 0.011614175 
##         199         200         201         202         203         204 
## 0.032487570 0.011450285 0.011450285 0.009758939 0.047154286 0.038650862 
##         205         206         207         208         209         210 
## 0.016518405 0.009714717 0.007025938 0.019488888 0.026473168 0.019663292 
##         211         212         213         214         215         216 
## 0.005518215 0.010419537 0.013472930 0.019483877 0.005562504 0.016323292 
##         217         218         219         220         221         222 
## 0.008803025 0.024164276 0.024215372 0.024966231 0.006454325 0.013776071 
##         223         224         225         226         227         228 
## 0.012044251 0.014561013 0.021900566 0.090154296 0.006761197 0.004206441 
##         229         230         231         232         233         234 
## 0.016995448 0.012216170 0.017324058 0.023216692 0.009947364 0.009472993 
##         235         236         237         238         239         240 
## 0.012022863 0.004109356 0.020973781 0.019672149 0.013008303 0.029422286 
##         241         242         243         244         245         246 
## 0.008017159 0.012251083 0.016211976 0.020061468 0.007829044 0.006459345 
##         247         248         249         250         251         252 
## 0.005106999 0.011550829 0.019955491 0.016048904 0.007143485 0.013779744 
##         253         254         255         256         257         258 
## 0.012155635 0.010826406 0.027760308 0.026447111 0.011096481 0.020088980 
##         259         260         261         262         263         264 
## 0.010388276 0.022566414 0.016293626 0.014490819 0.011775960 0.008029282 
##         265         266         267         268         269         270 
## 0.011270485 0.044057042 0.008702455 0.006800662 0.015002586 0.020397536 
##         271         272         273         274         275         276 
## 0.013651473 0.014292654 0.005414930 0.010458032 0.007390733 0.005589231 
##         277         278         279         280         281         282 
## 0.005931936 0.021310075 0.013389474 0.008443575 0.024505423 0.017596282 
##         283         284         285         286         287         288 
## 0.006152791 0.013113872 0.015482611 0.006421245 0.011638294 0.056269125 
##         289         290         291         292         293         294 
## 0.007607091 0.021218679 0.014145101 0.010767288 0.032638404 0.115858668 
##         295         296         297         298         299         300 
## 0.009240870 0.019781118 0.009305909 0.008280141 0.016993468 0.006145425 
##         301         302         303         304         305         306 
## 0.041197809 0.043735024 0.041596721 0.019157840 0.017571328 0.009594539 
##         307         308         309         310         311         312 
## 0.042937930 0.030345452 0.021528550 0.011351148 0.019478696 0.074685131 
##         313         314         315         316         317         318 
## 0.014182978 0.006498347 0.009224285 0.029773898 0.017452787 0.015414406 
##         319         320         321         322 
## 0.006517587 0.023350560 0.034311818 0.026586988</code></pre>
<ol start="12" style="list-style-type: decimal">
<li>Cook’s distance</li>
</ol>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="regression.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cooks.distance</span>(fit) </span></code></pre></div>
<pre><code>##            1            2            3            4            5            6 
## 1.308592e-03 5.705311e-04 1.298001e-04 8.157102e-06 2.899129e-04 3.530628e-04 
##            7            8            9           10           11           12 
## 5.407724e-03 6.625300e-04 8.102785e-04 1.526903e-02 1.009766e-02 6.079316e-05 
##           13           14           15           16           17           18 
## 3.501665e-04 1.841952e-03 6.537319e-05 1.567719e-03 5.670199e-02 5.838737e-03 
##           19           20           21           22           23           24 
## 2.315692e-02 2.002218e-04 3.538359e-04 8.607109e-04 2.008226e-03 4.949953e-04 
##           25           26           27           28           29           30 
## 1.226394e-04 9.414806e-04 4.428745e-04 4.851258e-03 2.515499e-03 5.947274e-11 
##           31           32           33           34           35           36 
## 1.386438e-04 2.568990e-03 1.545866e-02 9.026603e-04 1.200915e-03 7.825012e-04 
##           37           38           39           40           41           42 
## 4.760944e-05 5.529492e-05 5.247297e-04 3.220869e-04 1.351955e-03 1.460987e-03 
##           43           44           45           46           47           48 
## 5.942311e-04 7.820152e-04 3.619834e-05 2.315908e-03 2.485987e-03 1.360085e-03 
##           49           50           51           52           53           54 
## 1.124141e-03 2.693628e-07 1.847775e-04 2.679221e-03 2.103659e-02 8.612816e-04 
##           55           56           57           58           59           60 
## 2.826087e-03 4.598796e-04 1.641593e-05 4.158286e-03 1.861016e-03 2.315908e-03 
##           61           62           63           64           65           66 
## 2.761767e-03 8.951186e-04 4.790738e-03 1.767146e-04 4.725449e-04 1.412544e-04 
##           67           68           69           70           71           72 
## 8.334281e-03 2.589587e-05 1.183340e-03 3.412731e-04 1.394567e-04 2.089759e-03 
##           73           74           75           76           77           78 
## 2.396259e-04 3.266101e-04 3.172684e-04 1.291725e-02 5.993279e-03 1.534064e-04 
##           79           80           81           82           83           84 
## 3.643868e-04 3.283265e-03 1.076007e-05 2.506365e-03 2.808742e-03 2.927729e-03 
##           85           86           87           88           89           90 
## 2.400836e-03 2.554640e-04 1.657139e-03 5.831673e-03 7.852013e-04 1.054210e-02 
##           91           92           93           94           95           96 
## 1.912855e-04 5.998073e-05 4.769643e-03 8.183636e-03 1.485934e-03 9.356122e-03 
##           97           98           99          100          101          102 
## 4.637910e-03 1.848741e-03 3.971904e-05 3.906164e-05 7.009046e-03 6.019843e-05 
##          103          104          105          106          107          108 
## 6.913051e-04 7.337907e-03 1.673076e-04 3.953755e-03 7.899237e-04 2.666564e-05 
##          109          110          111          112          113          114 
## 9.255637e-05 2.614175e-04 4.923767e-04 5.647398e-04 1.133435e-04 5.864498e-06 
##          115          116          117          118          119          120 
## 3.039394e-03 5.068279e-02 3.843092e-04 4.046225e-03 3.724893e-03 1.048745e-03 
##          121          122          123          124          125          126 
## 1.406198e-04 4.365522e-04 2.616462e-04 7.274832e-03 8.066535e-04 9.272117e-04 
##          127          128          129          130          131          132 
## 7.843396e-05 8.542223e-03 7.081944e-05 5.802238e-06 2.241028e-03 9.079590e-04 
##          133          134          135          136          137          138 
## 8.167030e-04 2.523025e-04 1.696596e-03 3.337139e-04 1.054514e-04 1.027199e-04 
##          139          140          141          142          143          144 
## 1.849748e-03 1.335636e-04 7.640332e-05 2.132536e-04 5.759215e-02 1.679853e-04 
##          145          146          147          148          149          150 
## 7.057766e-03 2.464134e-05 7.494393e-03 9.995089e-03 8.139462e-04 1.191900e-02 
##          151          152          153          154          155          156 
## 1.678328e-04 5.830562e-04 1.950881e-05 5.366192e-03 1.462263e-05 3.644235e-04 
##          157          158          159          160          161          162 
## 3.641145e-04 5.434970e-04 1.693405e-04 3.895443e-03 1.401089e-03 2.225058e-04 
##          163          164          165          166          167          168 
## 1.153475e-02 4.341026e-04 5.616351e-04 6.012421e-05 5.335918e-03 2.806997e-04 
##          169          170          171          172          173          174 
## 2.787315e-04 5.987766e-05 4.304480e-04 1.639434e-03 1.589772e-04 6.706961e-05 
##          175          176          177          178          179          180 
## 8.547970e-03 2.535458e-04 5.059449e-03 4.275792e-04 1.934672e-04 1.588082e-04 
##          181          182          183          184          185          186 
## 1.040397e-03 2.191814e-04 1.123929e-05 3.134870e-02 1.457624e-03 6.087848e-03 
##          187          188          189          190          191          192 
## 2.405560e-05 1.462131e-02 1.248379e-07 9.839603e-05 5.549584e-03 1.167821e-03 
##          193          194          195          196          197          198 
## 6.258805e-04 9.428088e-04 1.433802e-03 6.668224e-03 5.886511e-03 1.133451e-02 
##          199          200          201          202          203          204 
## 1.371566e-04 8.092471e-04 8.092471e-04 1.934592e-05 2.841357e-03 2.654375e-03 
##          205          206          207          208          209          210 
## 1.002875e-04 4.624815e-04 5.162650e-04 3.323246e-03 4.824841e-03 5.238667e-03 
##          211          212          213          214          215          216 
## 8.861357e-05 3.760665e-04 1.124082e-03 2.030127e-04 1.019462e-03 1.770559e-03 
##          217          218          219          220          221          222 
## 7.426750e-04 1.983126e-02 3.362539e-03 5.489719e-02 8.912243e-04 3.861126e-03 
##          223          224          225          226          227          228 
## 1.012498e-03 1.042337e-02 5.450894e-06 4.594310e-02 6.036803e-04 8.791811e-06 
##          229          230          231          232          233          234 
## 2.434405e-04 4.997640e-04 2.751178e-05 2.048674e-04 1.022781e-02 1.690026e-04 
##          235          236          237          238          239          240 
## 4.624915e-04 8.166388e-05 1.594181e-03 1.184740e-02 8.453239e-04 4.506433e-03 
##          241          242          243          244          245          246 
## 1.073313e-03 1.940133e-02 2.388653e-03 1.996705e-03 2.026070e-03 3.741211e-03 
##          247          248          249          250          251          252 
## 9.790355e-05 1.671764e-05 7.071308e-03 9.482676e-03 1.193045e-03 2.127993e-04 
##          253          254          255          256          257          258 
## 5.103040e-04 1.914122e-03 1.393252e-03 4.950183e-04 1.194125e-03 1.455668e-03 
##          259          260          261          262          263          264 
## 2.331199e-04 8.583741e-04 6.848319e-04 1.429737e-05 1.334413e-03 1.276603e-03 
##          265          266          267          268          269          270 
## 1.270867e-04 4.393568e-03 4.091818e-04 9.769267e-04 2.337696e-07 1.466273e-03 
##          271          272          273          274          275          276 
## 3.468689e-03 3.071660e-03 1.507986e-04 1.161117e-04 8.281309e-06 4.191486e-04 
##          277          278          279          280          281          282 
## 3.138795e-04 1.404048e-03 6.980238e-03 3.037553e-04 1.219677e-02 7.706650e-04 
##          283          284          285          286          287          288 
## 2.785345e-04 2.268187e-06 3.754742e-03 4.975412e-04 4.764492e-03 8.307689e-03 
##          289          290          291          292          293          294 
## 5.071347e-03 3.189743e-03 2.272351e-03 5.932885e-04 3.630127e-03 1.612791e-03 
##          295          296          297          298          299          300 
## 5.482221e-06 4.945145e-05 1.369278e-04 4.394633e-06 5.078921e-05 2.301369e-04 
##          301          302          303          304          305          306 
## 2.885774e-03 5.364991e-03 1.525613e-02 7.241014e-04 5.690486e-03 6.257843e-07 
##          307          308          309          310          311          312 
## 2.893694e-03 2.169113e-03 3.940629e-05 4.020168e-03 1.273467e-02 2.087566e-03 
##          313          314          315          316          317          318 
## 2.783534e-05 1.525826e-06 1.013384e-03 1.481132e-03 5.981324e-03 4.313059e-03 
##          319          320          321          322 
## 2.654295e-05 1.031336e-03 1.054840e-05 1.064087e-02</code></pre>
<ol start="13" style="list-style-type: decimal">
<li>DFFITS</li>
</ol>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="regression.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dffits</span>(fit)</span></code></pre></div>
<pre><code>##             1             2             3             4             5 
##  0.0886435653  0.0584206340 -0.0278673354 -0.0069848593 -0.0416458730 
##             6             7             8             9            10 
##  0.0459578802 -0.1803948982  0.0630288648 -0.0696289779  0.3041268173 
##            11            12            13            14            15 
##  0.2487886225 -0.0190689445  0.0457950829 -0.1050546722  0.0197751513 
##            16            17            18            19            20 
## -0.0969655468  0.5842585112  0.1870346643  0.3771523432 -0.0346073115 
##            21            22            23            24            25 
## -0.0460126280 -0.0717828375 -0.1097815225  0.0544316846 -0.0270869239 
##            26            27            28            29            30 
## -0.0750447659  0.0514994146 -0.1711725900 -0.1226974485 -0.0000188602 
##            31            32            33            34            35 
## -0.0288051315  0.1240836283  0.3049468149 -0.0735407544  0.0848228780 
##            36            37            38            39            40 
## -0.0684325591  0.0168754890  0.0181865787  0.0560392175  0.0438970173 
##            41            42            43            44            45 
##  0.0900982112 -0.0935255710  0.0596277370  0.0684105730  0.0147142618 
##            46            47            48            49            50 
##  0.1179250413 -0.1223090211  0.0903195725 -0.0820550880 -0.0012692767 
##            51            52            53            54            55 
##  0.0332461319 -0.1269836051 -0.3556847325  0.0718416886  0.1301700153 
##            56            57            58            59            60 
##  0.0524552798 -0.0099088398 -0.1591747785  0.1055677567  0.1179250413 
##            61            62            63            64            65 
##  0.1287518727 -0.0732077408 -0.1701567071 -0.0325142270  0.0531792616 
##            66            67            68            69            70 
## -0.0290689848 -0.2235736669  0.0124455019  0.0841670620  0.0451967530 
##            71            72            73            74            75 
##  0.0288870254  0.1118937491 -0.0378729223  0.0442239324  0.0435689164 
##            76            77            78            79            80 
##  0.2787537299  0.1901872616 -0.0302980024 -0.0467034448 -0.1408183618 
##            81            82            83            84            85 
##  0.0080222762 -0.1227571512 -0.1297261413 -0.1325926275 -0.1199656754 
##            86            87            88            89            90 
## -0.0390993318 -0.0996997666 -0.1870706388 -0.0685592579 -0.2517947712 
##            91            92            93            94            95 
## -0.0338368471  0.0189406747 -0.1693853947 -0.2215754995  0.0943153403 
##            96            97            98            99           100 
## -0.2375375463  0.1672018675  0.1053036212  0.0154145346 -0.0152852818 
##           101           102           103           104           105 
##  0.2054764483  0.0189758888  0.0643530376 -0.2099395288 -0.0316444470 
##           106           107           108           109           110 
## -0.1539385705  0.0687803363 -0.0126293242 -0.0235289637 -0.0395495942 
##           111           112           113           114           115 
## -0.0542894895  0.0581543675  0.0260400034  0.0059225129 -0.1354812202 
##           116           117           118           119           120 
##  0.5590763124  0.0479514568  0.1558773419 -0.1496566234 -0.0792620445 
##           121           122           123           124           125 
##  0.0290014733  0.0511143413  0.0395627678 -0.2089909829 -0.0695025889 
##           126           127           128           129           130 
##  0.0745045173 -0.0216617138 -0.2266394355 -0.0205814324 -0.0058909689 
##           131           132           133           134           135 
## -0.1159212369 -0.0737621257  0.0699183648  0.0388647640 -0.1008508252 
##           136           137           138           139           140 
##  0.0446906015  0.0251150606  0.0247880256 -0.1053316177 -0.0282671747 
##           141           142           143           144           145 
## -0.0213780821  0.0357192912  0.5996147761  0.0317082850  0.2064921450 
##           146           147           148           149           150 
##  0.0121404203  0.2124331520 -0.2452279908  0.0698076540  0.2678964859 
##           151           152           153           154           155 
## -0.0316883559 -0.0591320142  0.0108021710 -0.1799392007 -0.0093519740 
##           156           157           158           159           160 
##  0.0466912251 -0.0466765533  0.0570743586 -0.0318278703 -0.1529008053 
##           161           162           163           164           165 
## -0.0917778554  0.0364907732 -0.2637145962 -0.0509664051  0.0579789933 
##           166           167           168           169           170 
## -0.0189647706 -0.1793151458 -0.0409766303 -0.0408380917  0.0189247097 
##           171           172           173           174           175 
##  0.0507595918 -0.0991113382 -0.0308398409  0.0200302996 -0.2271876543 
##           176           177           178           179           180 
## -0.0389513878  0.1755663707  0.0506151342  0.0340231334  0.0308254274 
##           181           182           183           184           185 
## -0.0789600972 -0.0362110996  0.0081990439 -0.4355472754 -0.0934341381 
##           186           187           188           189           190 
##  0.1917773705  0.0119949474  0.2982587364  0.0008640932 -0.0242603200 
##           191           192           193           194           195 
##  0.1832757696 -0.0836723062  0.0612155608 -0.0751344922 -0.0927144883 
##           196           197           198           199           200 
## -0.2002292837 -0.1885476011  0.2627862711 -0.0286426077 -0.0696171419 
##           201           202           203           204           205 
## -0.0696171419 -0.0107569742 -0.1304328818 -0.1260784526 -0.0244926252 
##           206           207           208           209           210 
##  0.0526173559 -0.0556063957 -0.1412079263  0.1701616352 -0.1774505266 
##           211           212           213           214           215 
## -0.0230251963  0.0474424374  0.0820589568  0.0348490587  0.0782214031 
##           216           217           218           219           220 
##  0.1030108368  0.0667009182 -0.3470482620 -0.1419974095  0.5850420091 
##           221           222           223           224           225 
## -0.0731050276  0.1523656308 -0.0778802323  0.2513735861  0.0057098177 
##           226           227           228           229           230 
##  0.5265234264  0.0601390861  0.0072516212  0.0381629419  0.0546936006 
##           231           232           233           234           235 
##  0.0128278276 -0.0350073544  0.2497565205 -0.0317985254  0.0526133573 
##           236           237           238           239           240 
## -0.0221046668 -0.0977154397 -0.2676990365 -0.0711481389  0.1644059853 
##           241           242           243           244           245 
## -0.0802229822  0.3458201463  0.1196912486 -0.1093822284  0.1103508723 
##           246           247           248           249           250 
##  0.1504108461 -0.0242027784 -0.0099995557 -0.2063354537  0.2394766680 
##           251           252           253           254           255 
## -0.0846058676  0.0356808540 -0.0552678941  0.1071752252  0.0913278903 
##           256           257           258           259           260 
##  0.0544218272 -0.0845963301  0.0933708870 -0.0373481053  0.0716768674 
##           261           262           263           264           265 
## -0.0640250463  0.0092473969 -0.0894323652  0.0875117678  0.0275729582 
##           266           267           268           269           270 
##  0.1622517757  0.0494923164  0.0765433373 -0.0011824464  0.0937098573 
##           271           272           273           274           275 
## -0.1443795968 -0.1358154245 -0.0300400250 -0.0263554621  0.0070378734 
##           276           277           278           279           280 
##  0.0501047667  0.0433496700 -0.0916947180  0.2053305507 -0.0426379589 
##           281           282           283           284           285 
##  0.2713444361  0.0679199965 -0.0408331099  0.0036832188  0.1501979730 
##           286           287           288           289           290 
##  0.0545908106  0.1694612224 -0.2232043863 -0.1752645436 -0.1383160917 
##           291           292           293           294           295 
##  0.1167559460 -0.0595998501 -0.1475000996 -0.0982261512  0.0057262203 
##           296           297           298           299           300 
## -0.0171983583 -0.0286215619 -0.0051268528 -0.0174295114  0.0371136812 
##           301           302           303           304           305 
##  0.1314605979 -0.1793312848 -0.3030844895 -0.0658324406 -0.1850451948 
##           306           307           308           309           310 
## -0.0019346391 -0.1316375424 -0.1139762498 -0.0153524430 -0.1555815013 
##           311           312           313           314           315 
## -0.2776774054 -0.1117671289  0.0129030854 -0.0030209310 -0.0779333886 
##           316           317           318           319           320 
## -0.0941636561 -0.1897487246 -0.1610344888  0.0126002338 -0.0785715750 
##           321           322 
##  0.0079429522  0.2532142400</code></pre>
</div>
<div id="with-sas-19" class="section level4 hasAnchor" number="5.3.7.2">
<h4><span class="header-section-number">5.3.7.2</span> With SAS<a href="regression.html#with-sas-19" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<blockquote>
<p>SAS Code</p>
</blockquote>
<pre><code>filename reg_data URL &quot;https://elflini.github.io/study/statanal/data/5.%20correlation_and_regression.csv&quot; termstr=crlf; 

proc import out=healthdata
datafile=reg_data
dbms=csv replace;
getnames=yes;
run;</code></pre>
<ol style="list-style-type: decimal">
<li>모든 변수를 사용하는 경우</li>
</ol>
<pre><code>proc sgscatter data=healthdata;
  title &quot;Scatterplot Matrix&quot;;
  matrix sbp age height weight waistline bmi ;
run;</code></pre>
<p><img src="regression/reg3.png" style="width:80.0%" /></p>
<pre><code>proc corr data=healthdata plots=matrix;
var sbp age height weight waistline bmi;
run;</code></pre>
<p><img src="regression/reg4.png" style="width:80.0%" /></p>
<pre><code>ods graphics on;
proc reg data=healthdata plots=residuals plots=QQ;
model sbp=age height weight waistline bmi/stb dw dwprob influence vif;
run;
ods graphics off;</code></pre>
<p><img src="regression/ex16.jpg" style="width:80.0%" /></p>
<p><img src="regression/ex17.jpg" style="width:60.0%" /></p>
<p><img src="regression/ex18.jpg" style="width:60.0%" /></p>
<p><img src="regression/ex19.jpg" style="width:50.0%" /></p>
<p><img src="regression/ex20.jpg" style="width:60.0%" /></p>
<ol start="2" style="list-style-type: decimal">
<li>단계적 선택법을 사용하는 경우</li>
</ol>
<pre><code>ods graphics on;
proc reg data=healthdata plots=diagnostics(stats=(default aic bic)) plots=QQ;
model sbp=age height weight waistline bmi/selection=stepwise stb dw dwprob influence vif sle=0.1 sls=0.05;
run;
ods graphics off;</code></pre>
<p><img src="regression/ex22.jpg" style="width:60.0%" /></p>
<p><img src="regression/ex23.jpg" style="width:60.0%" /></p>
<p><img src="regression/ex24.jpg" style="width:80.0%" /></p>
<p><img src="regression/ex25.jpg" style="width:80.0%" /></p>
<p><img src="regression/ex26.jpg" style="width:60.0%" /></p>
<p><img src="regression/ex27.jpg" style="width:50.0%" /></p>
<p><img src="regression/ex28.jpg" style="width:80.0%" /></p>
<!-------------------------------------->

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="category.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Statistical Analysis.pdf", "Statistical Analysis.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
