<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introduction | Statistical Learning</title>
  <meta name="description" content="This is a Statistical Learning" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introduction | Statistical Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a Statistical Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction | Statistical Learning" />
  
  <meta name="twitter:description" content="This is a Statistical Learning" />
  

<meta name="author" content="Jin Hyun Nam" />


<meta name="date" content="2023-05-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="chapter2.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>머리말</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#understanding-data"><i class="fa fa-check"></i><b>1.1</b> Understanding Data</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="chapter1.html"><a href="chapter1.html#example-1-supervised-learning-continuous-output"><i class="fa fa-check"></i><b>1.1.1</b> Example 1 (Supervised learning: Continuous output)</a></li>
<li class="chapter" data-level="1.1.2" data-path="chapter1.html"><a href="chapter1.html#example-2-supervised-leraning-categorical-output"><i class="fa fa-check"></i><b>1.1.2</b> Example 2 (Supervised leraning: Categorical output)</a></li>
<li class="chapter" data-level="1.1.3" data-path="chapter1.html"><a href="chapter1.html#example-3-unsupervised-learning-clustering-observations"><i class="fa fa-check"></i><b>1.1.3</b> Example 3 (Unsupervised learning: Clustering observations)</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#brief-history-of-statistical-learning"><i class="fa fa-check"></i><b>1.2</b> Brief History of Statistical Learning</a></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#notation-and-simple-matrix-algebra"><i class="fa fa-check"></i><b>1.3</b> Notation and Simple Matrix Algebra</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#what-is-statitical-learning"><i class="fa fa-check"></i><b>2.1</b> What is Statitical Learning</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="chapter2.html"><a href="chapter2.html#prediction"><i class="fa fa-check"></i><b>2.1.1</b> Prediction</a></li>
<li class="chapter" data-level="2.1.2" data-path="chapter2.html"><a href="chapter2.html#inference"><i class="fa fa-check"></i><b>2.1.2</b> Inference</a></li>
<li class="chapter" data-level="2.1.3" data-path="chapter2.html"><a href="chapter2.html#estimating-f"><i class="fa fa-check"></i><b>2.1.3</b> Estimating <span class="math inline">\(f\)</span></a></li>
<li class="chapter" data-level="2.1.4" data-path="chapter2.html"><a href="chapter2.html#prediction-accuaracy-and-model-interpretability"><i class="fa fa-check"></i><b>2.1.4</b> Prediction Accuaracy and Model Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#assessing-model-accuracy"><i class="fa fa-check"></i><b>2.2</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="chapter2.html"><a href="chapter2.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>2.2.1</b> Measuring the Quality of Fit</a></li>
<li class="chapter" data-level="2.2.2" data-path="chapter2.html"><a href="chapter2.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2.2</b> Bias-Variance Trade-off</a></li>
<li class="chapter" data-level="2.2.3" data-path="chapter2.html"><a href="chapter2.html#classification-problems"><i class="fa fa-check"></i><b>2.2.3</b> Classification Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#basic-commands"><i class="fa fa-check"></i><b>3.1</b> Basic Commands</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#graphics"><i class="fa fa-check"></i><b>3.2</b> Graphics</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#indexing-data"><i class="fa fa-check"></i><b>3.3</b> Indexing Data</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#loading-data"><i class="fa fa-check"></i><b>3.4</b> Loading Data</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#additional-graphical-and-numerical-summaries"><i class="fa fa-check"></i><b>3.5</b> Additional Graphical and Numerical Summaries</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#simple-regression"><i class="fa fa-check"></i><b>4.1</b> Simple Regression</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#multiple-regression"><i class="fa fa-check"></i><b>4.2</b> Multiple Regression</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="chapter4.html"><a href="chapter4.html#importance-of-predictors-statistical-significance-of-coefficients"><i class="fa fa-check"></i><b>4.2.1</b> Importance of Predictors: Statistical Significance of Coefficients</a></li>
<li class="chapter" data-level="4.2.2" data-path="chapter4.html"><a href="chapter4.html#selecting-important-variables"><i class="fa fa-check"></i><b>4.2.2</b> Selecting Important Variables</a></li>
<li class="chapter" data-level="4.2.3" data-path="chapter4.html"><a href="chapter4.html#model-fit"><i class="fa fa-check"></i><b>4.2.3</b> Model Fit</a></li>
<li class="chapter" data-level="4.2.4" data-path="chapter4.html"><a href="chapter4.html#prediction-1"><i class="fa fa-check"></i><b>4.2.4</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#other-consideration"><i class="fa fa-check"></i><b>4.3</b> Other Consideration</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="chapter4.html"><a href="chapter4.html#qualitative-predictors"><i class="fa fa-check"></i><b>4.3.1</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="" data-path="chapter4.html"><a href="chapter4.html#example-8"><i class="fa fa-check"></i>Example 8</a></li>
<li class="chapter" data-level="4.3.2" data-path="chapter4.html"><a href="chapter4.html#potential-problems"><i class="fa fa-check"></i><b>4.3.2</b> Potential Problems</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="chapter4.html"><a href="chapter4.html#non-parametric-regressions"><i class="fa fa-check"></i><b>4.4</b> Non-parametric Regressions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Classification</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#logit-and-probit-models"><i class="fa fa-check"></i><b>5.1</b> Logit and Probit Models</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#confounding"><i class="fa fa-check"></i><b>5.2</b> Confounding</a></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#logit-model-for-multiple-classes"><i class="fa fa-check"></i><b>5.3</b> Logit Model for Multiple Classes</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#discriminant-analysis"><i class="fa fa-check"></i><b>5.4</b> Discriminant Analysis</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="chapter5.html"><a href="chapter5.html#bayes-theorem-for-classification"><i class="fa fa-check"></i><b>5.4.1</b> Bayes Theorem for Classification</a></li>
<li class="chapter" data-level="5.4.2" data-path="chapter5.html"><a href="chapter5.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>5.4.2</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="5.4.3" data-path="chapter5.html"><a href="chapter5.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>5.4.3</b> Quadratic Discriminant Analysis</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#naive-bayes"><i class="fa fa-check"></i><b>5.5</b> Naive Bayes</a></li>
<li class="chapter" data-level="5.6" data-path="chapter5.html"><a href="chapter5.html#knn-classification"><i class="fa fa-check"></i><b>5.6</b> KNN Classification</a></li>
<li class="chapter" data-level="5.7" data-path="chapter5.html"><a href="chapter5.html#example-10"><i class="fa fa-check"></i><b>5.7</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Resampling Methods</a>
<ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#validation-set-approach"><i class="fa fa-check"></i><b>6.1</b> Validation Set Approach</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>6.2</b> K-fold Cross-validation</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="chapter6.html"><a href="chapter6.html#example-11"><i class="fa fa-check"></i><b>6.2.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#bootstrap"><i class="fa fa-check"></i><b>6.3</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Model Selection</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#variable-selection"><i class="fa fa-check"></i><b>7.1</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="chapter7.html"><a href="chapter7.html#best-subset-selection"><i class="fa fa-check"></i><b>7.1.1</b> Best Subset Selection</a></li>
<li class="chapter" data-level="7.1.2" data-path="chapter7.html"><a href="chapter7.html#forward-step-wise-selection"><i class="fa fa-check"></i><b>7.1.2</b> Forward Step Wise Selection</a></li>
<li class="chapter" data-level="7.1.3" data-path="chapter7.html"><a href="chapter7.html#backward-step-wise-selection"><i class="fa fa-check"></i><b>7.1.3</b> Backward Step Wise Selection</a></li>
<li class="chapter" data-level="7.1.4" data-path="chapter7.html"><a href="chapter7.html#choosing-the-optimal-model"><i class="fa fa-check"></i><b>7.1.4</b> Choosing the Optimal Model</a></li>
<li class="chapter" data-level="7.1.5" data-path="chapter7.html"><a href="chapter7.html#example-13"><i class="fa fa-check"></i><b>7.1.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#shrinkage-methods"><i class="fa fa-check"></i><b>7.2</b> Shrinkage Methods</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="chapter7.html"><a href="chapter7.html#ridge-regression"><i class="fa fa-check"></i><b>7.2.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="7.2.2" data-path="chapter7.html"><a href="chapter7.html#rasso-regression"><i class="fa fa-check"></i><b>7.2.2</b> RASSO Regression</a></li>
<li class="chapter" data-level="7.2.3" data-path="chapter7.html"><a href="chapter7.html#example-14"><i class="fa fa-check"></i><b>7.2.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#dimension-reduction-methods"><i class="fa fa-check"></i><b>7.3</b> Dimension Reduction Methods</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="chapter7.html"><a href="chapter7.html#principal-components-regression"><i class="fa fa-check"></i><b>7.3.1</b> Principal Components Regression</a></li>
<li class="chapter" data-level="7.3.2" data-path="chapter7.html"><a href="chapter7.html#example-15"><i class="fa fa-check"></i><b>7.3.2</b> Example</a></li>
<li class="chapter" data-level="7.3.3" data-path="chapter7.html"><a href="chapter7.html#partial-least-squares"><i class="fa fa-check"></i><b>7.3.3</b> Partial Least Squares</a></li>
<li class="chapter" data-level="7.3.4" data-path="chapter7.html"><a href="chapter7.html#example-16"><i class="fa fa-check"></i><b>7.3.4</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Moving Beyond Linearity</a>
<ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#polynomial-regression"><i class="fa fa-check"></i><b>8.1</b> Polynomial Regression</a></li>
<li class="chapter" data-level="8.2" data-path="chapter8.html"><a href="chapter8.html#step-functions"><i class="fa fa-check"></i><b>8.2</b> Step Functions</a></li>
<li class="chapter" data-level="8.3" data-path="chapter8.html"><a href="chapter8.html#piecewise-polynomials---splines"><i class="fa fa-check"></i><b>8.3</b> Piecewise Polynomials - Splines</a></li>
<li class="chapter" data-level="8.4" data-path="chapter8.html"><a href="chapter8.html#local-regression"><i class="fa fa-check"></i><b>8.4</b> Local Regression</a></li>
<li class="chapter" data-level="8.5" data-path="chapter8.html"><a href="chapter8.html#generalized-additive-models"><i class="fa fa-check"></i><b>8.5</b> Generalized Additive Models</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Tree-based Methods</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#the-basiscs-of-decision-trees"><i class="fa fa-check"></i><b>9.1</b> The Basiscs of Decision Trees</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#classification-trees"><i class="fa fa-check"></i><b>9.2</b> Classification Trees</a></li>
<li class="chapter" data-level="9.3" data-path="chapter9.html"><a href="chapter9.html#bagging"><i class="fa fa-check"></i><b>9.3</b> Bagging</a></li>
<li class="chapter" data-level="9.4" data-path="chapter9.html"><a href="chapter9.html#random-forests"><i class="fa fa-check"></i><b>9.4</b> Random Forests</a></li>
<li class="chapter" data-level="9.5" data-path="chapter9.html"><a href="chapter9.html#boosing"><i class="fa fa-check"></i><b>9.5</b> Boosing</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chapter10.html"><a href="chapter10.html"><i class="fa fa-check"></i><b>10</b> Support Vector Machines</a></li>
<li class="chapter" data-level="11" data-path="chapter11.html"><a href="chapter11.html"><i class="fa fa-check"></i><b>11</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="11.1" data-path="chapter11.html"><a href="chapter11.html#principal-components-anlsysis"><i class="fa fa-check"></i><b>11.1</b> Principal Components Anlsysis</a></li>
<li class="chapter" data-level="11.2" data-path="chapter11.html"><a href="chapter11.html#clustering"><i class="fa fa-check"></i><b>11.2</b> Clustering</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="chapter11.html"><a href="chapter11.html#k-means-clustering"><i class="fa fa-check"></i><b>11.2.1</b> <span class="math inline">\(K\)</span>-means clustering</a></li>
<li class="chapter" data-level="11.2.2" data-path="chapter11.html"><a href="chapter11.html#hierarchical-clustering"><i class="fa fa-check"></i><b>11.2.2</b> Hierarchical Clustering</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter1" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> Introduction<a href="chapter1.html#chapter1" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="statistics-in-the-news" class="section level4 unnumbered hasAnchor">
<h4>Statistics in the news<a href="chapter1.html#statistics-in-the-news" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><img src="fig1/s1.png" /></p>
<ul>
<li>“It’s machine learning allows the computer to become smarter as it tries to answer questions - and to learn as it gets them right or wrong.”</li>
</ul>
<p><img src="fig1/s2.png" /></p>
</div>
<div id="statistical-learning-problems" class="section level4 unnumbered hasAnchor">
<h4>Statistical learning problems<a href="chapter1.html#statistical-learning-problems" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Identify the risk factors for prostate cancer.</li>
</ul>
<p><img src="fig1/s3.png" /></p>
<ul>
<li>Classify a recorded phoneme based on a log-periodogram</li>
</ul>
<p><img src="fig1/s4.png" /></p>
<ul>
<li>Predict whether someone will have a heart attack on the basis
of demographic, diet and clinical measurements.</li>
</ul>
<p><img src="fig1/s5.png" /></p>
<ul>
<li>Customize an email spam detection system.
<ul>
<li>data from 4601 emails sent to an individual (named George,
at HP labs, before 2000). Each is labeled as spam or email.</li>
<li>goal: build a customized spam filter.</li>
<li>input features: relative frequencies of 57 of the most
commonly occurring words and punctuation marks in these
email messages.</li>
</ul></li>
</ul>
<p><img src="fig1/s6.png" /></p>
<ul>
<li><p>Average percentage of words or characters in an email message equal
to the indicated word or character. We have chosen the words and
characters showing the largest difference between spam and email.</p></li>
<li><p>Identify the numbers in a handwritten zip code.</p></li>
</ul>
<p><img src="fig1/s7.png" /></p>
<ul>
<li>Classify a tissue sample into one of several cancer classes,
based on a gene expression profile.</li>
</ul>
<p><img src="fig1/s8.png" /></p>
<ul>
<li>Establish the relationship between salary and demographic
variables in population survey data.</li>
</ul>
<p><img src="fig1/s9.png" /></p>
<ul>
<li>Classify the pixels in a LANDSAT image, by usage.</li>
</ul>
<p><img src="fig1/s10.png" /></p>
<ul>
<li>In these classes we take a statistical learning perspective to
statistical techniques of which various multivariate analyses are
part of. According to James et al. p.1.</li>
</ul>
</div>
<div id="statistical-learning-refers-to-a-vast-set-of-tools-for-understanding-data." class="section level4 unnumbered hasAnchor">
<h4>Statistical learning refers to a vast set of tools for understanding data.<a href="chapter1.html#statistical-learning-refers-to-a-vast-set-of-tools-for-understanding-data." class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="understanding-data" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Understanding Data<a href="chapter1.html#understanding-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Tools for understanding data can be broadly classified as</p>
<div id="supervised-learning" class="section level4 unnumbered hasAnchor">
<h4>Supervised learning<a href="chapter1.html#supervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Supervised learning involves building a statistical model for predicting, or
estimating, an output based on one or more inputs.</p>
<ul>
<li><p>The key is learning from training data set and use the training results for
prediction purposes as new input data becomes available.</p>
<ul>
<li>The learning problem consist of inferring from the training data set the function
that can be used to map future inputs to predictions, i.e., give input variables x
and output variable(s) <span class="math inline">\(y\)</span>, find function <span class="math inline">\(f\)</span> such that <span class="math inline">\(f(x) \approx y\)</span> in a predictive way.</li>
</ul></li>
</ul></li>
<li><p>Starting point:</p>
<ul>
<li>Outcome measurement <span class="math inline">\(Y\)</span> (also called dependent variable, response, target)</li>
<li>Vector of <span class="math inline">\(p\)</span> predictor measurements <span class="math inline">\(X\)</span> (also called inputs, regressors, covariates, features, independent variables).</li>
<li>In the <em>regression problem</em>, <span class="math inline">\(Y\)</span> is quantitative (e.g price, blood pressure).</li>
<li>In the *classification problem, <span class="math inline">\(Y\)</span> takes values in a finite, unordered set (survived/died, digit 0-9, cancer class of tissue sample).</li>
<li>We have training data <span class="math inline">\((x_1,y_1), \ldots, (x_N,y_N)\)</span>. These are observations (examples, instances) of these measurements.</li>
</ul></li>
<li><p>Tools</p>
<ul>
<li>Regression methods; find the functional mapping of input variables to quantitative
output variable(s) (e.g. how wage is related to some background variables, like
age, education, gender, etc.).</li>
<li>Classification methods; find functional mapping of input variables to discrete set of
classes (e.g. how different financial ratios predict firm solvency {solvent,
non-solvent}).</li>
</ul></li>
<li><p>On the basis of the training data we would like to:</p>
<ul>
<li>Accurately predict unseen test cases.</li>
<li>Understand which inputs affect the outcome, and how.</li>
<li>Assess the quality of out predictions and inferences.</li>
</ul></li>
</ul>
</div>
<div id="unsupervised-learning" class="section level4 unnumbered hasAnchor">
<h4>Unsupervised learning<a href="chapter1.html#unsupervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>There are inputs but no supervising output; from such
data we can learn relationships and structures.
<ul>
<li>No outcome variable, just a set of predictors (features)
measured on a set of samples.</li>
<li>objective is more fuzzy - find groups of samples that
behave similarly, find features that behave similarly, find
linear combinations of features with the most variation.</li>
<li>difficult to know how well your are doing.</li>
<li>different from supervised learning, but can be useful as a
pre-processing step for supervised learning.</li>
</ul></li>
<li>Tools: various clustering methods</li>
</ul>
</div>
<div id="the-netflix-prize" class="section level4 unnumbered hasAnchor">
<h4>The Netflix prize<a href="chapter1.html#the-netflix-prize" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Competition started in October 2006. Training data is
ratings for 18,000 movies by 400000 Netflix customers,
each rating between 1 and 5.</li>
<li>Training data is very sparse| about 98% missing.</li>
<li>Objective is to predict the rating for a set of 1 million
customer-movie pairs that are missing in the training data.</li>
<li>Netflix’s original algorithm achieved a root MSE of 0.953.</li>
<li>The first team to achieve a 10% improvement wins one
million dollars.</li>
<li>Is this a supervised or unsupervised problem?</li>
</ul>
<p><img src="fig1/s11.png" /></p>
</div>
<div id="statistical-learning-versus-machine-learning" class="section level4 unnumbered hasAnchor">
<h4>Statistical Learning versus Machine Learning<a href="chapter1.html#statistical-learning-versus-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Machine learning arose as a subfield of Artificial Intelligence.</li>
<li>Statistical learning arose as a subfield of Statistics.</li>
<li>There is much overlap - both fields focus on supervised
and unsupervised problems:
<ul>
<li>Machine learning has a greater emphasis on large scale
applications and prediction accuracy.</li>
<li>Statistical learning emphasizes models and their
interpretability, and precision and uncertainty.</li>
</ul></li>
<li>But the distinction has become more and more blurred, and there is a great deal of “cross-fertilization”.</li>
<li>Machine learning has the upper hand in Marketing!</li>
</ul>
</div>
<div id="example-1-supervised-learning-continuous-output" class="section level3 hasAnchor" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Example 1 (Supervised learning: Continuous output)<a href="chapter1.html#example-1-supervised-learning-continuous-output" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Wages of a group of men from the Atlantic region of the US.</p></li>
<li><p>The interest is in the relation/effects of various background factors (like age, education,
calendar year) on wage</p></li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="chapter1.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages(&quot;ISLR2&quot;) # install ISLR2 if not done yet</span></span>
<span id="cb1-2"><a href="chapter1.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;ISLR2&quot;</span>) <span class="co"># load ISLR2</span></span>
<span id="cb1-3"><a href="chapter1.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">help</span>(<span class="at">package =</span> <span class="st">&quot;ISLR2&quot;</span>) <span class="co"># short info about the package</span></span></code></pre></div>
<p><img src="fig1/help.png" /></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="chapter1.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Wage) <span class="co"># summarizing Wage data</span></span></code></pre></div>
<pre><code>##       year           age                     maritl           race     
##  Min.   :2003   Min.   :18.00   1. Never Married: 648   1. White:2480  
##  1st Qu.:2004   1st Qu.:33.75   2. Married      :2074   2. Black: 293  
##  Median :2006   Median :42.00   3. Widowed      :  19   3. Asian: 190  
##  Mean   :2006   Mean   :42.41   4. Divorced     : 204   4. Other:  37  
##  3rd Qu.:2008   3rd Qu.:51.00   5. Separated    :  55                  
##  Max.   :2009   Max.   :80.00                                          
##                                                                        
##               education                     region               jobclass   
##  1. &lt; HS Grad      :268   2. Middle Atlantic   :3000   1. Industrial :1544  
##  2. HS Grad        :971   1. New England       :   0   2. Information:1456  
##  3. Some College   :650   3. East North Central:   0                        
##  4. College Grad   :685   4. West North Central:   0                        
##  5. Advanced Degree:426   5. South Atlantic    :   0                        
##                           6. East South Central:   0                        
##                           (Other)              :   0                        
##             health      health_ins      logwage           wage       
##  1. &lt;=Good     : 858   1. Yes:2083   Min.   :3.000   Min.   : 20.09  
##  2. &gt;=Very Good:2142   2. No : 917   1st Qu.:4.447   1st Qu.: 85.38  
##                                      Median :4.653   Median :104.92  
##                                      Mean   :4.654   Mean   :111.70  
##                                      3rd Qu.:4.857   3rd Qu.:128.68  
##                                      Max.   :5.763   Max.   :318.34  
## </code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="chapter1.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Wage) <span class="co"># structure of Wage data</span></span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    3000 obs. of  11 variables:
##  $ year      : int  2006 2004 2003 2003 2005 2008 2009 2008 2006 2004 ...
##  $ age       : int  18 24 45 43 50 54 44 30 41 52 ...
##  $ maritl    : Factor w/ 5 levels &quot;1. Never Married&quot;,..: 1 1 2 2 4 2 2 1 1 2 ...
##  $ race      : Factor w/ 4 levels &quot;1. White&quot;,&quot;2. Black&quot;,..: 1 1 1 3 1 1 4 3 2 1 ...
##  $ education : Factor w/ 5 levels &quot;1. &lt; HS Grad&quot;,..: 1 4 3 4 2 4 3 3 3 2 ...
##  $ region    : Factor w/ 9 levels &quot;1. New England&quot;,..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ jobclass  : Factor w/ 2 levels &quot;1. Industrial&quot;,..: 1 2 1 2 2 2 1 2 2 2 ...
##  $ health    : Factor w/ 2 levels &quot;1. &lt;=Good&quot;,&quot;2. &gt;=Very Good&quot;: 1 2 1 2 1 2 2 1 2 2 ...
##  $ health_ins: Factor w/ 2 levels &quot;1. Yes&quot;,&quot;2. No&quot;: 2 2 1 1 1 1 1 1 1 1 ...
##  $ logwage   : num  4.32 4.26 4.88 5.04 4.32 ...
##  $ wage      : num  75 70.5 131 154.7 75 ...</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="chapter1.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)) <span class="co"># divide the screen vertically to three parts</span></span>
<span id="cb6-2"><a href="chapter1.html#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> Wage<span class="sc">$</span>age, <span class="at">y =</span> Wage<span class="sc">$</span>wage, <span class="at">xlab =</span> <span class="st">&quot;Age&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Annual Wage (1,000 USD)&quot;</span>, <span class="at">col =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>) <span class="co"># Wage and age</span></span>
<span id="cb6-3"><a href="chapter1.html#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(<span class="at">x =</span> Wage<span class="sc">$</span>age, <span class="at">y =</span> Wage<span class="sc">$</span>wage, <span class="at">f =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">5</span>), <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>) <span class="co"># impose trend line using lowess function</span></span>
<span id="cb6-4"><a href="chapter1.html#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> Wage<span class="sc">$</span>year, <span class="at">y =</span> Wage<span class="sc">$</span>wage, <span class="at">xlab =</span> <span class="st">&quot;Year&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Annual Wage (1,000 USD)&quot;</span>, <span class="at">col =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>) <span class="co"># year and wage</span></span>
<span id="cb6-5"><a href="chapter1.html#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(<span class="at">x =</span> Wage<span class="sc">$</span>year, <span class="at">y =</span> Wage<span class="sc">$</span>wage), <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>) <span class="co"># again using lowes to impose a trend line</span></span>
<span id="cb6-6"><a href="chapter1.html#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(<span class="fu">as.numeric</span>(Wage<span class="sc">$</span>education)), <span class="at">y =</span> Wage<span class="sc">$</span>wage, <span class="at">xlab =</span> <span class="st">&quot;Eduction Level&quot;</span>,</span>
<span id="cb6-7"><a href="chapter1.html#cb6-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Annual Wage (1,000 USD)&quot;</span>,</span>
<span id="cb6-8"><a href="chapter1.html#cb6-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;steel blue&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;yellow&quot;</span>, <span class="st">&quot;light blue&quot;</span>, <span class="st">&quot;red&quot;</span>)) <span class="do">## box plots (when x is a factor variable (catgorial variable))</span></span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<ul>
<li><p>There is considerable variability in wages. The trend in the left hand panel shows that wages
tend to rise up to age 45 followed some decreasing in older ages.</p></li>
<li><p>The middle panel show some increase over the years, the right hand panel shows clear incremental effect of education (1 = no high school diploma, 5 = advanced graduate degree).</p></li>
</ul>
<p><br></p>
</div>
<div id="example-2-supervised-leraning-categorical-output" class="section level3 hasAnchor" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Example 2 (Supervised leraning: Categorical output)<a href="chapter1.html#example-2-supervised-leraning-categorical-output" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Predict German stock market direction (Up or Down) next day on the basis of past few
days direction (daily returns from the beginning of 2012 until Oct 17, 2018).</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="chapter1.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Smarket) <span class="co"># summarizing Smarket data</span></span></code></pre></div>
<pre><code>##       Year           Lag1                Lag2                Lag3          
##  Min.   :2001   Min.   :-4.922000   Min.   :-4.922000   Min.   :-4.922000  
##  1st Qu.:2002   1st Qu.:-0.639500   1st Qu.:-0.639500   1st Qu.:-0.640000  
##  Median :2003   Median : 0.039000   Median : 0.039000   Median : 0.038500  
##  Mean   :2003   Mean   : 0.003834   Mean   : 0.003919   Mean   : 0.001716  
##  3rd Qu.:2004   3rd Qu.: 0.596750   3rd Qu.: 0.596750   3rd Qu.: 0.596750  
##  Max.   :2005   Max.   : 5.733000   Max.   : 5.733000   Max.   : 5.733000  
##       Lag4                Lag5              Volume           Today          
##  Min.   :-4.922000   Min.   :-4.92200   Min.   :0.3561   Min.   :-4.922000  
##  1st Qu.:-0.640000   1st Qu.:-0.64000   1st Qu.:1.2574   1st Qu.:-0.639500  
##  Median : 0.038500   Median : 0.03850   Median :1.4229   Median : 0.038500  
##  Mean   : 0.001636   Mean   : 0.00561   Mean   :1.4783   Mean   : 0.003138  
##  3rd Qu.: 0.596750   3rd Qu.: 0.59700   3rd Qu.:1.6417   3rd Qu.: 0.596750  
##  Max.   : 5.733000   Max.   : 5.73300   Max.   :3.1525   Max.   : 5.733000  
##  Direction 
##  Down:602  
##  Up  :648  
##            
##            
##            
## </code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="chapter1.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Smarket) <span class="co"># structure of Smarket data</span></span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1250 obs. of  9 variables:
##  $ Year     : num  2001 2001 2001 2001 2001 ...
##  $ Lag1     : num  0.381 0.959 1.032 -0.623 0.614 ...
##  $ Lag2     : num  -0.192 0.381 0.959 1.032 -0.623 ...
##  $ Lag3     : num  -2.624 -0.192 0.381 0.959 1.032 ...
##  $ Lag4     : num  -1.055 -2.624 -0.192 0.381 0.959 ...
##  $ Lag5     : num  5.01 -1.055 -2.624 -0.192 0.381 ...
##  $ Volume   : num  1.19 1.3 1.41 1.28 1.21 ...
##  $ Today    : num  0.959 1.032 -0.623 0.614 0.213 ...
##  $ Direction: Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 1 2 2 2 1 2 2 2 ...</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="chapter1.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb11-2"><a href="chapter1.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> Smarket<span class="sc">$</span>Direction, <span class="at">y =</span> Smarket<span class="sc">$</span>Lag1, <span class="at">ylab =</span> <span class="st">&quot;Today&#39;s Direction&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Dax Return (%) Yesterday&quot;</span>,</span>
<span id="cb11-3"><a href="chapter1.html#cb11-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">horizontal =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;orange&quot;</span>, <span class="st">&quot;skyblue&quot;</span>))</span>
<span id="cb11-4"><a href="chapter1.html#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> Smarket<span class="sc">$</span>Direction, <span class="at">y =</span> Smarket<span class="sc">$</span>Lag2, <span class="at">ylab =</span> <span class="st">&quot;Today&#39;s Direction&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Dax Return (%) Two Days Ago&quot;</span>,</span>
<span id="cb11-5"><a href="chapter1.html#cb11-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">horizontal =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;orange&quot;</span>, <span class="st">&quot;skyblue&quot;</span>))</span>
<span id="cb11-6"><a href="chapter1.html#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> Smarket<span class="sc">$</span>Direction, <span class="at">y =</span> Smarket<span class="sc">$</span>Lag3, <span class="at">ylab =</span> <span class="st">&quot;Today&#39;s Direction&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Dax Return (%) Three Days Ago&quot;</span>,</span>
<span id="cb11-7"><a href="chapter1.html#cb11-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">horizontal =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;orange&quot;</span>, <span class="st">&quot;skyblue&quot;</span>))</span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<ul>
<li>As valuable as it would be, the graphs show that most likely historical returns do not help much in predicting the direction of future stock markets.</li>
</ul>
<p><br></p>
</div>
<div id="example-3-unsupervised-learning-clustering-observations" class="section level3 hasAnchor" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Example 3 (Unsupervised learning: Clustering observations)<a href="chapter1.html#example-3-unsupervised-learning-clustering-observations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Clustering consumers according to their consumption habits is an example of
unsupervised learning.</p></li>
<li><p>The interest is to find clusters of similar consumers with similar consumption habits on
the basis of the collected purchasing data.</p></li>
<li><p>K-means clustering and various hierarchical clustering methods are popular tools.</p></li>
</ul>
<p><img src="fig1/ex3.png" /></p>
<p><br></p>
</div>
</div>
<div id="brief-history-of-statistical-learning" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Brief History of Statistical Learning<a href="chapter1.html#brief-history-of-statistical-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="brief-history" class="section level4 unnumbered hasAnchor">
<h4>Brief history:<a href="chapter1.html#brief-history" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Method of least squares (Legendre and Gauss, beginning of
19th century).</p></li>
<li><p>Linear discriminant analysis (Fisher, 1936).</p></li>
<li><p>Logistic regression (1940s by various authors).</p></li>
<li><p>Generalized linear models (Nelder and Wedderburn, 1970s).</p></li>
<li><p>Classification and regression trees (Breiman, Friedman, Olsen,
and Stone, 1980s).</p></li>
<li><p>Generalized additive models (Hastie and Tibshirani, 1986).</p></li>
<li><p>Neural networks (Rumelhart and McClelland, 1986).</p></li>
<li><p>Support vector machines (Vapnik, 1992)</p></li>
<li><p>Nowadays by the advent of machine learning and other
disciplines (analytics, big data), statistical learning is
becoming a new subfield in statistics.</p></li>
</ul>
<p><br></p>
</div>
</div>
<div id="notation-and-simple-matrix-algebra" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Notation and Simple Matrix Algebra<a href="chapter1.html#notation-and-simple-matrix-algebra" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Choosing notation is always a difficult task.</strong></p>
<ul>
<li><p>We will use <span class="math inline">\(n\)</span> to represent the number of distinct data points, or observations, in sample.</p></li>
<li><p>Let <span class="math inline">\(p\)</span> denote the number of variables that are available for use in making predictions.</p></li>
<li><p>For example, the Wage data set consist of 11 variables for 3,000 people, so we have <span class="math inline">\(n=3000\)</span> observations and <span class="math inline">\(p=11\)</span> variables (such as year, age, race, and more).</p></li>
<li><p>In general, we will let <span class="math inline">\(x_{ij}\)</span> represent the value of the <span class="math inline">\(j\)</span>th variable for the <span class="math inline">\(i\)</span>th observations, where <span class="math inline">\(i=1,2,\ldots,n\)</span> and <span class="math inline">\(j=1,2,\ldots,p\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\mathbf{X}\)</span> denote an <span class="math inline">\(n\times p\)</span> matrix whose <span class="math inline">\((i,j)\)</span>th element is <span class="math inline">\(x_{ij}\)</span>.</p></li>
</ul>
<p><span class="math display">\[
\begin{pmatrix}
x_{11}&amp;x_{12}&amp;\cdots&amp;x_{1p}\\
x_{21}&amp;x_{22}&amp;\cdots&amp;x_{2p}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
x_{n1}&amp;x_{n2}&amp;\cdots&amp;x_{np}\\
\end{pmatrix}
\]</span></p>
<ul>
<li>At times we will be interested in the rows of <span class="math inline">\(\mathbf{X}\)</span>, which we write as <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span>.
<ul>
<li>Here <span class="math inline">\(x_i\)</span> is a vector of length <span class="math inline">\(p\)</span>, containing the <span class="math inline">\(p\)</span> variable measurements for the <span class="math inline">\(i\)</span>th observation.</li>
</ul></li>
</ul>
<p><span class="math display">\[
x_i=\begin{pmatrix}
x_{i1}\\
x_{i2}\\
\vdots\\
x_{ip}\\
\end{pmatrix}
\]</span>
      Vectors are by default represented as columns.</p>
<ul>
<li>For columns of <span class="math inline">\(\mathbf{X}\)</span>, which we write as <span class="math inline">\(\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_p\)</span>.
<ul>
<li>Each is a vector of length <span class="math inline">\(n\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[
\mathbf{x}_j=\begin{pmatrix}
x_{1j}\\
x_{2j}\\
\vdots\\
x_{nj}\\
\end{pmatrix}
\]</span></p>
<ul>
<li>The matrix <span class="math inline">\(\mathbf{X}\)</span> can be written as</li>
</ul>
<p><span class="math display">\[
\mathbf{X}=(\mathbf{x}_1 \,\,\, \mathbf{x}_2 \,\,\, \cdots \,\,\, \mathbf{x}_p)
\]</span></p>
<p>      or</p>
<p><span class="math display">\[
\mathbf{X}=\begin{pmatrix}
x_{1}^T\\
x_{2}^T\\
\vdots\\
x_{n}^T\\
\end{pmatrix}
\]</span></p>
<ul>
<li>The <span class="math inline">\(^T\)</span> notation denotes the transpose of a matrix or vector.</li>
</ul>
<p><span class="math display">\[
\mathbf{X}^T=\begin{pmatrix}
x_{11}&amp;x_{21}&amp;\cdots&amp;x_{n1}\\
x_{12}&amp;x_{22}&amp;\cdots&amp;x_{n2}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
x_{1p}&amp;x_{2p}&amp;\cdots&amp;x_{np}\\
\end{pmatrix}
\]</span></p>
<p>      while</p>
<p><span class="math display">\[
x_i^T=(x_{i1} \,\,\, x_{i2} \,\,\, \cdots \,\,\, x_{ip})
\]</span></p>
<ul>
<li><p>We use <span class="math inline">\(y_i\)</span> to denote the <span class="math inline">\(i\)</span>th observation of the variable on which we which to make predictions.</p></li>
<li><p>The set of all <span class="math inline">\(n\)</span> observations in vector form as</p></li>
</ul>
<p><span class="math display">\[
\mathbf{y}=\begin{pmatrix}
y_{1}\\
y_{2}\\
\vdots\\
y_{n}\\
\end{pmatrix}
\]</span></p>
<ul>
<li><p>Then observed data consists of <span class="math inline">\(\{(x_1,y_1), (x_2,y_2), \ldots, (x_n,y_n)\}\)</span>, where each <span class="math inline">\(x_i\)</span> is a vector of length <span class="math inline">\(p\)</span>.</p></li>
<li><p>A vector of length <span class="math inline">\(n\)</span> will always be denoted in <span class="math inline">\(lower case bold\)</span>; e.g.</p></li>
</ul>
<p><span class="math display">\[
\mathbf{a}=\begin{pmatrix}
a_{1}\\
a_{2}\\
\vdots\\
a_{n}\\
\end{pmatrix}
\]</span></p>
<ul>
<li><p>Vectors that are not of length <span class="math inline">\(n\)</span> (such as feature vectors of length <span class="math inline">\(p\)</span>) will be denoted in *lower case normal font, e.g. a.</p></li>
<li><p>Matrices will be denoted using <em>bold capitals</em>, such as <span class="math inline">\(\mathbf{A}\)</span>.</p></li>
<li><p>Random variables will be denoted using <em>capital normal font</em>, e.g. <span class="math inline">\(A\)</span>, regardless of their dimensions.</p></li>
<li><p>Occasionally, to indicate the dimension of a particular object, for example a scalar, we will use the notation <span class="math inline">\(a \in \Re\)</span>.</p></li>
<li><p>To indicate that it is a vector of length <span class="math inline">\(k\)</span>, we will use <span class="math inline">\(a \in \Re^k\)</span> (or <span class="math inline">\(\mathbf{a} \in \Re^n\)</span> if it is of length <span class="math inline">\(n\)</span>)</p></li>
<li><p>We will indicate that an object is an <span class="math inline">\(r\times s\)</span> matrix using <span class="math inline">\(\mathbf{A}\in \Re^{r\times s}\)</span>.</p></li>
<li><p>For multiplying two matricex, suppose that <span class="math inline">\(\mathbf{A}\in \Re^{r\times d}\)</span> and <span class="math inline">\(\mathbf{B}\in \Re^{d\times s}\)</span></p>
<ul>
<li>Then the product of <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> is denoted <span class="math inline">\(\mathbf{AB}\)</span>.</li>
<li>The <span class="math inline">\((i,j)\)</span>th element of <span class="math inline">\(\mathbf{AB}\)</span> is computed by multiplying each element of the <span class="math inline">\(i\)</span>th row of <span class="math inline">\(\mathbf{A}\)</span> by the corresponding element of the <span class="math inline">\(j\)</span>th column of <span class="math inline">\(\mathbf{B}\)</span>.</li>
<li>That is, <span class="math inline">\((\mathbf{AB})_{ij}=\sum_{k=1}^d a_{ik}b_{kj}\)</span>.</li>
</ul></li>
<li><p>Example</p></li>
</ul>
<p><span class="math display">\[
\mathbf{A}=\begin{pmatrix}
1&amp;2\\
3&amp;4\\
\end{pmatrix}
\,\,\, and \,\,\, \mathbf{B}=\begin{pmatrix}
5&amp;6\\
7&amp;8\\
\end{pmatrix}
\]</span></p>
<p>      Then</p>
<p><span class="math display">\[
\mathbf{AB}=\begin{pmatrix}
1&amp;2\\
3&amp;4\\
\end{pmatrix}
\begin{pmatrix}
5&amp;6\\
7&amp;8\\
\end{pmatrix}=\begin{pmatrix}
1\times 5+2\times 7&amp;1\times 6 + 2\times 8\\
3\times 6 + 4\times 7&amp;3\times 6 + 4 \times 8\\
\end{pmatrix}=
\begin{pmatrix}
19&amp;22\\
43&amp;50\\
\end{pmatrix}
\]</span></p>
<ul>
<li>Note that this operation produces an <span class="math inline">\(r\times s\)</span> matrix.
<ul>
<li>It is only pssible to compute <span class="math inline">\(\mathbf{AB}\)</span> if the number of columns of <span class="math inline">\(\mathbf{A}\)</span> is the same as the number of rows of <span class="math inline">\(\mathbf{B}\)</span>.</li>
</ul></li>
</ul>
<p><br></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ILR.pdf", "ILR.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
