<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Linear Regression | Statistical Learning</title>
  <meta name="description" content="This is a Statistical Learning" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Linear Regression | Statistical Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a Statistical Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Linear Regression | Statistical Learning" />
  
  <meta name="twitter:description" content="This is a Statistical Learning" />
  

<meta name="author" content="Jin Hyun Nam" />


<meta name="date" content="2023-03-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter3.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>머리말</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#understanding-data"><i class="fa fa-check"></i><b>1.1</b> Understanding data</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="chapter1.html"><a href="chapter1.html#example-1-supervised-learning-continuous-output"><i class="fa fa-check"></i><b>1.1.1</b> Example 1 (Supervised learning: Continuous output)</a></li>
<li class="chapter" data-level="1.1.2" data-path="chapter1.html"><a href="chapter1.html#example-2-supervised-leraning-categorical-output"><i class="fa fa-check"></i><b>1.1.2</b> Example 2 (Supervised leraning: Categorical output)</a></li>
<li class="chapter" data-level="1.1.3" data-path="chapter1.html"><a href="chapter1.html#example-3-unsupervised-learning-clustering-observations"><i class="fa fa-check"></i><b>1.1.3</b> Example 3 (Unsupervised learning: Clustering observations)</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#brief-history-of-statistical-learning"><i class="fa fa-check"></i><b>1.2</b> Brief history of statistical learning</a></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#notation-and-simple-matrix-algebra"><i class="fa fa-check"></i><b>1.3</b> Notation and simple matrix algebra</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#what-is-statitical-learning"><i class="fa fa-check"></i><b>2.1</b> What is Statitical Learning</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="chapter2.html"><a href="chapter2.html#prediction"><i class="fa fa-check"></i><b>2.1.1</b> Prediction</a></li>
<li class="chapter" data-level="2.1.2" data-path="chapter2.html"><a href="chapter2.html#inference"><i class="fa fa-check"></i><b>2.1.2</b> Inference</a></li>
<li class="chapter" data-level="2.1.3" data-path="chapter2.html"><a href="chapter2.html#estimating-f"><i class="fa fa-check"></i><b>2.1.3</b> Estimating <span class="math inline">\(f\)</span></a></li>
<li class="chapter" data-level="2.1.4" data-path="chapter2.html"><a href="chapter2.html#prediction-accuaracy-and-model-interpretability"><i class="fa fa-check"></i><b>2.1.4</b> Prediction Accuaracy and Model Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#assessing-model-accuracy"><i class="fa fa-check"></i><b>2.2</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="chapter2.html"><a href="chapter2.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>2.2.1</b> Measuring the Quality of Fit</a></li>
<li class="chapter" data-level="2.2.2" data-path="chapter2.html"><a href="chapter2.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2.2</b> Bias-Variance trade-off</a></li>
<li class="chapter" data-level="2.2.3" data-path="chapter2.html"><a href="chapter2.html#classification-problems"><i class="fa fa-check"></i><b>2.2.3</b> Classification Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#basic-commands"><i class="fa fa-check"></i><b>3.1</b> Basic Commands</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#graphics"><i class="fa fa-check"></i><b>3.2</b> Graphics</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#indexing-data"><i class="fa fa-check"></i><b>3.3</b> Indexing Data</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#loading-data"><i class="fa fa-check"></i><b>3.4</b> Loading Data</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#additional-graphical-and-numerical-summaries"><i class="fa fa-check"></i><b>3.5</b> Additional Graphical and Numerical Summaries</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#simple-regression"><i class="fa fa-check"></i><b>4.1</b> Simple Regression</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#multiple-regression"><i class="fa fa-check"></i><b>4.2</b> Multiple Regression</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="chapter4.html"><a href="chapter4.html#importance-of-predictors-statistical-significance-of-coefficients"><i class="fa fa-check"></i><b>4.2.1</b> Importance of predictors: Statistical significance of coefficients</a></li>
<li class="chapter" data-level="4.2.2" data-path="chapter4.html"><a href="chapter4.html#selecting-important-variables"><i class="fa fa-check"></i><b>4.2.2</b> Selecting important variables</a></li>
<li class="chapter" data-level="4.2.3" data-path="chapter4.html"><a href="chapter4.html#model-fit"><i class="fa fa-check"></i><b>4.2.3</b> Model fit</a></li>
<li class="chapter" data-level="4.2.4" data-path="chapter4.html"><a href="chapter4.html#prediction-1"><i class="fa fa-check"></i><b>4.2.4</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#other-consideration"><i class="fa fa-check"></i><b>4.3</b> Other consideration</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="chapter4.html"><a href="chapter4.html#qualitative-predictors"><i class="fa fa-check"></i><b>4.3.1</b> Qualitative predictors</a></li>
<li class="chapter" data-level="" data-path="chapter4.html"><a href="chapter4.html#example-8"><i class="fa fa-check"></i>Example 8</a></li>
<li class="chapter" data-level="4.3.2" data-path="chapter4.html"><a href="chapter4.html#potential-problems"><i class="fa fa-check"></i><b>4.3.2</b> Potential problems</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="chapter4.html"><a href="chapter4.html#non-parametric-regressions"><i class="fa fa-check"></i><b>4.4</b> Non-parametric regressions</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter4" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Linear Regression<a href="chapter4.html#chapter4" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<ul>
<li><p>Linear regression is a simple approach to supervised learning.</p></li>
<li><p>It assumes that the dependence of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span> is linear.</p></li>
<li><p>True regression functions are never linear!</p></li>
</ul>
<p><img src="fig4/f1.png" /></p>
<ul>
<li><p>Although it may seem overly simplistic, linear regression is extremely useful both conceptually and practically.</p></li>
<li><p>Consider the advertising data</p></li>
</ul>
<p><img src="fig4/f2.png" /></p>
<ul>
<li>Questions we might ask:
<ul>
<li>Is there a relationship between advertising budget and sales?</li>
<li>How strong is the relationship between advertising budget and sales?</li>
<li>Which media contribute to sales?</li>
<li>how accurately can we predict future sales?</li>
<li>Is the relationship linear?</li>
<li>Is there synergy among the advertising media?</li>
</ul></li>
</ul>
<div id="simple-regression" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Simple Regression<a href="chapter4.html#simple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Simple (linear) regression is defined as</li>
</ul>
<p><span class="math display">\[
Y = \beta_0 + \beta_1X + \epsilon,\qquad         
\]</span></p>
<p>where <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are observed values, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, called parameters, are the <em>intercept</em> (constant) term and <em>slope</em> coefficient, respectively, and <span class="math inline">\(\epsilon\)</span> is an unobserved random error term.</p>
<ul>
<li><p>The parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown constants, and are estimated from training data.</p></li>
<li><p>Given some estimates <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, for the model coefficients, we predict future sales using</p></li>
</ul>
<p><span class="math display">\[
\hat{y}=\hat{\beta}_0+\hat{\beta}_1 x
\]</span></p>
<p>where <span class="math inline">\(\hat{y}\)</span> indicates a prediction of <span class="math inline">\(Y\)</span> on the basis of <span class="math inline">\(X=x\)</span>.</p>
<ul>
<li>The <em>hat</em> symbol denotes an estimated value.</li>
</ul>
<div id="regression-estimation" class="section level4 unnumbered hasAnchor">
<h4>Regression: Estimation<a href="chapter4.html#regression-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Let <span class="math inline">\(\hat{y}_i=\hat{\beta}_0+\hat{\beta}_1x_i\)</span> be the prediction for <span class="math inline">\(Y\)</span> based on the <span class="math inline">\(i\)</span>th value of <span class="math inline">\(X\)</span>.</p></li>
<li><p>Then <span class="math inline">\(e_i=y_i-\hat{y}_i\)</span> represents the <span class="math inline">\(i\)</span>th <em>residual</em>.</p></li>
<li><p>We define the <em>residual sum of squares</em> (RSS) as</p></li>
</ul>
<p><span class="math display">\[
RSS=e_1^2+e_2^2+\cdots+e_n^2
\]</span></p>
<p>or equivalently as</p>
<p><span class="math display">\[
RSS=(y_1-\hat{\beta}_0-\hat{\beta}_1x_1)^2+(y_2-\hat{\beta}_0-\hat{\beta}_1x_2)^2+\cdots +(y_n-\hat{\beta}_0-\hat{\beta}_1x_n)^2
\]</span></p>
<ul>
<li><p>The least squares approach chooses <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> to minimize the RSS.</p></li>
<li><p>The unknown coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are most often estimated from the training data (sample) with observations <span class="math inline">\((x_1,y_1), \ldots, (x_n,y_n)\)</span> by the ordinary least squares (OLS), i.e,</p></li>
</ul>
<p><span class="math display">\[
(\hat{\beta}_1,\hat{\beta}_1)=argmin_{\beta_0,\beta_1}\sum_{i=1}^n (y_i-(\beta_0+\beta_1x_i))^2
\]</span></p>
<ul>
<li>Here the solutions are</li>
</ul>
<p><span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n (x_i-\bar{x})^2}
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_0=\bar{y}-\hat{\beta}_1\bar{x}
\]</span></p>
<p>where <span class="math inline">\(\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i\)</span> and <span class="math inline">\(\bar{y}=\frac{1}{n}\sum_{i=1}^ny_i\)</span> are the sample means of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
</div>
<div id="remark-1" class="section level4 unnumbered hasAnchor">
<h4>Remark 1<a href="chapter4.html#remark-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A crucial assumption for in estimation for successful estimation is</p>
<p><span class="math display">\[
E(\epsilon|x)=0
\]</span></p>
<p>which implies that the explanatory variable <span class="math inline">\(x\)</span> and the error term <span class="math inline">\(\epsilon\)</span> are uncorrelated.</p>
</div>
<div id="example-1" class="section level4 unnumbered hasAnchor">
<h4>Example 1<a href="chapter4.html#example-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In the Advertising data, regressing Sales on TV budget gives</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="chapter4.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#library(ISLR2) # load ISRL</span></span>
<span id="cb1-2"><a href="chapter4.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#library(help = ISLR2)</span></span>
<span id="cb1-3"><a href="chapter4.html#cb1-3" aria-hidden="true" tabindex="-1"></a>adv <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file =</span> <span class="st">&quot;https://www.statlearning.com/s/Advertising.csv&quot;</span>)</span>
<span id="cb1-4"><a href="chapter4.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(adv)</span></code></pre></div>
<pre><code>##        X                TV             radio          newspaper     
##  Min.   :  1.00   Min.   :  0.70   Min.   : 0.000   Min.   :  0.30  
##  1st Qu.: 50.75   1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75  
##  Median :100.50   Median :149.75   Median :22.900   Median : 25.75  
##  Mean   :100.50   Mean   :147.04   Mean   :23.264   Mean   : 30.55  
##  3rd Qu.:150.25   3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10  
##  Max.   :200.00   Max.   :296.40   Max.   :49.600   Max.   :114.00  
##      sales      
##  Min.   : 1.60  
##  1st Qu.:10.38  
##  Median :12.90  
##  Mean   :14.02  
##  3rd Qu.:17.40  
##  Max.   :27.00</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="chapter4.html#cb3-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV, <span class="at">data =</span> adv) <span class="co"># OLS regression: sales on TV</span></span>
<span id="cb3-2"><a href="chapter4.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit) <span class="co"># summarize regression results</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sales ~ TV, data = adv)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.3860 -1.9545 -0.1913  2.0671  7.2124 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
## TV          0.047537   0.002691   17.67   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.259 on 198 degrees of freedom
## Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 
## F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="chapter4.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> adv<span class="sc">$</span>TV, <span class="at">y =</span> adv<span class="sc">$</span>sales, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">xlab =</span> <span class="st">&quot;TV budget (1,000USD)&quot;</span>,</span>
<span id="cb5-2"><a href="chapter4.html#cb5-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Sales (1,000 units)&quot;</span>, <span class="at">col =</span> <span class="st">&quot;steel blue&quot;</span>) <span class="co"># scatter plot</span></span>
<span id="cb5-3"><a href="chapter4.html#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(fit, <span class="at">col =</span> <span class="st">&quot;dark gray&quot;</span>, <span class="at">lwd =</span> <span class="dv">3</span>) <span class="co"># fitted OLS regression line</span></span>
<span id="cb5-4"><a href="chapter4.html#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="do">## deviations from the observed values</span></span>
<span id="cb5-5"><a href="chapter4.html#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> adv<span class="sc">$</span>TV, <span class="at">y0 =</span> <span class="fu">predict</span>(fit), <span class="at">x1 =</span> adv<span class="sc">$</span>TV, <span class="at">y1 =</span> adv<span class="sc">$</span>sales, <span class="at">col =</span> <span class="st">&quot;light gray&quot;</span>)</span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<ul>
<li><p>The least squares fit for the regression of sales onto TV.</p></li>
<li><p>In this case a linear fit captures the essence of the relationship, although it is somewhat deficient in the left of the plot.</p></li>
<li><p>The deviations from the regression line, <span class="math inline">\(e_i = y_i − \hat{y}_i\)</span> are called <em>residuals</em>, which are estimates of the unobserved errors (<span class="math inline">\(\epsilon_i\)</span>).</p></li>
<li><p>Note, <span class="math inline">\(y_i = \hat{y}_i + \epsilon_i = \hat{\beta}_0+\hat{\beta}_0 x+\epsilon_i\)</span>.</p></li>
<li><p>The estimators are random variables in the sense that is another sample is selected they assume different values.</p></li>
<li><p>The distribution of an estimator is called the sampling distribution, which is the distribution of the estimate values if one sampled <span class="math inline">\(n\)</span> observations over and over again from the population and computed the estimates.</p></li>
</ul>
</div>
<div id="example-2" class="section level4 unnumbered hasAnchor">
<h4>Example 2<a href="chapter4.html#example-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Below in the left panel are the scatter plot, the population regression line, and the OLS estimated line from a sample of <span class="math inline">\(n=100\)</span> observations, in the middle panel are OLS estimated lines from 10 samples of size <span class="math inline">\(n=100\)</span>, and in the right panel is a histogram of the slope coefficient estimates <span class="math inline">\(\hat{\beta}_1\)</span> from 1,000 different samples of size <span class="math inline">\(n=100\)</span>.</p></li>
<li><p>The population model is</p></li>
</ul>
<p><span class="math display">\[
y=2+3x+\epsilon
\]</span></p>
<p>i.e., <span class="math inline">\(\beta_0=2\)</span> and <span class="math inline">\(\beta_1=3\)</span>.</p>
<ul>
<li>For this simulated esample <span class="math inline">\(x\)</span> and <span class="math inline">\(\epsilon\)</span> are generated from <span class="math inline">\(N(0,1)\)</span> and <span class="math inline">\(N(0,4)\)</span> distribution, respectively.</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="chapter4.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>) <span class="co"># intialize seed for exact replication</span></span>
<span id="cb6-2"><a href="chapter4.html#cb6-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>) <span class="co"># explanatory variable values</span></span>
<span id="cb6-3"><a href="chapter4.html#cb6-3" aria-hidden="true" tabindex="-1"></a>eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">4</span>) <span class="co"># error term</span></span>
<span id="cb6-4"><a href="chapter4.html#cb6-4" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">=</span> <span class="dv">2</span>; beta1 <span class="ot">=</span> <span class="dv">3</span> <span class="co"># population regression coefficients</span></span>
<span id="cb6-5"><a href="chapter4.html#cb6-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> beta1 <span class="sc">*</span> x <span class="sc">+</span> eps <span class="co"># realized values from the smaple of 100 observations</span></span>
<span id="cb6-6"><a href="chapter4.html#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">cbind</span>(x, y)) <span class="co"># first few observations</span></span></code></pre></div>
<pre><code>##               x         y
## [1,]  1.7049032  1.900747
## [2,] -0.7120386 -3.810928
## [3,] -0.2779849  5.699243
## [4,] -0.1196490  4.912434
## [5,] -0.1239606 -3.068909
## [6,]  0.2681838  2.450691</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="chapter4.html#cb8-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x) <span class="co"># OLS results</span></span>
<span id="cb8-2"><a href="chapter4.html#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit) <span class="co"># results</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.0051  -2.0868  -0.1227   2.4214   8.3195 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.9905     0.3663   5.434 4.03e-07 ***
## x             3.3588     0.3852   8.720 7.22e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.663 on 98 degrees of freedom
## Multiple R-squared:  0.4369, Adjusted R-squared:  0.4311 
## F-statistic: 76.03 on 1 and 98 DF,  p-value: 7.219e-14</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="chapter4.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>)) <span class="co"># graph window into 3 segents</span></span>
<span id="cb10-2"><a href="chapter4.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">col =</span> <span class="st">&quot;steel blue&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;y&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Initial Sample&quot;</span>,</span>
<span id="cb10-3"><a href="chapter4.html#cb10-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">font.main =</span> <span class="dv">1</span>) <span class="co"># scatter plot of the initial sample</span></span>
<span id="cb10-4"><a href="chapter4.html#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">0</span>] <span class="sc">==</span> <span class="fl">1.99</span>, <span class="fu">hat</span>(beta)[<span class="dv">1</span>] <span class="sc">==</span> <span class="fl">3.36</span>), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb10-5"><a href="chapter4.html#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="chapter4.html#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">2</span>, <span class="at">b =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>) <span class="co"># population regression line</span></span>
<span id="cb10-7"><a href="chapter4.html#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(fit, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="co"># OLS estimated regression line</span></span>
<span id="cb10-8"><a href="chapter4.html#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Lines from 10 Samples&quot;</span>, <span class="at">font.main =</span> <span class="dv">1</span>) <span class="co"># empty plot for simulated regression lines</span></span>
<span id="cb10-9"><a href="chapter4.html#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="chapter4.html#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {<span class="co"># impose ten other sample lines</span></span>
<span id="cb10-11"><a href="chapter4.html#cb10-11" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb10-12"><a href="chapter4.html#cb10-12" aria-hidden="true" tabindex="-1"></a>    eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">4</span>)</span>
<span id="cb10-13"><a href="chapter4.html#cb10-13" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> beta1 <span class="sc">*</span> x <span class="sc">+</span> eps</span>
<span id="cb10-14"><a href="chapter4.html#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">col =</span> <span class="st">&quot;light blue&quot;</span>)</span>
<span id="cb10-15"><a href="chapter4.html#cb10-15" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb10-16"><a href="chapter4.html#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="chapter4.html#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">2</span>, <span class="at">b =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>) <span class="co"># add also the population line</span></span>
<span id="cb10-18"><a href="chapter4.html#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(fit, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="co"># add also the initial OLS estimated regression line</span></span>
<span id="cb10-19"><a href="chapter4.html#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Population&quot;</span>, <span class="st">&quot;Initial sample&quot;</span>, <span class="st">&quot;10 simulations&quot;</span>),</span>
<span id="cb10-20"><a href="chapter4.html#cb10-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;light blue&quot;</span>), <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb10-21"><a href="chapter4.html#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="chapter4.html#cb10-22" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb10-23"><a href="chapter4.html#cb10-23" aria-hidden="true" tabindex="-1"></a>hat_beta1 <span class="ot">&lt;-</span> <span class="fu">double</span>(nsim)</span>
<span id="cb10-24"><a href="chapter4.html#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim) {<span class="do">## nsim samples</span></span>
<span id="cb10-25"><a href="chapter4.html#cb10-25" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb10-26"><a href="chapter4.html#cb10-26" aria-hidden="true" tabindex="-1"></a>    eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">4</span>)</span>
<span id="cb10-27"><a href="chapter4.html#cb10-27" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> beta1 <span class="sc">*</span> x <span class="sc">+</span> eps</span>
<span id="cb10-28"><a href="chapter4.html#cb10-28" aria-hidden="true" tabindex="-1"></a>    hat_beta1[i] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x))[<span class="dv">2</span>] <span class="co"># the slope coefficient</span></span>
<span id="cb10-29"><a href="chapter4.html#cb10-29" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb10-30"><a href="chapter4.html#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="chapter4.html#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(hat_beta1,</span>
<span id="cb10-32"><a href="chapter4.html#cb10-32" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">1</span>]), <span class="co"># expression allows for dispaying symbols and math equations</span></span>
<span id="cb10-33"><a href="chapter4.html#cb10-33" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&quot;light blue&quot;</span>, <span class="at">prob =</span> <span class="cn">TRUE</span>,</span>
<span id="cb10-34"><a href="chapter4.html#cb10-34" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">expression</span>(<span class="st">&quot;Histogram of 1,000 &quot;</span> <span class="sc">~</span> beta[<span class="dv">1</span>] <span class="sc">~</span><span class="st">&quot; Estimates&quot;</span>)) <span class="co"># histogram with relative freq</span></span>
<span id="cb10-35"><a href="chapter4.html#cb10-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-36"><a href="chapter4.html#cb10-36" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="at">expr =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="fu">mean</span>(hat_beta1), <span class="at">sd =</span> <span class="fu">sd</span>(hat_beta1)),</span>
<span id="cb10-37"><a href="chapter4.html#cb10-37" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">add =</span> <span class="cn">TRUE</span>) <span class="co"># impose normal curve</span></span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="chapter4.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.0051  -2.0868  -0.1227   2.4214   8.3195 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.9905     0.3663   5.434 4.03e-07 ***
## x             3.3588     0.3852   8.720 7.22e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.663 on 98 degrees of freedom
## Multiple R-squared:  0.4369, Adjusted R-squared:  0.4311 
## F-statistic: 76.03 on 1 and 98 DF,  p-value: 7.219e-14</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="chapter4.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(hat_beta1) <span class="co"># standard error of beta1 estimate from the repeated samples</span></span></code></pre></div>
<pre><code>## [1] 0.4141057</code></pre>
</div>
<div id="regression-accuracy-of-coefficients" class="section level4 unnumbered hasAnchor">
<h4>Regression: Accuracy of coefficients<a href="chapter4.html#regression-accuracy-of-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>As stated generally in equation, the true relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is <span class="math inline">\(Y=f(X)+\epsilon\)</span>.</p></li>
<li><p>Here, <span class="math inline">\(f(X)=\beta_0+\beta_1X\)</span>, resulting to the population regression <span class="math inline">\(Y=\beta_0+\beta_1X+\epsilon\)</span>.</p></li>
<li><p>As demonstrated by Example 2 estimates <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> deviate more or less from the underlying population parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>However, it can be shown that on average the estimates equal the underlying parameter value, mathematically <span class="math inline">\(E(\hat{\beta}_j)=\beta_j\)</span>, <span class="math inline">\(j=0,1\)</span>.</p></li>
<li><p>In such a case we say that the estimates are unbiased</p></li>
<li><p>So, in summary, it can be shown that OLS estimators are unbiased, i.e., they do not systematically over or under estimate the underlying parameters.</p></li>
<li><p>The accuracy of the estimates can be evaluated in terms of
<em>standard errors</em> of the estimates.</p></li>
</ul>
<p><span class="math display">\[
\hat{se}(\hat{\beta}_1)=\frac{\hat{\sigma}}{\sqrt{\Sigma_{i=1}^{n}(x_i - \bar{x})^2}}
\]</span></p>
<p><span class="math display">\[
\hat{se}(\hat{\beta}_0)=\hat{\sigma}\bigg(\frac{1}{n} +\frac{\bar{x}}{\Sigma_{i=1}^{n}(x_i - \bar{x})^2}\bigg)^{1/2}
\]</span></p>
<p>where <span class="math inline">\(\sigma^2=Var(\epsilon)\)</span></p>
<ul>
<li>These are routinely produced by every regression package.</li>
</ul>
<p>In the above example, the initial sample produces:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="chapter4.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.0051  -2.0868  -0.1227   2.4214   8.3195 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.9905     0.3663   5.434 4.03e-07 ***
## x             3.3588     0.3852   8.720 7.22e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.663 on 98 degrees of freedom
## Multiple R-squared:  0.4369, Adjusted R-squared:  0.4311 
## F-statistic: 76.03 on 1 and 98 DF,  p-value: 7.219e-14</code></pre>
<ul>
<li><p>Thus <span class="math inline">\(\hat{se}(\hat{\beta}_1)=0.3852\)</span>, which estimates the standard error if we repeated the sampling over and over again, computed <span class="math inline">\(\hat{\beta}_1\)</span> from each sample and calculated the standard deviation of them.</p></li>
<li><p>We did this 1,000 times for the right panel histogram in Example 2.</p></li>
<li><p>The standard deviation of these estimates is 0.4141 which is close to that of <span class="math inline">\(\hat{se}(\hat{\beta}_1)=0.3852\)</span> (the difference is about .029, or 7%)</p></li>
</ul>
</div>
<div id="confidence-intervals" class="section level4 unnumbered hasAnchor">
<h4>Confidence intervals<a href="chapter4.html#confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>The standard errors can be used to compute <em>confidence intervals</em> (CIs) for the coefficients.</p></li>
<li><p>A 95% confidence interval is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameter.</p></li>
<li><p>CIs are of the form</p></li>
</ul>
<p><span class="math display">\[
\hat{\beta}\pm c_{\alpha/2}·\hat{se}\big(\hat{\beta}\big)
\]</span></p>
<p>or</p>
<p><span class="math display">\[
\hat{\beta}- c_{\alpha/2}·\hat{se}\big(\hat{\beta}\big), \hat{\beta}+ c_{\alpha/2}·\hat{se}\big(\hat{\beta}\big)
\]</span></p>
<p>where <span class="math inline">\(c_{\alpha/2}\)</span> is the <span class="math inline">\(1-\alpha/2\)</span> percentile of the <span class="math inline">\(t\)</span>-distribution (or normal distribution).</p>
<ul>
<li><p><span class="math inline">\(\alpha\)</span> is the significance level with typical values .05 or .01 in which cases the confidence levels are 95% and 99%, respectively.</p></li>
<li><p>For example, for the 95% confidence limit <span class="math inline">\(c_{0.025}\approx 2\)</span>.</p></li>
<li><p>In Example 2 the 95% confidence interval for <span class="math inline">\(\beta_1\)</span> is</p></li>
</ul>
<p><span class="math display">\[
\hat{\beta}_1 \pm 2 × \hat{se}(\hat{\beta}_1)= 3.36 ± 2 \times 0.385 = 3.36 \pm 0.770, \,\,\, or \,\,\, [2.59, 4.13].
\]</span></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="chapter4.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(fit)</span></code></pre></div>
<pre><code>##                2.5 %   97.5 %
## (Intercept) 1.263579 2.717503
## x           2.594394 4.123197</code></pre>
<ul>
<li><p>We observe that in this case the population <span class="math inline">\(\beta_1 = 3\)</span> belongs to the
interval.</p></li>
<li><p>For a 95% confidence interval there is 5% change to have such a sample that the estimate is so much off that the confidence
interval does not cover the population parameter.</p></li>
</ul>
</div>
<div id="hypothesis-testing" class="section level4 unnumbered hasAnchor">
<h4>Hypothesis testing<a href="chapter4.html#hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Standard errors can also used in <em>hypothesis testing</em>.</p></li>
<li><p>The most common hypothesis testing involves testing the <em>null hypothesis</em> of</p></li>
</ul>
<p><span class="math display">\[H_0 : There \ is \ no \ relationship \ between \ X \ and \ Y \]</span></p>
<p>versus the <em>alternative hypothesis</em></p>
<p><span class="math display">\[H_1 : There \ is \ some \ relationship \ between \ x \ and \ y \]</span></p>
<ul>
<li>More formally, in terms of the regression model this corresponds to testing</li>
</ul>
<p><span class="math display">\[H_0 : \beta_1 =  0\]</span>
versus
<span class="math display">\[ H_1 : \beta_1 \ne 0\]</span></p>
<ul>
<li><p>If the null hypothesis holds then <span class="math inline">\(Y = \beta_0 + \epsilon\)</span>, so that <span class="math inline">\(X\)</span> is not associated to <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Testing for a more general null hypothesis of <span class="math inline">\(H_0 : \beta_1 = \beta_1^*\)</span>, where <span class="math inline">\(\beta_1^*\)</span> is some given value, the test statistic is</p></li>
</ul>
<p><span class="math display">\[
t= \frac{\hat{\beta}_1-\beta_1^*}{\hat{se}\big(\hat{\beta}_1\big)}
\]</span></p>
<p>which for testing hypothesis with <span class="math inline">\(\beta_1^*=0\)</span> reduces to</p>
<p><span class="math display">\[t= \frac{\beta_1}{\hat{se}\big(\hat{\beta}_1\big)}\]</span></p>
<ul>
<li><p>The null distribution (i.e., when the null hypothesis <span class="math inline">\(H_0\)</span> is true) of <em>t</em> is the Student <em>t</em> distribution with <span class="math inline">\(n − 2\)</span> degrees of freedom.</p></li>
<li><p>With <span class="math inline">\(n &gt; 30\)</span> the <em>t</em>-distribution is close to the normal distribution.</p></li>
<li><p>For large absolute value of <em>t</em> the null hypothesis is rejected.</p></li>
<li><p>By a ’large’ value we mean that if the probability of obtaining such a large value is smaller then some specified threshold value <span class="math inline">\(\alpha\)</span> , we reject the null hypothesis.</p></li>
<li><p>Typical values of <span class="math inline">\(\alpha\)</span> are 0.05 or 0.05 , i.e., 5% or 1%.</p></li>
<li><p>The computer produces <span class="math inline">\(p-value\)</span> that indicate the probability <span class="math inline">\(P(|t| &gt; |t_{obs}| |H_0)\)</span> , i.e., the probability for getting as large (or larger) values than the one observed, <span class="math inline">\(t_{obs}\)</span> , if the null hypothesis is
holds.</p></li>
<li><p>If the probability is too low, we infer that rather than having so
extreme sample, the underlying parameter value is something else
than that of the null hypothesis, and therefore reject the <span class="math inline">\(H_0\)</span> .</p></li>
<li><p>Typical threshold values are 0.05 ( <em>statistically significant</em> at the 5% level) and 0.01 ( <em>statistically significant</em> at the 1% level), i.e., if the <span class="math inline">\(p\)</span>-value goes below these values, we reject the null hypothesis at the associated level of significance.</p></li>
</ul>
</div>
<div id="example-3" class="section level4 unnumbered hasAnchor">
<h4>Example 3<a href="chapter4.html#example-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>In the advertising example in p-value &lt; .0001 (in fact the first 15 decimals are zeros), so the data suggest strongly to reject the null hypothesis that TV advertising does not affect Sales (the sign of the coefficient show that the association is positive, as could be expected).</p></li>
<li><p>The quality of a linear regression fit is typically assessed by the <em>residual standard error</em> (RSE) and <em>coefficient of determination</em> <span class="math inline">\(R^2\)</span> (R-square) of which the R-square more popular.</p></li>
</ul>
<p><span class="math display">\[RSE =\sqrt{\frac{1}{n-2}RSS} = \sqrt{\frac{1}{n-2} \sum_{i=1}^n (y_i -\hat{y}_i)^2 }\]</span></p>
<p>and</p>
<p><span class="math display">\[
R^2 = \frac{TSS-RSS} {TSS} = 1-\frac{RSS}{TSS}
\]</span></p>
<p>where <span class="math inline">\(TSS = \Sigma_{i=1}^n(y_i - \bar{y})^2\)</span> is the <em>total sum of squares</em> and
<span class="math inline">\(RSS = \Sigma_{i=1}^n(y_i - \hat{y}_i)^2\)</span> is the <em>residual sum-of-squares</em>.</p>
<ul>
<li>We observe that <span class="math inline">\(RSE = \sqrt{RSS/(n-2)}\)</span></li>
</ul>
<p>It can be shown that in this simple linear regression setting that <span class="math inline">\(R^2=r^2\)</span>, where <span class="math inline">\(r\)</span> is the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:</p>
<p><span class="math display">\[
r=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}}
\]</span></p>
<ul>
<li><p>R-square is a <em>goodness-of-fit</em> measure with <span class="math inline">\(0 \le R^2\le 1\)</span> ( <span class="math inline">\(R^2 = 0\)</span> , no association, <span class="math inline">\(R^2 = 1\)</span> perfect fit), while RSE measures <em>lack of fit</em>.</p>
<ul>
<li><p>Both of these are routinely produced by regression packages.</p></li>
<li><p>In the advertising example (rounded to two decimals) <span class="math inline">\(RSE = 3.26\)</span> and <span class="math inline">\(R^2 = 0.61\)</span>.</p></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="chapter4.html#cb19-1" aria-hidden="true" tabindex="-1"></a>adv <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file =</span> <span class="st">&quot;https://www.statlearning.com/s/Advertising.csv&quot;</span>)</span>
<span id="cb19-2"><a href="chapter4.html#cb19-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV, <span class="at">data =</span> adv) <span class="co"># OLS regression: sales on TV</span></span>
<span id="cb19-3"><a href="chapter4.html#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sales ~ TV, data = adv)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.3860 -1.9545 -0.1913  2.0671  7.2124 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
## TV          0.047537   0.002691   17.67   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.259 on 198 degrees of freedom
## Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 
## F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li><p>RSE is in the same units as the dependent variable <span class="math inline">\(y\)</span>.</p></li>
<li><p>James et al. interpret RSE as the amount the prediction is on average off from the true value of the dependent variable.</p></li>
<li><p>Accordingly, <span class="math inline">\(RES = 3.26\)</span> would indicate that any sales on the basis
of TV would be off on average 3.26 thousand units.</p></li>
<li><p>Thus, as the average sales over all markets is approximately 14 thousand units, the error is 3.26 / 14 = 23%.</p></li>
</ul>
<p><br>
<!-- --- --></p>
</div>
</div>
<div id="multiple-regression" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Multiple Regression<a href="chapter4.html#multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Adding explanatory variables ( <span class="math inline">\(X\)</span>-variables) to the model gives <em>multiple regression</em></li>
</ul>
<p><span class="math display">\[Y = β_0 + β_1X_1 + · · · + β_pX_p + ϵ\]</span></p>
<p>where <span class="math inline">\(X_j\)</span> is the <span class="math inline">\(j\)</span> th predictor (explanatory variable) and <span class="math inline">\(β_j\)</span> quantifies the marginal effect or association between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_j\)</span> .</p>
<ul>
<li><p>That is, <span class="math inline">\(β_j\)</span> indicates the unit change in <span class="math inline">\(x_j\)</span> holding all other predictors fixed.</p></li>
<li><p>We interpret <span class="math inline">\(\beta_j\)</span> as the <em>average</em> effect on <span class="math inline">\(Y\)</span> of a one unit increase in <span class="math inline">\(X_j\)</span>, <em>holding all other predictors fixed</em>.</p></li>
<li><p>The coefficients are again estimated by finding <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1, . . . , \hat{\beta}_p\)</span> that minimize the sum of squares <span class="math inline">\(\Sigma_{i=1}^n (y_i - \hat{y}_i)^2\)</span>, where <span class="math inline">\(\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1x_{i1} +. . . +\hat{\beta}_px_{ip}\)</span>.</p></li>
</ul>
<div id="interpreting-regression-coefficients" class="section level4 unnumbered hasAnchor">
<h4>Interpreting regression coefficients<a href="chapter4.html#interpreting-regression-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>The ideal scenario is when the predictors are uncorrelated - a <em>balanced design</em>:</p>
<ul>
<li>Each coefficient can be estimate and tested separately.</li>
<li>Interpretations such as “<em>a unit change in <span class="math inline">\(X_j\)</span> is associated with a <span class="math inline">\(\beta_j\)</span> change in <span class="math inline">\(Y\)</span>, while all the other variables stay fixed</em>”, are possible.</li>
</ul></li>
<li><p>Correlations among predictors cause problems:</p>
<ul>
<li>The variance of all coefficients tends to increase, sometimes dramatically</li>
<li>Interpretations become hazardous - when <span class="math inline">\(X_j\)</span> changes, everything else changes.</li>
</ul></li>
<li><p><em>Claims of causality</em> should be avoided for observational data.</p></li>
<li><p>“Data Analysis and Regression” Mosteller and Tukey 1977</p>
<ul>
<li>A regression coefficient <span class="math inline">\(\beta_j\)</span> estimates the expected change in <span class="math inline">\(Y\)</span> per unit change in <span class="math inline">\(X_j\)</span>, <em>with all other predictors held fixed</em>. But predictors usually change together!</li>
<li>Example: <span class="math inline">\(Y\)</span> total amount of change in your pocket; <span class="math inline">\(X_1\)</span>= # of coins; <span class="math inline">\(X_2\)</span>= # of pennies, nickels and dimes. By itself, regression coefficient of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X_2\)</span> will be <span class="math inline">\(&gt;0\)</span>. But how about with <span class="math inline">\(X_1\)</span> in model?</li>
<li><span class="math inline">\(Y\)</span>= number of tackles by a football player in a season; <span class="math inline">\(W\)</span> and <span class="math inline">\(H\)</span> are his weight and height. Fitted regression model is <span class="math inline">\(\hat{Y}=b_0+0.50W-0.10H\)</span>. How do we interpret <span class="math inline">\(\hat{\beta}_2&lt;0\)</span>?</li>
</ul></li>
</ul>
<blockquote>
<blockquote>
<p>“Essentially, all models are wrong, but some are useful” - George Box</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>“The only way to find out what will happen when a complex system is disturbed is to disturb the system, not merely to observe it passively” - Fred Mosteller and John Tukey, paraphrasing George Box</p>
</blockquote>
</blockquote>
</div>
<div id="estimation-and-prediction-for-multiple-regression" class="section level4 unnumbered hasAnchor">
<h4>Estimation and Prediction for Multiple Regression<a href="chapter4.html#estimation-and-prediction-for-multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Given estimates <span class="math inline">\(\hat{\beta}_0,\hat{\beta}_1, \ldots, \hat{\beta}_p\)</span>, we can make predictions using the formula</li>
</ul>
<p><span class="math display">\[
\hat{y}=\hat{\beta}_0+\hat{\beta}_1x_1+ \cdots + \hat{\beta}_px_p
\]</span></p>
<ul>
<li>We estimate <span class="math inline">\(\beta_0,\beta_1,\ldots, \beta_p\)</span> as the values that minimize the sum of squared residuals</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
RSS &amp;= \sum_{i=1}^n (y_i-\hat{y}_i)^2 \\
&amp;= \sum_{i=1}^n (y_i-\hat{\beta}_0 - \hat{\beta}_1x_{i1}-\hat{\beta}_2x_{i2}-\cdots -\hat{\beta}_px_{ip})^2
\end{aligned}
\]</span></p>
<ul>
<li>This is done using standard statistical software. The values <span class="math inline">\(\hat{\beta}_0,\hat{\beta}_1, \ldots, \hat{\beta}_p\)</span> that minimize <span class="math inline">\(RSS\)</span> are the multiple least squares regression coefficient estimates.</li>
</ul>
<p><img src="fig4/f3.png" style="width:80.0%" /></p>
<ul>
<li>Results for advertising data</li>
</ul>
<p><img src="fig4/f4.png" style="width:80.0%" /></p>
</div>
<div id="example-4" class="section level4 unnumbered hasAnchor">
<h4>Example 4<a href="chapter4.html#example-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>In the advertising example let us enhance the model as</li>
</ul>
<p><span class="math display">\[sales = \beta_0 + \beta_1TV + \beta_2radio + \beta_3newspaper + \epsilon \]</span></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="chapter4.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#library(car) # load car package</span></span>
<span id="cb21-2"><a href="chapter4.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">#adv &lt;- read.csv(file = &quot;https://www.statlearning.com/s/Advertising.csv&quot;)</span></span>
<span id="cb21-3"><a href="chapter4.html#cb21-3" aria-hidden="true" tabindex="-1"></a>adv <span class="ot">&lt;-</span> <span class="fu">url</span>(<span class="st">&quot;https://elflini.github.io/study/statlearn/Advertising.rda&quot;</span>)</span>
<span id="cb21-4"><a href="chapter4.html#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="at">file=</span>adv)</span>
<span id="cb21-5"><a href="chapter4.html#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(adv)</span></code></pre></div>
<pre><code>##        X                TV             radio          newspaper     
##  Min.   :  1.00   Min.   :  0.70   Min.   : 0.000   Min.   :  0.30  
##  1st Qu.: 50.75   1st Qu.: 74.38   1st Qu.: 9.975   1st Qu.: 12.75  
##  Median :100.50   Median :149.75   Median :22.900   Median : 25.75  
##  Mean   :100.50   Mean   :147.04   Mean   :23.264   Mean   : 30.55  
##  3rd Qu.:150.25   3rd Qu.:218.82   3rd Qu.:36.525   3rd Qu.: 45.10  
##  Max.   :200.00   Max.   :296.40   Max.   :49.600   Max.   :114.00  
##      sales      
##  Min.   : 1.60  
##  1st Qu.:10.38  
##  Median :12.90  
##  Mean   :14.02  
##  3rd Qu.:17.40  
##  Max.   :27.00</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="chapter4.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(adv) <span class="co"># a few first lines of the Advertising data loaded into object adv</span></span></code></pre></div>
<pre><code>##   X    TV radio newspaper sales
## 1 1 230.1  37.8      69.2  22.1
## 2 2  44.5  39.3      45.1  10.4
## 3 3  17.2  45.9      69.3   9.3
## 4 4 151.5  41.3      58.5  18.5
## 5 5 180.8  10.8      58.4  12.9
## 6 6   8.7  48.9      75.0   7.2</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="chapter4.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(adv) <span class="co"># a few last lines</span></span></code></pre></div>
<pre><code>##       X    TV radio newspaper sales
## 195 195 149.7  35.6       6.0  17.3
## 196 196  38.2   3.7      13.8   7.6
## 197 197  94.2   4.9       8.1   9.7
## 198 198 177.0   9.3       6.4  12.8
## 199 199 283.6  42.0      66.2  25.5
## 200 200 232.1   8.6       8.7  13.4</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="chapter4.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(<span class="fu">subset</span>(adv,<span class="at">select=</span><span class="sc">-</span>X))</span></code></pre></div>
<pre><code>##                   TV      radio  newspaper     sales
## TV        1.00000000 0.05480866 0.05664787 0.7822244
## radio     0.05480866 1.00000000 0.35410375 0.5762226
## newspaper 0.05664787 0.35410375 1.00000000 0.2282990
## sales     0.78222442 0.57622257 0.22829903 1.0000000</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="chapter4.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(<span class="fu">subset</span>(adv,<span class="at">select=</span><span class="sc">-</span>X),<span class="at">cex=</span><span class="fl">0.5</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="chapter4.html#cb30-1" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, <span class="at">data =</span> adv) <span class="co"># fit the regression, results saved in object fit</span></span>
<span id="cb30-2"><a href="chapter4.html#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1) <span class="co"># show results</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sales ~ TV + radio + newspaper, data = adv)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.8277 -0.8908  0.2418  1.1893  2.8292 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
## TV           0.045765   0.001395  32.809   &lt;2e-16 ***
## radio        0.188530   0.008611  21.893   &lt;2e-16 ***
## newspaper   -0.001037   0.005871  -0.177     0.86    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.686 on 196 degrees of freedom
## Multiple R-squared:  0.8972, Adjusted R-squared:  0.8956 
## F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li><p>The results indicate that newspapers do not contribute sales, while an additional thousand spent in TV advertising predicts an average increase in sales by about 46 units (holding radio budget unchanged).</p></li>
<li><p>Similarly an additional thousand in radio advertising predicts increase in sales by about 189 units (holding TV budget intact).</p></li>
<li><p>However, checking out the residuals reveals that the specification is not satisfactory.</p></li>
</ul>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="chapter4.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit1, <span class="at">which =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<ul>
<li><p>The graph indicates non-linearity.</p></li>
<li><p>After dropping the non-significant newspaper, we add squared terms of
the explanatory variables to account for the obvious non-linearity.</p></li>
</ul>
<p><span class="math display">\[sales = \beta_0 + \beta_1TV + \beta_2radio + \beta_{11}(TV)^2 + \beta_{22}(radio)^2 + \epsilon \]</span></p>
<p>(Note: <span class="math inline">\(β\)</span> s and <span class="math inline">\(\epsilon\)</span> are generic notations).</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="chapter4.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1b <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> <span class="fu">I</span>(TV<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(radio<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> adv)) <span class="co"># quadratic terms after removing newspaper</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sales ~ TV + radio + I(TV^2) + I(radio^2), data = adv)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.3987 -0.8509  0.0376  0.9781  3.3727 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.535e+00  4.093e-01   3.750 0.000233 ***
## TV           7.852e-02  4.978e-03  15.774  &lt; 2e-16 ***
## radio        1.588e-01  2.830e-02   5.613 6.78e-08 ***
## I(TV^2)     -1.138e-04  1.674e-05  -6.799 1.26e-10 ***
## I(radio^2)   7.135e-04  5.709e-04   1.250 0.212862    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.515 on 195 degrees of freedom
## Multiple R-squared:  0.9174, Adjusted R-squared:  0.9157 
## F-statistic: 541.2 on 4 and 195 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="chapter4.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="do">## note: expression of the form y ~ x + z is R formula, see help(I) to see the meaning of I() function</span></span>
<span id="cb35-2"><a href="chapter4.html#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="co"># split plot window in 4 quadrants</span></span>
<span id="cb35-3"><a href="chapter4.html#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit1b, <span class="at">which =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb35-4"><a href="chapter4.html#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> adv<span class="sc">$</span>TV, <span class="at">y =</span> <span class="fu">resid</span>(fit1b), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>), <span class="at">col =</span> <span class="st">&quot;steel blue&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;TV&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Residuals vs TV adrvertising&quot;</span>,</span>
<span id="cb35-5"><a href="chapter4.html#cb35-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex.main =</span> <span class="dv">1</span>, <span class="at">font.main =</span> <span class="dv">1</span>)</span>
<span id="cb35-6"><a href="chapter4.html#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(<span class="fu">resid</span>(fit1b) <span class="sc">~</span> adv<span class="sc">$</span>TV, <span class="at">f =</span> .<span class="dv">5</span>), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb35-7"><a href="chapter4.html#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> adv<span class="sc">$</span>radio, <span class="at">y =</span> <span class="fu">resid</span>(fit1b), <span class="at">col =</span> <span class="st">&quot;steel blue&quot;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>), <span class="at">xlab =</span> <span class="st">&quot;Radio&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Residuals vs Radio adrvertising&quot;</span>,</span>
<span id="cb35-8"><a href="chapter4.html#cb35-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex.main =</span> <span class="dv">1</span>, <span class="at">font.main =</span> <span class="dv">1</span>)</span>
<span id="cb35-9"><a href="chapter4.html#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(<span class="fu">resid</span>(fit1b) <span class="sc">~</span> adv<span class="sc">$</span>radio, <span class="at">f =</span> .<span class="dv">5</span>), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<ul>
<li><p>The residual plot (top left) indicate still non-linearity.</p></li>
<li><p>Let us yet enhance the model by adding the <em>interaction</em> term TV × radio of the explanatory variables and estimate regression</p></li>
</ul>
<p><span class="math display">\[sales = \beta_0 + \beta_1TV + \beta_2radio + \beta_{11}(TV)^2 + \beta_{22}(radio)^2 + \beta_{12}(TV \times radio) + ϵ \qquad (23)\]</span></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="chapter4.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1c <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> <span class="fu">I</span>(TV<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(radio<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> TV<span class="sc">:</span>radio,</span>
<span id="cb36-2"><a href="chapter4.html#cb36-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> adv)) <span class="co"># quadratic terms after dropping newspaper</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sales ~ TV + radio + I(TV^2) + I(radio^2) + TV:radio, 
##     data = adv)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.0027 -0.2859 -0.0062  0.3829  1.2100 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  5.194e+00  2.061e-01  25.202   &lt;2e-16 ***
## TV           5.099e-02  2.236e-03  22.801   &lt;2e-16 ***
## radio        2.654e-02  1.242e-02   2.136   0.0339 *  
## I(TV^2)     -1.098e-04  6.901e-06 -15.914   &lt;2e-16 ***
## I(radio^2)   1.861e-04  2.359e-04   0.789   0.4311    
## TV:radio     1.075e-03  3.479e-05  30.892   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6244 on 194 degrees of freedom
## Multiple R-squared:  0.986,  Adjusted R-squared:  0.9857 
## F-statistic:  2740 on 5 and 194 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="chapter4.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(<span class="fu">cbind</span>(<span class="at">radio=</span>adv<span class="sc">$</span>radio, <span class="at">TV=</span>adv<span class="sc">$</span>TV, <span class="at">radioTV=</span>adv<span class="sc">$</span>radio <span class="sc">*</span> adv<span class="sc">$</span>TV))</span></code></pre></div>
<pre><code>##              radio         TV   radioTV
## radio   1.00000000 0.05480866 0.6813916
## TV      0.05480866 1.00000000 0.6621602
## radioTV 0.68139157 0.66216021 1.0000000</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="chapter4.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb40-2"><a href="chapter4.html#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit1c, <span class="at">which =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb40-3"><a href="chapter4.html#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> adv<span class="sc">$</span>TV, <span class="at">y =</span> <span class="fu">resid</span>(fit1c), <span class="at">col =</span> <span class="st">&quot;steel blue&quot;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>), <span class="at">xlab =</span> <span class="st">&quot;TV&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Residuals vs TV adrvertising&quot;</span>,</span>
<span id="cb40-4"><a href="chapter4.html#cb40-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex.main =</span> <span class="dv">1</span>, <span class="at">font.main =</span> <span class="dv">1</span>)</span>
<span id="cb40-5"><a href="chapter4.html#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(<span class="fu">resid</span>(fit1c) <span class="sc">~</span> adv<span class="sc">$</span>TV, <span class="at">f =</span> .<span class="dv">5</span>), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb40-6"><a href="chapter4.html#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> adv<span class="sc">$</span>radio, <span class="at">y =</span> <span class="fu">resid</span>(fit1c), <span class="at">col =</span> <span class="st">&quot;steel blue&quot;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>), <span class="at">xlab =</span> <span class="st">&quot;Radio&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Residuals vs Radio adrvertising&quot;</span>,</span>
<span id="cb40-7"><a href="chapter4.html#cb40-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex.main =</span> <span class="dv">1</span>, <span class="at">font.main =</span> <span class="dv">1</span>)</span>
<span id="cb40-8"><a href="chapter4.html#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(<span class="fu">resid</span>(fit1c) <span class="sc">~</span> adv<span class="sc">$</span>radio, <span class="at">f =</span> .<span class="dv">5</span>), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<ul>
<li><p>Except of two potential outliers (obs 131 and 156), the residual plots are more satisfactory (recall error term should be purely random, thereby showing any systematic patterns in any context).</p></li>
<li><p>Some indication of third order effect of TV may be present.</p></li>
<li><p>The interpretation of coefficients is now a bit more tricky.</p></li>
<li><p>For example the TV coefficient 0.051 indicates TV effect at zero radio budget (an increase of $1,000 TV advertising can be expected to increases sales by 51 units if radio advertising is zero), while generally the marginal effect depends on the current levels of TV and radio advertising, being of the form</p></li>
</ul>
<p><span class="math display">\[
\hat{\beta}_1+\hat{\beta}_{11}TV^2 + \hat{\beta}_{12}radio
\]</span></p>
<ul>
<li>Finally, it may be surprising that newspaper advertising does not contribute sales in the model because alone it is significant in a simple regression.</li>
</ul>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="chapter4.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1d <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(sales) <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> <span class="fu">I</span>(TV<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(radio<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> TV<span class="sc">:</span>radio,</span>
<span id="cb41-2"><a href="chapter4.html#cb41-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> adv[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">131</span>, <span class="dv">156</span>), ])) <span class="co"># quadratic term</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(sales) ~ TV + radio + I(TV^2) + I(radio^2) + 
##     TV:radio, data = adv[-c(131, 156), ])
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.312665 -0.032455 -0.006775  0.045860  0.121585 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.685e+00  2.236e-02  75.321  &lt; 2e-16 ***
## TV           6.661e-03  2.440e-04  27.297  &lt; 2e-16 ***
## radio        1.071e-02  1.325e-03   8.083 6.91e-14 ***
## I(TV^2)     -1.462e-05  7.496e-07 -19.506  &lt; 2e-16 ***
## I(radio^2)  -7.432e-05  2.512e-05  -2.958  0.00348 ** 
## TV:radio     4.061e-05  3.752e-06  10.823  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.06645 on 192 degrees of freedom
## Multiple R-squared:  0.9695, Adjusted R-squared:  0.9687 
## F-statistic:  1219 on 5 and 192 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li><p>The reason is that radio and newspaper are correlated.</p></li>
<li><p>So, newspaper alone in a regression reflects the radio advertising (due to the correlation) even though newspaper advertising actually does not contribute sales!</p></li>
<li><p>A 3D plot to illustrate graphically the relationships.</p></li>
</ul>
<p><img src="fig4/fig4.jpg" /></p>
<p><strong>Some important questions</strong></p>
<ol style="list-style-type: decimal">
<li>Is at least one of the predictors <span class="math inline">\(x_1, x_2, . . . , x_p\)</span> useful in predicting the response?</li>
<li>Do all predictors help to explain <span class="math inline">\(y\)</span> , or is only a subset of the predictors useful?</li>
<li>How well does the model fit the data?</li>
<li>Given a set of predictor values, what response value should we predict, and how accurate is our prediction?</li>
</ol>
</div>
<div id="importance-of-predictors-statistical-significance-of-coefficients" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Importance of predictors: Statistical significance of coefficients<a href="chapter4.html#importance-of-predictors-statistical-significance-of-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The <span class="math inline">\(t\)</span>-statistics</li>
</ul>
<p><span class="math display">\[t = \frac{\hat{\beta}_j}{\hat{se}\big(\hat{\beta}_j\big)}\]</span></p>
<p>and associated <span class="math inline">\(p\)</span>-values indicate significance of individual coefficients separately.</p>
<ul>
<li>Testing <em>joint significance</em> of all (or a subset of) coefficients, i.e., null
hypothesis</li>
</ul>
<p><span class="math display">\[H_0~: \beta_1 = · · · = \beta_p = 0\]</span></p>
<p>versus</p>
<p><span class="math display">\[H_1: at \ least \ one  \ \beta_j \ne 0\]</span></p>
<p>can be performed by the <span class="math inline">\(F\)</span>-statistic</p>
<p><span class="math display">\[F = \frac{(TSS − RSS)/p}{RSS/(n − p − 1)} \sim F_{p,n-p-1}\]</span></p>
<p>which has the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(p\)</span> and <span class="math inline">\(n − p − 1\)</span> degrees of freedom if the null hypothesis <span class="math inline">\(H_0\)</span> is true.</p>
<div id="example-5" class="section level4 unnumbered hasAnchor">
<h4>Example 5<a href="chapter4.html#example-5" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>In Example 4, <span class="math inline">\(F = 260.9\)</span> with degrees of freedom 3 and 169 the <span class="math inline">\(p\)</span> -value zero in 15 decimal places, implying strong rejection of the null hypothesis that advertising in the three media does not affect sales (i.e., the null hypothesis <span class="math inline">\(H_0 : \beta_1 = \beta_2 = \beta_3 = 0\)</span> ).</p></li>
<li><p>The <span class="math inline">\(F\)</span>-test for testing hypothesis can be consider as the first step.</p></li>
<li><p>If the null hypothesis is not rejected, we conclude that no explanatory variable is associated to <span class="math inline">\(Y\)</span> and the model is of the form <span class="math inline">\(Y = \beta_0 + ϵ\)</span> , i.e., <span class="math inline">\(Y\)</span> purely varies around its mean.</p></li>
<li><p>If the null hypothesis is rejected then the interest is which variables are associated with <span class="math inline">\(Y\)</span> , i.e., which explanatory variables are important.</p></li>
<li><p>Above we tested the importance of all variables.</p></li>
<li><p>This can be generalized to test the importance of a particular
subset <span class="math inline">\(q\)</span> variables (assume that they are the <span class="math inline">\(q\)</span> last ones).</p></li>
<li><p>This corresponds to a null hypothesis</p></li>
</ul>
<p><span class="math display">\[H_0 : \beta_{p−q+1} = \beta_{p−q+2} = · · · = \beta_p = 0\]</span></p>
<ul>
<li><p>The alternative hypothesis is again that at least one of those coefficients is non-zero.</p></li>
<li><p>The test statistic is</p></li>
</ul>
<p><span class="math display">\[F = \frac{(RSS_0 − RSS)/q}{RSS/(n − p − 1)}\]</span></p>
<p>where <span class="math inline">\(RSS_0\)</span> is the residual sum of squares of the regression with <span class="math inline">\(q\)</span> explanatory variables, i.e. of the fit of regression</p>
<p><span class="math display">\[y = \beta_0 + \beta_1x_1 + · · · + \beta_qx_q + ϵ\]</span></p>
</div>
</div>
<div id="selecting-important-variables" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Selecting important variables<a href="chapter4.html#selecting-important-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>The most direct approach is called <em>all subsets</em> or <em>best subset</em> regression: we compute the least squares fit for all possible subsets and then choose between them based on some criterion that balances training error with model size.</p></li>
<li><p>However we often can’t examine all possible models, since they are <span class="math inline">\(2^p\)</span> of them; for example when <span class="math inline">\(p=40\)</span> there are over a billion models!</p></li>
<li><p>Instead we need an automated approach that searches through a subset of them.</p></li>
<li><p>From a set of <span class="math inline">\(p\)</span> explanatory variables all are not necessarily associated to <span class="math inline">\(Y\)</span> or their importance is marginal.</p></li>
<li><p><em>Variable selection</em> or model selection in regression analysis refers to the problem to choosing the best subset of variables from available (large number of) candidates.</p>
<ul>
<li>Criterion functions:
<ul>
<li>Mellow’s <span class="math inline">\(C_p\)</span></li>
<li>Akaike information criterion (AIC)</li>
<li>Bayesian information criterion (BIC)</li>
<li>Ajdusted $R<sup>2</sup></li>
<li>Cross-validation (CV)</li>
</ul></li>
<li><em>Forward selection</em>
<ul>
<li>start from the null model - a model that contains an intercept but no predictors.</li>
<li>Fit <span class="math inline">\(p\)</span> simple linear regressions and ad to the null model the variable that results in the lowest RSS</li>
<li>Add to that model the variable that results in the lowest RSS amongst all two-variable models.</li>
<li>Continue until some stopping rule is satisfied, for example when all remaining variables have a <span class="math inline">\(p\)</span>-value above some threshold.</li>
</ul></li>
<li><em>Backward selection</em>
<ul>
<li>Start with all variables in the model.</li>
<li>Remove the variable with the largest <span class="math inline">\(p\)</span>-value - that is, the variable that is the least statistically significant.</li>
<li>The new (<span class="math inline">\(p-1\)</span>)-variable model is fit, and the variable with the largest <span class="math inline">\(p\)</span>-value is removed.</li>
<li>Continue until a stopping rule is reached. For instance, we may stop when all remaining variables have a significant <span class="math inline">\(p\)</span>-value defined by some sifnificance threshold.</li>
</ul></li>
<li><em>Forward-backward selection (step-wise)</em>
<ul>
<li>This is a combination of forward and backward selection by starting with the forward selection.</li>
<li>And applying backward selection at each step to remove non-significant variables from the current model.</li>
<li>The procedure is stopped when no more variables are selected and no variables are removed.</li>
</ul></li>
</ul></li>
</ul>
<div id="remark-2" class="section level4 unnumbered hasAnchor">
<h4>Remark 2<a href="chapter4.html#remark-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>The step-wise selections can be also performed using criterion functions like AIC.</li>
<li>For example R package car has AIC step wise option.</li>
</ul>
</div>
<div id="example-6" class="section level4 unnumbered hasAnchor">
<h4>Example 6<a href="chapter4.html#example-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>AIC step wise variable selection.</li>
</ul>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="chapter4.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car) </span></code></pre></div>
<pre><code>## 필요한 패키지를 로딩중입니다: carData</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="chapter4.html#cb45-1" aria-hidden="true" tabindex="-1"></a>boston <span class="ot">&lt;-</span> MASS<span class="sc">::</span>Boston </span>
<span id="cb45-2"><a href="chapter4.html#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">3</span>, <span class="at">scipen =</span> <span class="dv">3</span>) </span>
<span id="cb45-3"><a href="chapter4.html#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">summary</span>(fit_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> boston)), <span class="at">digits =</span> <span class="dv">2</span>) </span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = medv ~ ., data = boston)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -15.59  -2.73  -0.52   1.78  26.20 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  36.45949    5.10346     7.1    3e-12 ***
## crim         -0.10801    0.03286    -3.3    0.001 ** 
## zn            0.04642    0.01373     3.4    8e-04 ***
## indus         0.02056    0.06150     0.3    0.738    
## chas          2.68673    0.86158     3.1    0.002 ** 
## nox         -17.76661    3.81974    -4.7    4e-06 ***
## rm            3.80987    0.41793     9.1   &lt;2e-16 ***
## age           0.00069    0.01321     0.1    0.958    
## dis          -1.47557    0.19945    -7.4    6e-13 ***
## rad           0.30605    0.06635     4.6    5e-06 ***
## tax          -0.01233    0.00376    -3.3    0.001 ** 
## ptratio      -0.95275    0.13083    -7.3    1e-12 ***
## black         0.00931    0.00269     3.5    6e-04 ***
## lstat        -0.52476    0.05072   -10.3   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.7 on 492 degrees of freedom
## Multiple R-squared:  0.74,   Adjusted R-squared:  0.73 
## F-statistic: 1.1e+02 on 13 and 492 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="chapter4.html#cb47-1" aria-hidden="true" tabindex="-1"></a>stw <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">stepAIC</span>(fit_lm, <span class="at">direction =</span> <span class="st">&quot;both&quot;</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>) </span>
<span id="cb47-2"><a href="chapter4.html#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(stw) <span class="co"># model select by stepwise AIC</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + 
##     tax + ptratio + black + lstat, data = boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.598  -2.739  -0.505   1.727  26.237 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  36.34115    5.06749    7.17  2.7e-12 ***
## crim         -0.10841    0.03278   -3.31  0.00101 ** 
## zn            0.04584    0.01352    3.39  0.00075 ***
## chas          2.71872    0.85424    3.18  0.00155 ** 
## nox         -17.37602    3.53524   -4.92  1.2e-06 ***
## rm            3.80158    0.40632    9.36  &lt; 2e-16 ***
## dis          -1.49271    0.18573   -8.04  6.8e-15 ***
## rad           0.29961    0.06340    4.73  3.0e-06 ***
## tax          -0.01178    0.00337   -3.49  0.00052 ***
## ptratio      -0.94652    0.12907   -7.33  9.2e-13 ***
## black         0.00929    0.00267    3.47  0.00056 ***
## lstat        -0.52255    0.04742  -11.02  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.74 on 494 degrees of freedom
## Multiple R-squared:  0.741,  Adjusted R-squared:  0.735 
## F-statistic:  128 on 11 and 494 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="chapter4.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="do">## log(medv)</span></span>
<span id="cb49-2"><a href="chapter4.html#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">summary</span>(fit_lm2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(medv) <span class="sc">~</span> ., <span class="at">data =</span> boston)), <span class="at">digits =</span> <span class="dv">2</span>) <span class="co"># regress log(medv) on all variables</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(medv) ~ ., data = boston)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.734 -0.097 -0.017  0.096  0.864 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.10204    0.20427    20.1   &lt;2e-16 ***
## crim        -0.01027    0.00132    -7.8    4e-14 ***
## zn           0.00117    0.00055     2.1    0.033 *  
## indus        0.00247    0.00246     1.0    0.317    
## chas         0.10089    0.03449     2.9    0.004 ** 
## nox         -0.77840    0.15289    -5.1    5e-07 ***
## rm           0.09083    0.01673     5.4    9e-08 ***
## age          0.00021    0.00053     0.4    0.691    
## dis         -0.04909    0.00798    -6.1    2e-09 ***
## rad          0.01427    0.00266     5.4    1e-07 ***
## tax         -0.00063    0.00015    -4.2    4e-05 ***
## ptratio     -0.03827    0.00524    -7.3    1e-12 ***
## black        0.00041    0.00011     3.8    1e-04 ***
## lstat       -0.02904    0.00203   -14.3   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.19 on 492 degrees of freedom
## Multiple R-squared:  0.79,   Adjusted R-squared:  0.78 
## F-statistic: 1.4e+02 on 13 and 492 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="chapter4.html#cb51-1" aria-hidden="true" tabindex="-1"></a>stw2 <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">stepAIC</span>(fit_lm2, <span class="at">direction =</span> <span class="st">&quot;both&quot;</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>) <span class="co"># forward-backward, no intermadiate results</span></span>
<span id="cb51-2"><a href="chapter4.html#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(stw2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(medv) ~ crim + zn + chas + nox + rm + dis + 
##     rad + tax + ptratio + black + lstat, data = boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.7340 -0.0946 -0.0177  0.0978  0.8629 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.083682   0.203049   20.11  &lt; 2e-16 ***
## crim        -0.010319   0.001313   -7.86  2.5e-14 ***
## zn           0.001087   0.000542    2.01  0.04531 *  
## chas         0.105148   0.034228    3.07  0.00224 ** 
## nox         -0.721744   0.141653   -5.10  5.0e-07 ***
## rm           0.090673   0.016281    5.57  4.2e-08 ***
## dis         -0.051706   0.007442   -6.95  1.2e-11 ***
## rad          0.013446   0.002540    5.29  1.8e-07 ***
## tax         -0.000558   0.000135   -4.13  4.3e-05 ***
## ptratio     -0.037426   0.005172   -7.24  1.8e-12 ***
## black        0.000413   0.000107    3.85  0.00013 ***
## lstat       -0.028604   0.001900  -15.05  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.19 on 494 degrees of freedom
## Multiple R-squared:  0.789,  Adjusted R-squared:  0.784 
## F-statistic:  168 on 11 and 494 DF,  p-value: &lt;2e-16</code></pre>
<ul>
<li>indus and age become removed.</li>
</ul>
</div>
</div>
<div id="model-fit" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Model fit<a href="chapter4.html#model-fit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Similar to simple regression <span class="math inline">\(R^2\)</span> and residual standard error (RSE) are two of the most common model fit measures.</p></li>
<li><p>In Example 4: <span class="math inline">\(R^2 = 0.986\)</span> , i.e., the model explains 98.6% of the total variation in sales.</p></li>
<li><p>Another R-squared is
<span class="math display">\[ \bar{R^2}= 1-\frac{RSS/(n-p-1)}{TSS/(n − 1)}=1-(1-R^2)\frac{n-1}{n-p-1}\]</span></p></li>
</ul>
<p>called the adjusted R-squared which penalizes the <span class="math inline">\(R^2\)</span> by inclusion of additional
explanatory variables.</p>
<ul>
<li><p>In Example 6: <span class="math inline">\(R^2 = 0.741\)</span> for the full model and 0.7406 for the stepwise selected model (indus and age removed), while <span class="math inline">\(\bar{R^2} = 0.734\)</span> for the full model and <span class="math inline">\(\bar{R^2} = 0.735\)</span> for the reduced model.</p></li>
<li><p>Thus, R-squared (slightly) decreases when removing explanatory variables,
while in this case the adjusted R-squared slightly increases.</p></li>
</ul>
</div>
<div id="prediction-1" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Prediction<a href="chapter4.html#prediction-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The estimated model</li>
</ul>
<p><span class="math display">\[\hat{y} = \hat{\beta}_0+\hat{\beta}_{1}x_1+ · · ·+\hat{\beta}_px_p\]</span>
estimates the <em>population regression</em></p>
<p><span class="math display">\[f(X) = \beta_0+\beta_1X_1+ · · ·+\beta_pX_p\]</span></p>
<ul>
<li><p>The inaccuracy in the estimated coefficients is related to the reducible error.</p></li>
<li><p><em>Confidence interval for regression</em> : Confidence interval of the population regression in (31) is</p></li>
</ul>
<p><span class="math display">\[\hat{y} ± c_{\alpha/2} \hat{se}(\hat{y}) \]</span></p>
<p>where</p>
<p><span class="math display">\[\hat{se}(\hat{y}) = \hat{\sigma}\sqrt{x&#39;(\boldsymbol x&#39;\boldsymbol x)^{-1}x}\]</span></p>
<p>is the standard error of the regression line (more precisely hyper plane).</p>
<ul>
<li><em>Confidence interval for prediction</em> : Confidence interval for a realized value <span class="math inline">\(y\)</span> related to a given <span class="math inline">\(x\)</span> observed values is given by</li>
</ul>
<p><span class="math display">\[\hat{y} ± c_{\alpha/2} \hat{se}(pred \, y)\]</span></p>
<p>where</p>
<p><span class="math display">\[\hat{se}(pred \, y) = \hat{\sigma}\sqrt{1+x&#39;(\boldsymbol x&#39;\boldsymbol x)^{-1}x}\]</span></p>
<ul>
<li>The one in the standard error of prediction is due to the irreducible error.</li>
</ul>
<div id="example-7" class="section level4 unnumbered hasAnchor">
<h4>Example 7<a href="chapter4.html#example-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>In the Advertising data set consider regression <span class="math inline">\(sales = \beta_0 + \beta_1TV + \beta_{11}(TV)^2 + \epsilon\)</span>.</li>
<li>The figure depicts 95% confidence for the regression line (grey) and predictions (light blue).</li>
</ul>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="chapter4.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="do">## regression of advertising on TV and TV squared</span></span>
<span id="cb53-2"><a href="chapter4.html#cb53-2" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> <span class="fu">I</span>(TV<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> adv)) <span class="co"># save summary resutls to object a and lm results to object fit</span></span>
<span id="cb53-3"><a href="chapter4.html#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="do">## lower 95% limit for the regression line</span></span>
<span id="cb53-4"><a href="chapter4.html#cb53-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fu">min</span>(adv<span class="sc">$</span>TV), <span class="at">to =</span> <span class="fu">max</span>(adv<span class="sc">$</span>TV), <span class="at">length =</span> <span class="dv">200</span>) <span class="co"># generate ordered values for prediction</span></span>
<span id="cb53-5"><a href="chapter4.html#cb53-5" aria-hidden="true" tabindex="-1"></a>xx <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">TV =</span> x) <span class="co"># values for the prediction equation</span></span>
<span id="cb53-6"><a href="chapter4.html#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="co">#head(xx)</span></span>
<span id="cb53-7"><a href="chapter4.html#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="do">## confidence interval for regression</span></span>
<span id="cb53-8"><a href="chapter4.html#cb53-8" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> xx, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>) <span class="co"># default ci is 95%</span></span>
<span id="cb53-9"><a href="chapter4.html#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="do">## confidence interval for prediction</span></span>
<span id="cb53-10"><a href="chapter4.html#cb53-10" aria-hidden="true" tabindex="-1"></a>pred2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> xx, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb53-11"><a href="chapter4.html#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co">#str(pred)</span></span>
<span id="cb53-12"><a href="chapter4.html#cb53-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(sales <span class="sc">~</span> TV, <span class="at">data =</span> adv, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>) <span class="co"># co-ordinate axes</span></span>
<span id="cb53-13"><a href="chapter4.html#cb53-13" aria-hidden="true" tabindex="-1"></a><span class="do">## use polygon function to create shaded confidence bounds</span></span>
<span id="cb53-14"><a href="chapter4.html#cb53-14" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="at">x =</span> <span class="fu">c</span>(x, <span class="fu">rev</span>(x)), <span class="at">y =</span> <span class="fu">c</span>(pred2[, <span class="st">&quot;upr&quot;</span>], <span class="fu">rev</span>(pred2[, <span class="st">&quot;lwr&quot;</span>])),</span>
<span id="cb53-15"><a href="chapter4.html#cb53-15" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">&quot;light blue&quot;</span>, <span class="at">border =</span> <span class="cn">NA</span>) <span class="co"># confidence interval for prediction</span></span>
<span id="cb53-16"><a href="chapter4.html#cb53-16" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="at">x =</span> <span class="fu">c</span>(x, <span class="fu">rev</span>(x)), <span class="at">y =</span> <span class="fu">c</span>(pred[, <span class="st">&quot;upr&quot;</span>], <span class="fu">rev</span>(pred[, <span class="st">&quot;lwr&quot;</span>])), <span class="at">col =</span> <span class="st">&quot;light gray&quot;</span>, <span class="at">border =</span> <span class="cn">NA</span>) <span class="co"># confidence interval for regression line</span></span>
<span id="cb53-17"><a href="chapter4.html#cb53-17" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> x, <span class="at">y =</span> pred[, <span class="st">&quot;fit&quot;</span>], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>) <span class="co"># fitted regression line</span></span>
<span id="cb53-18"><a href="chapter4.html#cb53-18" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">formula =</span> sales <span class="sc">~</span> TV, <span class="at">data =</span> adv, <span class="at">col =</span> <span class="st">&quot;steel blue&quot;</span>) <span class="co"># add observations</span></span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="other-consideration" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Other consideration<a href="chapter4.html#other-consideration" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="qualitative-predictors" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Qualitative predictors<a href="chapter4.html#qualitative-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Some predictors are not <em>quantitative</em> but are <em>qualitative</em>, taking a discrete set of values.</p></li>
<li><p>These are also called <em>categorical</em> predictors or <em>factor variable</em>.</p></li>
<li><p>Example - Credit data (ISLR package)</p></li>
</ul>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="chapter4.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR2)</span>
<span id="cb54-2"><a href="chapter4.html#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(<span class="fu">subset</span>(ISLR<span class="sc">::</span>Credit,<span class="at">select=</span><span class="fu">c</span>(<span class="st">&quot;Balance&quot;</span>,<span class="st">&quot;Age&quot;</span>,<span class="st">&quot;Cards&quot;</span>,<span class="st">&quot;Education&quot;</span>,<span class="st">&quot;Income&quot;</span>,<span class="st">&quot;Limit&quot;</span>,<span class="st">&quot;Rating&quot;</span>)),<span class="at">cex=</span><span class="fl">0.4</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="ILR_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<ul>
<li><p>In addition to the 7 quantitative variables shown, there are four qualitative variables: gender, student (student status), status (marital status), and ethnicity (Caucasian, African American (AA) or Asian)</p></li>
<li><p>Qualitative information that indicate only classification information (e.g. gender, ethnic group, etc) can be introduced into the regression using indicator or <em>dummy variables</em>.</p></li>
<li><p>In regression for a qualitative explanatory variables with <span class="math inline">\(q\)</span> classes, one is selected as the reference class and the other <span class="math inline">\(q-1\)</span> classes are indicated by <span class="math inline">\(q-1\)</span> dummy variables.</p></li>
<li><p>The coefficients of the dummy variable indicate the deviation from the base group.</p></li>
<li><p>In R category variables can be defined as factor variables, for which R generates the needed dummy variables in the regression.</p></li>
<li><p>Example: investigate differences in credit card balance between makes and females, ignoring the other variables.</p></li>
<li><p>We create a new variable</p></li>
</ul>
<p><span class="math display">\[
x_i=\begin{cases}
1, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, female \\
0, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, male \\
\end{cases}
\]</span></p>
<ul>
<li>Resulting model:</li>
</ul>
<p><span class="math display">\[
y_i=\beta_0+\beta_1x_i+\epsilon=\begin{cases}
\beta_0+\beta_1+\epsilon_i, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, female \\
\beta_0+\epsilon_i, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, male \\
\end{cases}
\]</span></p>
<ul>
<li>Interpretation?</li>
</ul>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="chapter4.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb55-2"><a href="chapter4.html#cb55-2" aria-hidden="true" tabindex="-1"></a>cred <span class="ot">&lt;-</span> ISLR<span class="sc">::</span>Credit</span>
<span id="cb55-3"><a href="chapter4.html#cb55-3" aria-hidden="true" tabindex="-1"></a>cred<span class="sc">$</span>Female <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(cred<span class="sc">$</span>Gender<span class="sc">==</span><span class="st">&quot;Female&quot;</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb55-4"><a href="chapter4.html#cb55-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Balance <span class="sc">~</span> Female, <span class="at">data=</span>cred)</span>
<span id="cb55-5"><a href="chapter4.html#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Female, data = cred)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -529.5 -455.4  -60.2  334.7 1489.2 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    509.8       33.1   15.39   &lt;2e-16 ***
## Female          19.7       46.1    0.43     0.67    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 460 on 398 degrees of freedom
## Multiple R-squared:  0.000461,   Adjusted R-squared:  -0.00205 
## F-statistic: 0.184 on 1 and 398 DF,  p-value: 0.669</code></pre>
<ul>
<li>With more than two levels, we create additional dummy variables. For example, for the <em>ethnicity</em> variable we create two dummy variables. The first could be</li>
</ul>
<p><span class="math display">\[
x_{i1}=\begin{cases}
1, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, Asian \\
0, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, not \,\,\, Asian \\
\end{cases}
\]</span></p>
<p>and the second could be</p>
<p><span class="math display">\[
x_{i2}=\begin{cases}
1, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, Caucasian \\
0, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, not \,\,\, Caucasian \\
\end{cases}
\]</span></p>
<ul>
<li>Then both of these variables can be used in the regression equation, in order to obtain the model</li>
</ul>
<p><span class="math display">\[
y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\epsilon=\begin{cases}
\beta_0+\beta_1+\epsilon_i, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, Asian \\
\beta_0+\beta_2+\epsilon_i, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, Caucasian \\
\beta_0+\epsilon_i, \,\,\, if \,\,\, ith \,\,\, person \,\,\, is \,\,\, AA \\
\end{cases}
\]</span></p>
<ul>
<li>There will always be one fewer dummy variable than the number of levels.
<ul>
<li>The level with no dummy variable - African American in this example - is known as the <em>baseline</em>.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="chapter4.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb57-2"><a href="chapter4.html#cb57-2" aria-hidden="true" tabindex="-1"></a>cred <span class="ot">&lt;-</span> ISLR<span class="sc">::</span>Credit</span>
<span id="cb57-3"><a href="chapter4.html#cb57-3" aria-hidden="true" tabindex="-1"></a>cred<span class="sc">$</span>Asian <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(cred<span class="sc">$</span>Ethnicity<span class="sc">==</span><span class="st">&quot;Asian&quot;</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb57-4"><a href="chapter4.html#cb57-4" aria-hidden="true" tabindex="-1"></a>cred<span class="sc">$</span>Caucasian <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(cred<span class="sc">$</span>Ethnicity<span class="sc">==</span><span class="st">&quot;Caucasian&quot;</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb57-5"><a href="chapter4.html#cb57-5" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Balance <span class="sc">~</span> Asian <span class="sc">+</span> Caucasian, <span class="at">data=</span>cred)</span>
<span id="cb57-6"><a href="chapter4.html#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Asian + Caucasian, data = cred)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -531.0 -457.1  -63.2  339.3 1480.5 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    531.0       46.3   11.46   &lt;2e-16 ***
## Asian          -18.7       65.0   -0.29     0.77    
## Caucasian      -12.5       56.7   -0.22     0.83    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 461 on 397 degrees of freedom
## Multiple R-squared:  0.000219,   Adjusted R-squared:  -0.00482 
## F-statistic: 0.0434 on 2 and 397 DF,  p-value: 0.957</code></pre>
</div>
<div id="example-8" class="section level3 unnumbered hasAnchor">
<h3>Example 8<a href="chapter4.html#example-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Using the wage data available on www.econometrics.com</li>
</ul>
<p><span class="math display">\[log(wage) = β_0 + δ_1singlefem + δ_2marrmale + δ_3marrfem + β_2educ\\ + β_3tenure + β_4exper + β_5(tenure)^2 + β_6(exper)^2 + \epsilon.\]</span></p>
<ul>
<li>Thus, single male is the reference group.</li>
</ul>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="chapter4.html#cb59-1" aria-hidden="true" tabindex="-1"></a>wdf <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="at">file =</span> <span class="st">&quot;http://econometrics.com/comdata/wooldridge/WAGE1.shd&quot;</span>, <span class="co"># data from econometrics.com</span></span>
<span id="cb59-2"><a href="chapter4.html#cb59-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>, <span class="co"># do not transform character variables as factor variable (category variables)</span></span>
<span id="cb59-3"><a href="chapter4.html#cb59-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">na.string =</span> <span class="sc">-</span><span class="dv">999</span> <span class="co"># missing values</span></span>
<span id="cb59-4"><a href="chapter4.html#cb59-4" aria-hidden="true" tabindex="-1"></a>                  ) <span class="co"># read.table</span></span>
<span id="cb59-5"><a href="chapter4.html#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="chapter4.html#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="do">## change variable names</span></span>
<span id="cb59-7"><a href="chapter4.html#cb59-7" aria-hidden="true" tabindex="-1"></a>vnames <span class="ot">&lt;-</span> <span class="fu">readLines</span>(<span class="at">con =</span> <span class="st">&quot;http://econometrics.com/comdata/wooldridge/wage1D.text&quot;</span>)</span>
<span id="cb59-8"><a href="chapter4.html#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="co">#head(vnames) # this shows that the variable names are in rows 3 to 5</span></span>
<span id="cb59-9"><a href="chapter4.html#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(wdf) <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">strsplit</span>(vnames[<span class="dv">3</span><span class="sc">:</span><span class="dv">5</span>], <span class="at">split =</span> <span class="st">&quot; +&quot;</span>)) <span class="co"># use only rows 3 to 5 (see also hlep(regexp) for more info about regular expressions)</span></span>
<span id="cb59-10"><a href="chapter4.html#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="chapter4.html#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(wdf) <span class="co"># check the restults</span></span></code></pre></div>
<pre><code>##   wage educ exper tenure nonwhite female married numdep smsa northcen south
## 1 3.10   11     2      0        0      1       0      2    1        0     0
## 2 3.24   12    22      2        0      1       1      3    1        0     0
## 3 3.00   11     2      0        0      0       0      2    0        0     0
## 4 6.00    8    44     28        0      0       1      0    1        0     0
## 5 5.30   12     7      2        0      0       1      1    0        0     0
## 6 8.75   16     9      8        0      0       1      0    1        0     0
##   west construc ndurman trcommpu trade services profserv profocc clerocc
## 1    1        0       0        0     0        0        0       0       0
## 2    1        0       0        0     0        1        0       0       0
## 3    1        0       0        0     1        0        0       0       0
## 4    1        0       0        0     0        0        0       0       1
## 5    1        0       0        0     0        0        0       0       0
## 6    1        0       0        0     0        0        1       1       0
##   servocc lwage expersq tenursq
## 1       0  1.13       4       0
## 2       1  1.18     484       4
## 3       0  1.10       4       0
## 4       0  1.79    1936     784
## 5       0  1.67      49       4
## 6       0  2.17      81      64</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="chapter4.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="do">## add marriage status as a factor variable with four levels</span></span>
<span id="cb61-2"><a href="chapter4.html#cb61-2" aria-hidden="true" tabindex="-1"></a>wdf<span class="sc">$</span>mstatus <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> wdf<span class="sc">$</span>female) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> wdf<span class="sc">$</span>married) <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> wdf<span class="sc">$</span>female <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> wdf<span class="sc">$</span>married) <span class="sc">+</span></span>
<span id="cb61-3"><a href="chapter4.html#cb61-3" aria-hidden="true" tabindex="-1"></a>                          <span class="dv">3</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> wdf<span class="sc">$</span>female) <span class="sc">*</span> wdf<span class="sc">$</span>married <span class="sc">+</span> <span class="dv">4</span> <span class="sc">*</span> wdf<span class="sc">$</span>female <span class="sc">*</span> wdf<span class="sc">$</span>married,</span>
<span id="cb61-4"><a href="chapter4.html#cb61-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">levels =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;single male&quot;</span>, <span class="st">&quot;single female&quot;</span>, <span class="st">&quot;married male&quot;</span>, <span class="st">&quot;married female&quot;</span>))</span>
<span id="cb61-5"><a href="chapter4.html#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="chapter4.html#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="do">## single males become the reference group</span></span>
<span id="cb61-7"><a href="chapter4.html#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(wage) <span class="sc">~</span> mstatus <span class="sc">+</span> educ <span class="sc">+</span> tenure <span class="sc">+</span> exper <span class="sc">+</span> <span class="fu">I</span>(tenure<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span>  <span class="fu">I</span>(exper<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> wdf))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(wage) ~ mstatus + educ + tenure + exper + I(tenure^2) + 
##     I(exper^2), data = wdf)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.8970 -0.2406 -0.0269  0.2314  1.0920 
## 
## Coefficients:
##                        Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept)            0.321378   0.100009    3.21    0.00139 ** 
## mstatussingle female  -0.110350   0.055742   -1.98    0.04827 *  
## mstatusmarried male    0.212676   0.055357    3.84    0.00014 ***
## mstatusmarried female -0.198268   0.057835   -3.43    0.00066 ***
## educ                   0.078910   0.006694   11.79    &lt; 2e-16 ***
## tenure                 0.029088   0.006762    4.30 0.00002028 ***
## exper                  0.026801   0.005243    5.11 0.00000045 ***
## I(tenure^2)           -0.000533   0.000231   -2.31    0.02153 *  
## I(exper^2)            -0.000535   0.000110   -4.85 0.00000166 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.393 on 517 degrees of freedom
## Multiple R-squared:  0.461,  Adjusted R-squared:  0.453 
## F-statistic: 55.2 on 8 and 517 DF,  p-value: &lt;2e-16</code></pre>
<div id="extensions-of-the-linear-model" class="section level4 unnumbered hasAnchor">
<h4>Extensions of the Linear Model<a href="chapter4.html#extensions-of-the-linear-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Removing the additive assumption: <em>interactions</em> and <em>nonlinearity</em></li>
</ul>
</div>
<div id="interactions" class="section level4 unnumbered hasAnchor">
<h4><strong>Interactions</strong><a href="chapter4.html#interactions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>In our previous analysis of the Advertising data, we assumed that the effect on sales of increasing one advertising medium is independent of the amount spent on the other media.</p></li>
<li><p>For example, the linear model</p></li>
</ul>
<p><span class="math display">\[
\hat{sales}=\beta_0+\beta_1\times TV+\beta_2 \times radio+\beta_3\times newspaper
\]</span>
      states that the average effect on sales of a one-unit increase in TV is always <span class="math inline">\(\beta_1\)</span>, regardless of the amount spent on radio.</p>
<ul>
<li><p>But suppose that spending money on radio advertising actually increases the effectiveness of TV advertising, so that the slope term for TV should increase as radio increases.</p></li>
<li><p>In this situation, given a fixed budget of $100,000, spending half on radio nad half on TV may increase sales more than allocating the entire amount to either TV or to radio.</p></li>
<li><p>In marketing, this is known as a <em>synergy</em> effect, and in statistics it is referred to as an <em>interaction</em> effect.</p></li>
</ul>
<p><img src="fig4/f5.png" /></p>
<ul>
<li><p>When levels of either TV or radio are low, then the true sales are lower than predicted by the linear model.</p></li>
<li><p>But when advertising is split between the two media, then the model tends to underestimate sales.</p></li>
<li><p>Model takes the form</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
sales &amp;= \beta_0+\beta_1\times TV+\beta_2 \times radio+\beta_3 (radio\times TV) +\epsilon \\
&amp;= \beta_0+(\beta_1 +\beta_3 \times radio) \times TV +\beta_2 \times radio +\epsilon
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="chapter4.html#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="at">help =</span> ISLR2)</span>
<span id="cb63-2"><a href="chapter4.html#cb63-2" aria-hidden="true" tabindex="-1"></a>adv <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file =</span> <span class="st">&quot;https://www.statlearning.com/s/Advertising.csv&quot;</span>)</span>
<span id="cb63-3"><a href="chapter4.html#cb63-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales<span class="sc">~</span>TV<span class="sc">+</span>radio<span class="sc">+</span>TV<span class="sc">:</span>radio, <span class="at">data=</span>adv)</span>
<span id="cb63-4"><a href="chapter4.html#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sales ~ TV + radio + TV:radio, data = adv)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.337 -0.403  0.183  0.595  1.525 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 6.7502202  0.2478714   27.23   &lt;2e-16 ***
## TV          0.0191011  0.0015041   12.70   &lt;2e-16 ***
## radio       0.0288603  0.0089053    3.24   0.0014 ** 
## TV:radio    0.0010865  0.0000524   20.73   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.944 on 196 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.967 
## F-statistic: 1.96e+03 on 3 and 196 DF,  p-value: &lt;2e-16</code></pre>
<ul>
<li><p>The results in this table suggests that interactions are important.</p></li>
<li><p>The <span class="math inline">\(p\)</span>-value for the interaction term <span class="math inline">\(TV\times radio\)</span> is extremely low, indicating that there is strong evidence for <span class="math inline">\(H_A:\beta_3 \ne 0\)</span>.</p></li>
<li><p>The <span class="math inline">\(R^2\)</span> for the interaction model is 96.8%, compared to only 89.7% for the model that predicts sales using TV and radio without an interaction term.</p></li>
<li><p>This means that (96.8-89.7)/(100-89.7)=69% of the variability in sales that remains after fitting the additive model has been explained by the interaction term.</p></li>
<li><p>The coefficient estimates in the table suggest that an increase in TV advertising of $1,000 is associted with increased sales of <span class="math inline">\((\hat{\beta}_1+\hat{\beta}_3\times radio)\times 1000=19+1.1\times radio\)</span> units.</p></li>
<li><p>An increase in radio advertising of $1,000 will be assiciated with an increase in sales of <span class="math inline">\((\hat{\beta}_2+\hat{\beta}_3\times TV)\times 1000=29+1.1\times TV\)</span> units.</p></li>
</ul>
</div>
<div id="hierarchy" class="section level4 unnumbered hasAnchor">
<h4>Hierarchy<a href="chapter4.html#hierarchy" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Sometimes it is the case that an interaction term has a very small <span class="math inline">\(p\)</span>-value, but the associated main effects (in this case, TV and radio) do not.</p></li>
<li><p>The <em>hierarchy principle</em></p>
<ul>
<li>If we include an interaction in a model, we should also include the main effects, even if the <span class="math inline">\(p\)</span>-values associated with their coefficients are not significant.</li>
</ul></li>
<li><p>The rationale for this principle is that interactions are hard to interpret in a model without main effects - their meaning is changed.</p></li>
<li><p>Specifically, the interaction terms also contain main effects, if the model has no main effect terms.</p></li>
<li><p>Consider the Credit data set, and suppose that we wish to predict balance using income (quantitative) and student (qualitative)</p></li>
<li><p>Without an interaction term, the model takes the form</p></li>
</ul>
<p><img src="fig4/f6.png" /></p>
<ul>
<li>With interactions, it takes the form</li>
</ul>
<p><img src="fig4/f7.png" /></p>
<p><img src="fig4/f8.png" /></p>
<ul>
<li><p>Credit data; left: no interaction between income and student. Right: with an interaction term between income and student.</p></li>
<li><p>Polynomial regression on Auto data</p></li>
</ul>
<p><img src="fig4/f9.png" /></p>
<ul>
<li>The figure suggests that</li>
</ul>
<p><span class="math display">\[
mpg=\beta_0+\beta_1\times horsepower+\beta_2\times horsepower^2+\epsilon
\]</span>
may provide a better fit.</p>
<p><img src="fig4/f10.png" /></p>
</div>
</div>
<div id="potential-problems" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Potential problems<a href="chapter4.html#potential-problems" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>In fitting a linear regression, many problems may occur.
<ul>
<li>Correlation of error terms with explanatory variables</li>
<li>Non-linearity</li>
<li>Correlation of error terms</li>
<li>Heteroskedasticity</li>
<li>Outliers</li>
<li>High-leverage points</li>
<li>Collinearity</li>
</ul></li>
<li>Graphical tools hare often useful in checking the presence of most of these problems (scatter plots of residuals against predicted
values and explanatory variables as we have done in some of Advertising examples).</li>
</ul>
</div>
</div>
<div id="non-parametric-regressions" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Non-parametric regressions<a href="chapter4.html#non-parametric-regressions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>Parametric regression assume well defined functional form for <span class="math inline">\(f(x)\)</span>.</p></li>
<li><p>Non-parametric approaches do not set assumptions on <span class="math inline">\(f(x)\)</span>.</p></li>
<li><p>These methods rely on data and apply different algorithms to find relationships between the dependent and response variable.</p></li>
<li><p>One is the <span class="math inline">\(K\)</span>-nearest neighbor regression (KNN regression), which is closely related to KNN classifier.</p></li>
<li><p>Given a value of <span class="math inline">\(K\)</span> and prediction point <span class="math inline">\(x_0\)</span> , KNN regression first identifies the <span class="math inline">\(K\)</span> training observations that are closest to <span class="math inline">\(x_0\)</span>,
represented by <span class="math inline">\(N_0\)</span>.</p></li>
<li><p><span class="math inline">\(f(x_0)\)</span> is estimated by the average of the training responses in <span class="math inline">\(N_0\)</span> , i.e.,</p></li>
</ul>
<p><span class="math display">\[
\hat{f}(x_0) = \frac{1}{K} \sum_{x_i \in N_0}y_i\]</span></p>
<ul>
<li>We will return to this later.</li>
</ul>
<p><br></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter3.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ILR.pdf", "ILR.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
